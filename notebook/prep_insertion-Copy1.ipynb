{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is for compute canada.\n",
    "#{'A': 'A', 'C': 'C', 'G': 'G', 'T': 'T', '-': '-', 'AA': 'q', 'AC': 'd', 'AT': 'M', 'AG': 'B', 'CA': 'O', 'CC': 'b', 'CT': 'U', 'CG': 'y', 'TA': 'p', 'TC': 'K', 'TT': 'S', 'TG': 'D', 'GA': 'r', 'GC': 'P', 'GT': 'Z', 'GG': 'l'}\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from bio import AlignIO\n",
    "# from Bio.Align import MultipleSeqAlignment\n",
    "# from Bio.SeqRecord import SeqRecord\n",
    "# from Bio import SeqIO\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras_preprocessing import sequence\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: panTro4.chr2A\n",
      "Name: panTro4.chr2A\n",
      "Number of features: 0\n",
      "/start=4703\n",
      "/size=1\n",
      "/strand=1\n",
      "/srcSize=113622374\n",
      "Seq('a', SingleLetterAlphabet())\n",
      "['__add__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_alphabet', '_annotations', '_append', '_get_per_column_annotations', '_per_col_annotations', '_records', '_set_per_column_annotations', '_str_line', 'add_sequence', 'annotations', 'append', 'column_annotations', 'extend', 'format', 'get_alignment_length', 'sort']\n",
      "hg38.chr2\n"
     ]
    }
   ],
   "source": [
    "seq_length = 11\n",
    "def string_to_array(my_string):\n",
    "    my_string = my_string.lower()\n",
    "    my_string = re.sub('[^acgt0]', 'z', my_string)\n",
    "    my_array = np.array(list(my_string))\n",
    "    return my_array\n",
    "\n",
    "def readmaf(start, end, filename):\n",
    "    count = 0\n",
    "    oldlist =[]\n",
    "    align = AlignIO.parse(filename, \"maf\")\n",
    "\n",
    "    for multiple_alignment in align:\n",
    "        count = count+1\n",
    "        if count >start and count<=end:\n",
    "            oldlist.append(multiple_alignment)\n",
    "        elif count>end:\n",
    "            break\n",
    "    return oldlist\n",
    "\n",
    "#oldlist stores MSAs\n",
    "oldlist = readmaf(0, 1000000, \"data/chr2.anc.maf\")\n",
    "print(oldlist[1][1])\n",
    "print(dir(oldlist[1]))\n",
    "print(oldlist[1][0].id)\n",
    "#print(oldlist[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print(len(oldlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alignList stores alignments between direct ancestor and descendent\n",
    "ancSeq = ['_HPGPNRMPC']\n",
    "desSeq = ['hg38', 'panTro4', 'ponAbe2', 'nomLeu3', 'rheMac3', 'macFas5', 'papAnu2', 'calJac3']\n",
    "\n",
    "# def getAlign(inputList):\n",
    "#     alignList = []\n",
    "#     zeros = ''\n",
    "#     anc = ''\n",
    "#     des = ''\n",
    "#     for i in range(len(inputList)):\n",
    "#         # index for the dog\n",
    "#         indexDes = -1\n",
    "#         indexAnc = -1\n",
    "\n",
    "#         for j in range(len(inputList[i])):\n",
    "#             if len(inputList[i][j])>=10 and 'canFam3' in inputList[i][j].id  :\n",
    "#                 indexDes = j\n",
    "#             elif len(inputList[i][j])>=10 and inputList[i][j].id == '_CMAOL': #'_RMPC' :\n",
    "#                 indexAnc = j\n",
    "#         if indexDes!=-1 and indexAnc!=-1:\n",
    "#             des = des+str(inputList[i][indexDes].seq)\n",
    "#             anc = anc+str(inputList[i][indexAnc].seq)\n",
    "\n",
    "#     return anc, des\n",
    "\n",
    "\n",
    "# anc, des = getAlign(oldlist)\n",
    "# print(anc[:100])\n",
    "# print(des[:100])\n",
    "# print(anc[7]=='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyzBDEFHIJKLMNOPQRSUVWXYZ\n",
      "{'A': 'A', 'C': 'C', 'G': 'G', 'T': 'T', '-': '-', 'AA': 'S', 'AC': 'H', 'AT': 'F', 'AG': 'Y', 'CA': 'W', 'CC': 'P', 'CT': 'm', 'CG': 'X', 'TA': 'r', 'TC': 'K', 'TT': 'Q', 'TG': 'u', 'GA': 'J', 'GC': 'v', 'GT': 'l', 'GG': 'O'}\n",
      "_HPGPNRMPC hg38\n"
     ]
    }
   ],
   "source": [
    "keys = []\n",
    "alphabet = string.ascii_letters\n",
    "alphabet = alphabet.replace('A','').replace('C', '').replace('G', '').replace('T', '').replace('-', '')\n",
    "print(alphabet)\n",
    "#print(random.sample(string.ascii_letters, 5))\n",
    "a = 'ACTG'\n",
    "for output in itertools.product(a, repeat=2):\n",
    "    keys.append(''.join(output))\n",
    "value = random.sample(alphabet, len(keys))\n",
    "alphaDict = {'A' : 'A', 'C' :'C', 'G':'G','T':'T', '-':'-'}\n",
    "for k, v in zip(keys, value):\n",
    "    alphaDict[k] = v\n",
    "    \n",
    "print(alphaDict)\n",
    "\n",
    "def ungap(anc, des):\n",
    "    a = ''\n",
    "    d = ''\n",
    "    for i in range(len(anc)):\n",
    "        if anc[i] == '-' and des[i] =='-':\n",
    "            continue\n",
    "        else:\n",
    "            a = a+ anc[i]\n",
    "            d = d + des[i]\n",
    "            \n",
    "    return a, d\n",
    "\n",
    "def coded(anc, des):\n",
    "    newAnc = ''\n",
    "    newDes = ''\n",
    "    if len(anc) != len(des):\n",
    "        print('Lenghts mismatch!')\n",
    "        return\n",
    "    i = 0\n",
    "    while i < len(anc)-1:\n",
    "\n",
    "        if anc[i] != '-' and anc[i+1] == '-' and anc[i+2] != '-' and des[i+1] != '-' and des[i] != '-':\n",
    "            newAnc = newAnc + anc[i]\n",
    "            newDes = newDes + alphaDict[des[i:i+2]]\n",
    "            i = i+2\n",
    "        else:\n",
    "            newAnc = newAnc + anc[i]\n",
    "            newDes = newDes + des[i]\n",
    "            i= i+1\n",
    "\n",
    "    return [newAnc, newDes]\n",
    "\n",
    "def ungapAnc(anc, des):\n",
    "    newAnc = ''\n",
    "    newDes = ''\n",
    "    for i in range(len(anc)):\n",
    "        if anc[i] == '-':\n",
    "            continue\n",
    "        else:\n",
    "            newAnc = newAnc + anc[i]\n",
    "            newDes = newDes + des[i]\n",
    "    return [newAnc, newDes]\n",
    "            \n",
    "def getAlign(inputList, ancSeq, desSeq):\n",
    "    alignDict = {}\n",
    "    nucSet = set(['A','C','G','T','-'])\n",
    "    for a in ancSeq:\n",
    "        for b in desSeq:\n",
    "            print(a,b)\n",
    "            alignList = []\n",
    "            zeros = ''\n",
    "            anc = ''\n",
    "            des = ''\n",
    "            for i in range(len(inputList)):\n",
    "                # index for the dog\n",
    "                indexDes = -1\n",
    "                indexAnc = -1\n",
    "                for j in range(len(inputList[i])):\n",
    "                    if set(inputList[i][j].seq.upper()).issubset(nucSet) and (b in inputList[i][j].id ) :\n",
    "                        indexDes = j\n",
    "                    elif set(inputList[i][j].seq.upper()).issubset(nucSet) and (inputList[i][j].id == a): #'_RMPC' :\n",
    "                        indexAnc = j\n",
    "                if indexDes!=-1 and indexAnc!=-1:\n",
    "                    des = des+str(inputList[i][indexDes].seq)\n",
    "                    anc = anc+str(inputList[i][indexAnc].seq)\n",
    "            anc = anc.upper()\n",
    "            des = des.upper()\n",
    "            anc, des = ungap(anc, des)\n",
    "            anc, des = coded(anc, des)\n",
    "            anc, des = ungapAnc(anc, des)\n",
    "            \n",
    "            np.save('prepData/insert1Anc_{}_{}'.format(a,b), anc)\n",
    "            np.save('prepData/insert1Des_{}_{}'.format(a,b), des)\n",
    "            alignDict[(a,b)] = (anc,des)\n",
    "    return alignDict           \n",
    "\n",
    "getAlign(oldlist, ancSeq, desSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneEncode(input):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded_seq = label_encoder.fit_transform(input)\n",
    "\n",
    "    #one hot the sequence\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    #reshape because that's what OneHotEncoder likes\n",
    "    integer_encoded_seq = integer_encoded_seq.reshape(len(integer_encoded_seq), 1)\n",
    "    onehot_encoded_seq = onehot_encoder.fit_transform(integer_encoded_seq)\n",
    "    return onehot_encoded_seq\n",
    "\n",
    "oneEncode(np.array(list(des)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(anc):\n",
    "    token = []\n",
    "    for i in range(len(anc)-seq_length):\n",
    "        token.append(list(anc[i:i+seq_length]))\n",
    "    return token\n",
    "\n",
    "\n",
    "# with open('ancestral', 'wb') as fp:\n",
    "#     pickle.dump(anc, fp)\n",
    "    \n",
    "# with open('descendant', 'wb') as f:\n",
    "#     pickle.dump(des, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    print(''.join(anc[i]), ''.join(des[i]))\n",
    "    if ''.join(anc[i]) == ''.join(des[i]):\n",
    "        print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['a','c','g','t','0', 'z']))\n",
    "encoder = OneHotEncoder(sparse=False, dtype=int, categories=[range(6)])\n",
    "def one_hot_encoder(my_array, encoder):\n",
    "    integer_encoded = label_encoder.transform(my_array)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = encoder.fit_transform(integer_encoded)\n",
    "    #onehot_encoded = np.delete(onehot_encoded, -1, 1)\n",
    "    return onehot_encoded, encoder\n",
    "\n",
    "def alignBoth(alignList):\n",
    "    zeros = '00000'\n",
    "    h, w = len(alignList), 2;\n",
    "    Matrix = [[0 for x in range(w)] for y in range(h)]\n",
    "    for i in range(len(alignList)):\n",
    "        for j in range(len(alignList[i])):\n",
    "            Matrix[i][j] = one_hot_encoder(string_to_array(str(alignList[i][j].seq).upper()), encoder)\n",
    "    return Matrix\n",
    "\n",
    "# [Index of alignment][1 for Ancester, 0 for Descendant][Always 0]\n",
    "one_hot_aligned = alignBoth(alignList)\n",
    "#one_hot_aligned = one_hot_aligned[:][:][0]\n",
    "one_hot_aligned = np.array(one_hot_aligned)\n",
    "#print(one_hot_aligned.shape)\n",
    "#ignorethis, encoder = one_hot_encoder(string_to_array(str(alignList[1][1].seq)),encoder)\n",
    "\n",
    "\n",
    "print(type(one_hot_aligned))\n",
    "print(len(one_hot_aligned[126][1]))\n",
    "print(one_hot_aligned[126][1][0])\n",
    "#print(encoder.inverse_transform(one_hot_aligned[126][1]))\n",
    "print(type(one_hot_aligned[126][1]))\n",
    "# A = [1 0 0 0], C = [0 1 0 0], G = [0 0 1 0], T = [0 0 0 1]\n",
    "def decoder(array):\n",
    "    result = \"\"\n",
    "    size = len(array)\n",
    "    for i in range(size):\n",
    "        if array[i].tolist() == [1, 0, 0, 0, 0, 0]:\n",
    "            result=result+\"0\" \n",
    "        elif array[i].tolist() == [0, 1, 0, 0, 0, 0]:\n",
    "            result=result+\"A\"\n",
    "        elif array[i].tolist() == [0, 0, 1, 0, 0, 0]:\n",
    "            result=result+\"C\"\n",
    "        elif array[i].tolist() == [0, 0, 0, 1, 0, 0]:\n",
    "            result=result+\"G\"\n",
    "        elif array[i].tolist() == [0, 0, 0, 0, 1, 0]:\n",
    "            result=result+\"T\"\n",
    "        elif array[i].tolist() == [0, 0, 0, 0, 0, 1]:\n",
    "            result=result+\"-\"\n",
    "    return result\n",
    "\n",
    "def decoderY(array):\n",
    "    result = \"\"    \n",
    "    if array.tolist() == [1, 0, 0, 0, 0, 0]:\n",
    "        result=result+\"0\" \n",
    "    elif array.tolist() == [0, 1, 0, 0, 0, 0]:\n",
    "        result=result+\"A\"\n",
    "    elif array.tolist() == [0, 0, 1, 0, 0, 0]:\n",
    "        result=result+\"C\"\n",
    "    elif array.tolist() == [0, 0, 0, 1, 0, 0]:\n",
    "        result=result+\"G\"\n",
    "    elif array.tolist() == [0, 0, 0, 0, 1, 0]:\n",
    "        result=result+\"T\"\n",
    "    elif array.tolist() == [0, 0, 0, 0, 0, 1]:\n",
    "        result=result+\"-\"\n",
    "    return result\n",
    "    \n",
    "print(decoder(one_hot_aligned[126][1][0]))\n",
    "print(len(one_hot_aligned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(char_setx, char_sety, sequence_length):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    dataX1 = []\n",
    "    dataY1 = []\n",
    "    result=[]\n",
    "    char_setx, char_sety = mutation_with_gap(char_setx, char_sety)\n",
    "    #print(type(char_sety[0]))\n",
    "    for i in range(len(char_setx) - sequence_length):\n",
    "        \n",
    "        '''for i in char_sety[i: i + sequence_length-1]:\n",
    "            y1.append(i)'''\n",
    "        #x1 = char_setx1[i: i + sequence_length]\n",
    "        x = char_setx[i:i + sequence_length]\n",
    "        y = char_sety[i: i + sequence_length]\n",
    "        y1 = [[1, 0, 0, 0, 0, 0]]\n",
    "        temp = y[:-1]\n",
    "        #temp = temp.tolist()\n",
    "        for i in temp:\n",
    "            y1.append(i)\n",
    "        y1=np.array(y1)\n",
    "        dataX.append(x)\n",
    "        dataY.append(y)\n",
    "        dataY1.append(y1)\n",
    "\n",
    "    return dataX, dataY, dataY1\n",
    "\n",
    "def tokenize(one_hot_aligned, sequence_length):\n",
    "    X = []\n",
    "    Y = []\n",
    "    X1 = []\n",
    "    Y1 = []\n",
    "    for i in range(len(one_hot_aligned)):\n",
    "        dataX, dataY, dataY1 = vectorize(one_hot_aligned[i][1][0], one_hot_aligned[i][0][0],  sequence_length)\n",
    "        X.extend(dataX)\n",
    "        Y.extend(dataY)\n",
    "        #X1.extend(dataX1)\n",
    "        Y1.extend(dataY1)\n",
    "    return X, Y, Y1\n",
    "\n",
    "def truncate(one_hot_aligned):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(one_hot_aligned)):\n",
    "        X.append(one_hot_aligned[i][1][0])\n",
    "        Y.append(one_hot_aligned[i][0][0])\n",
    "    X = sequence.pad_sequences(X,\n",
    "                                 maxlen=30,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=0)\n",
    "    Y = sequence.pad_sequences(Y,\n",
    "                                 maxlen=30,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=0)\n",
    "    return X,Y\n",
    "\n",
    "# function for checking if there are at least one mutation and there are no gaps.\n",
    "def mutation_with_nogap(a, b):\n",
    "    a = a.tolist()\n",
    "    b = b.tolist()\n",
    "    if a.count([0,0,0,0,0,1])>0 or b.count([0,0,0,0,0,1])>0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def mutation_with_gap(a, b):\n",
    "    a = a.tolist()\n",
    "    b = b.tolist()\n",
    "    a_new = []\n",
    "    b_new = []\n",
    "    for i, j in zip(a,b):\n",
    "        if i == [0,0,0,0,0,1] and j == [0,0,0,0,0,1]:\n",
    "            continue\n",
    "        else:\n",
    "            a_new.append(i)\n",
    "            b_new.append(j)\n",
    "    return a_new, b_new\n",
    "        \n",
    "\n",
    "\n",
    "def diffList(a, b):\n",
    "    count = 0\n",
    "    length = len(a)\n",
    "    for i in range(length):\n",
    "        if a[i] != b[i]:\n",
    "            count = count+1\n",
    "    return count\n",
    "\n",
    "def deleteGap(one_hot_aligned):\n",
    "    result = one_hot_aligned\n",
    "    for i in range(len(one_hot_aligned)):\n",
    "        if one_hot_aligned[i][1][0] == '-' and one_hot_aligned[i][0][0] == '-':\n",
    "            result.pop(i)\n",
    "    return result\n",
    "\n",
    "# Used for non 0 padding\n",
    "#one_hot_aligned = deleteGap(one_hot_aligned)\n",
    "X, Y, Y1=tokenize(one_hot_aligned, seq_length)\n",
    "\n",
    "# Used for 0 padding\n",
    "#X, Y = truncate(one_hot_aligned)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "#X1 = np.array(X1)\n",
    "Y1 = np.array(Y1)\n",
    "\n",
    "print(Y.shape)\n",
    "print(len(X))\n",
    "pt1 = 9600000\n",
    "pt2 = 9650000\n",
    "pt3 = 9700000\n",
    "X_train = X[:pt1]\n",
    "X_val = X[pt1:pt2]\n",
    "X_test = X[pt2:pt3]\n",
    "y_train = Y[:pt1]\n",
    "y_val =  Y[pt1:pt2]\n",
    "y_test = Y[pt2:pt3]\n",
    "# X_train1 = X1[:pt1]\n",
    "# X_val1 = X1[pt1:pt2]\n",
    "# X_test1 = X1[pt2:pt3]\n",
    "y_train1 = Y1[:pt1]\n",
    "y_val1 =  Y1[pt1:pt2]\n",
    "y_test1 = Y1[pt2:pt3]\n",
    "\n",
    "# X_train = X[:20000]\n",
    "# X_val = X[20000:23000]\n",
    "# X_test = X[23000:26000]\n",
    "# y_train = Y[:20000]\n",
    "# y_val =  Y[20000:23000]\n",
    "# y_test = Y[23000:26000]\n",
    "\n",
    "np.save('prepData/X_train_camFam3_v3_chr2_size11', X_train)\n",
    "np.save('prepData/X_val_camFam3_v3_chr2_size11', X_val)\n",
    "np.save('prepData/X_test_camFam3_v3_chr2_size11', X_test)\n",
    "np.save('prepData/y_train_camFam3_v3_chr2_size11', y_train)\n",
    "np.save('prepData/y_val_camFam3_v3_chr2_size11', y_val)\n",
    "np.save('prepData/y_test_camFam3_v3_chr2_size11', y_test)\n",
    "\n",
    "np.save('prepData/y_train1_camFam3_v3_chr2_size11', y_train1)\n",
    "np.save('prepData/y_val1_camFam3_v3_chr2_size11', y_val1)\n",
    "np.save('prepData/y_test1_camFam3_v3_chr2_size11', y_test1)\n",
    "\n",
    "# np.save('prepData/X_train1_camFam3_1mutOnly_v2', X_train1)\n",
    "# np.save('prepData/X_val1_camFam3_1mutOnly_v2', X_val1)\n",
    "# np.save('prepData/X_test1_camFam3_1mutOnly_v2', X_test1)\n",
    "\n",
    "\n",
    "# np.save('prepData20/X_train_camFam3_1mutOnly', X_train)\n",
    "# np.save('prepData20/X_val_camFam3_1mutOnly', X_val)\n",
    "# np.save('prepData20/X_test_camFam3_1mutOnly', X_test)\n",
    "# np.save('prepData20/y_train_camFam3_1mutOnly', y_train)\n",
    "# np.save('prepData20/y_val_camFam3_1mutOnly', y_val)\n",
    "# np.save('prepData20/y_test_camFam3_1mutOnly', y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(y_train1[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import difflib\n",
    "# sm=difflib.SequenceMatcher(None,X_test,X_train)\n",
    "# sm2=difflib.SequenceMatcher(None,y_test,y_train)\n",
    "for i in range(100):\n",
    "    print(i, decoder(X[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(i, decoder(Y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(i, decoder(Y1[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
