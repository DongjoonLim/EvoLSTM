{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import itertools\n",
    "import operator\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as k\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import choice\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "ancName = '_HPGPNRMPCCSO'\n",
    "desName = 'hg38'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "seq_length = 15\n",
    "val_loss_hist = []\n",
    "train_size = 0\n",
    "modelName = 'lstm'\n",
    "\n",
    "#K.clear_session()\n",
    "#keras.backend.clear_session()\n",
    "\n",
    "anc = str(np.load('prepData/insert2Anc_{}_{}.npy'.format(ancName, desName)))\n",
    "des = str(np.load('prepData/insert2Des_{}_{}.npy'.format(ancName, desName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "anc = np.array(list(anc+'0'))\n",
    "des = np.array(list(des+'0'))\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(des)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded_des = label_encoder.transform(des)\n",
    "integer_encoded_anc = label_encoder.transform(anc)\n",
    "#one hot the sequence\n",
    "integer_des = integer_encoded_des.reshape(len(integer_encoded_des), 1)\n",
    "\n",
    "onehot_encoder.fit(integer_des)\n",
    "encoded_des =onehot_encoder.transform(integer_des)\n",
    "\n",
    "integer_anc = integer_encoded_anc.reshape(len(integer_encoded_anc), 1)\n",
    "encoded_anc = onehot_encoder.transform(integer_anc)\n",
    "\n",
    "print(encoded_des)\n",
    "print(encoded_anc)\n",
    "\n",
    "print(len(encoded_des[0]))\n",
    "encode_dimension= len(encoded_des[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_des.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!' '\"' '$' '%' '&' '(' ')' '*' '+' '-' '.' '/' '0' '1' '2' '3' '4' '5'\n",
      " '6' '7' '8' '9' ':' ';' '<' '=' '>' '?' '@' 'A' 'B' 'C' 'D' 'E' 'F' 'G'\n",
      " 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z'\n",
      " '[' '\\\\' ']' '^' '_' '`' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm'\n",
      " 'n' 'o' 'p' 'q' 's' 't' 'u' 'w' 'x' 'z' '{' '|' '}' '~']\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "print(onehot_encoder.transform(np.ones(1).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1330982, 15, 86)\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "GAAAAATTTTAAAGG AAAAAATTTTAAAGG\n",
      "AAAACTATAGCCCTT AAAACTACAGCCATT\n",
      "GTGGGTTATCAGATT GTGGGTTATCAGATT\n",
      "CTAGTCTTGTTTCTT CTAGTCTTGTTTCTT\n",
      "GTCTTCGGGCTATTT GTTTCTGGGCTATTT\n",
      "TTACCTCTTTGTAAA TTACCTCTTTGTAAA\n",
      "CTGGATCCTGCCATC CTGCATCCTGCCATC\n",
      "TGATGAATTTTGCCA TGATGAATTTTHCCA\n",
      "CAATGATACTTGTGG CAATGATACTTGGGG\n",
      "AACAAGAAGCCAAGT AACAAGAAGCCAATT\n",
      "ATTGTCTCTCCTATT ATTGTCTCTCCTACT\n",
      "AATGTATCTATTGTC AATGTATCTATTGTC\n",
      "AGTTAATTTGAAGGT AGTTAATTTGAAGGT\n",
      "CTCCAACCCCGGAAC CTCCAACCCTGGAAC\n",
      "AAAGTTAGAAGAAGG AAAGTTAGAAGAAGG\n",
      "TTTTTCTCCCCAAAT TTCTGCTCCCNAAAT\n",
      "TAACCAAATTGTGGT TAACCAAATTGTGGT\n",
      "ACATTCATGCAATGG ACATTCATGTAATGG\n",
      "AACACTATTTAGCCA AACACTATTTAGCCA\n",
      "TAGAAAGGAACGAGC TAGAAACGAACAAGC\n",
      "TGACATGAGTGAATC TGACATGAGTGAATC\n",
      "TTGCATGCACATCGC TTGCATGCACATTGC\n",
      "TAAGTGGAAGAAGAC TAAGTGGAAGAAGAC\n",
      "AGTCCGAGGAGGATA AGTCTGAGGAGGATA\n",
      "CACACAGTGACTGAC CACACAGTG--TGAC\n",
      "TTCATTTAATGAGAT CTCATTTAATGAGAC\n",
      "TCTGGAGAAGGCAAA ACTGGAGAAGGC-AA\n",
      "ACTACGCGGATGGGA ACTACACAGATGGGA\n",
      "AGCCATTGGCTCCGT AGCCATTGGCTCCAT\n",
      "GGGGTGGGGGTTTGA GGGGTGGGGGTTTGA\n",
      "AGCATTCCATATGAT AGCATTCCATATGAT\n",
      "ACTTTAATTGCCACT ACTTTAATTGCCACA\n",
      "ATGCATTTGTCAAAA ATGCATTTGTCAAAA\n",
      "CACGCAGAATTTTAC TATGCAGAATTTTAC\n",
      "AGCCAAAAGGATAAA AGCCATATGGTTAGA\n",
      "TCAAATCTATTCAAA GCAA`TCTATTCAAA\n",
      "TTAAATAAAATTATT TTAAATAAAATTACT\n",
      "CAGATGTGGAGTACC C<GATGTGGAGTlCC\n",
      "CAGCACAGAATACAT CAGGACAGAATACAT\n",
      "CATGTGAAAAAGGCA CATGTGAAAAAGACA\n",
      "TGGGAGAGTGAAGGT TGGGAGAGTGAAGG?\n",
      "GGGTAAAACGCTCAC GGTTAAAACATTCAT\n",
      "ACTGGAGAACTTCCA ATTAAAGAACTTCCA\n",
      "CTCAGATGGCAAGAA CTCAGATTGCAAGAA\n",
      "AAGAGAGAGGAGTGG AAGAGAGAGGAATGG\n",
      "AGATGGCAGCGCCAG AGATGGTAGCACAAG\n",
      "TCCCTAAAATAAAAG TCCCTACAATAAAAG\n",
      "CAGATGTTTTGAGAT TAGATGTTTTGAGAT\n",
      "CAGTTGTATTTGTTC CAGTTCTATTTGTTC\n",
      "TGACAAAAATTGAAG TGACAAAAATTAAAG\n",
      "ACAGAAACCAAAGTT ACAGAAACCAAAGTT\n",
      "TAGCCTGAGGCTACA TAGCCTGAGGCAACA\n",
      "ATTGATTTGACAATA ATTAGTTGGGGAATA\n",
      "GGTCAGGGGAACGTA AGCCAGAGGCATATA\n",
      "TGGCATAGACAGATT TGGCATAGACACA-T\n",
      "TTAAACATTTCTCCA TTAAACATTTCTCTC\n",
      "TTATATTAATACAAA --ATATTAATACAAA\n",
      "TACTAAAATTAGGAA TACTAAAATGACATA\n",
      "TAAATTGATTCCAAA TCAATTGATTCCAAA\n",
      "TAAAACAAATGTTTA TAAAACAAATATTTA\n",
      "AAAAGTTTAATAAAT AAACATTTAATGAAT\n",
      "AAACACAGGGATCTA AAACACTGGGGTCTA\n",
      "CAGTAGTAACTGAAG CAGTAGTAGTTAAAG\n",
      "CAGATCTCACAAACA GAGATCTCACAAACA\n",
      "GGTTTGGGTTTTGAA GGTTTGGTTTTTGAA\n",
      "GGTTAGAACTGATGG GGTTAGAAATGATGG\n",
      "CCTAGAGAGAGAGAA TCTAGAgAGACAGAA\n",
      "AGGAGAAATTTCTTG A-GAGGAATATCTTG\n",
      "GGTTCCTTCAGGAAT GGTTCCTTCAGGAAT\n",
      "GTATCTGGCTTTACC ACATCTGGCTTTGCC\n",
      "TCATCTTTGTGTGTT TCATCTTTGTGTGTT\n",
      "TGAACCATGTATATG TGAACTATGCATACG\n",
      "ACAAAAGAAAACAAA GCAGAAGAAAACAAA\n",
      "GGATTTCACAGATTT GGATTTCACAGATTT\n",
      "AAAAAGTCACTGGAT AAAAA-TCACTGGGT\n",
      "TCTCTAAGAAGTCTG TCTCTAAGAAGCCTG\n",
      "GGATTCTACTGCTGG GGATTCTTCTGCTGG\n",
      "AAAAAGAAGTTTGTT AAAAATAAGTTTGTT\n",
      "GAGAAAAAATGAGTT GAG-AAAAATGAGTT\n",
      "GGAGGAGGCTGTTAT GGAGGAGGTTGTTAT\n",
      "TGGAGTGAAGCAGAA TGAAGTGAAGCAGAA\n",
      "TTTTCTTTACTAATC TTGTTTTTACTAATC\n",
      "TGCTTATTACCCACT TGCTTATTACCCACT\n",
      "CTGTAGTGTGGAAAC CTGAAGTGTGGAAAC\n",
      "TTTAAATTATTCATG ---AAATTTTTCATG\n",
      "AACAAGGCTCTCTTA CACAAGGTCATCTTA\n",
      "CTGTTCCTGGAATGC CTGTTACTGGAATGC\n",
      "AATGGAAAGAGAACA AGTGGAAAGAGAACA\n",
      "GACTAGTTTTTCTCC GATTAGTTTTTCTCT\n",
      "CTCAGAACACAACCT CTCAGAACACAACCA\n",
      "CTACAAACGCCCAAC CTAGAAACGTCCTAT\n",
      "CTCAGATGAGATATT GTCAGATGAGATATT\n",
      "GCCTAGTTATTTTCA GCCCAGTTATTTTCA\n",
      "AAAGACAGTGAAAAA AAAGAC--TGAAAAA\n",
      "TGATGGATGTAAATG TCCTGGATGTAAATG\n",
      "TTTGCTGCAAAATAA TTTGCTGCAAAATAA\n",
      "ATATATGCTAGAAAC ATACATGCTAGAAAC\n",
      "AGAAGCATCTGGGTC AGAAGCATCTGGGTC\n",
      "ATAGCTATATTAGAG ACAGCTATATTAGAG\n",
      "CTACCTGTGTTCCCC CTACCTGTGTTCCCC\n"
     ]
    }
   ],
   "source": [
    "def splice(input, pad):\n",
    "    result = []\n",
    "    if pad == False:\n",
    "        for i in range(int(len(input)/seq_length)):\n",
    "            result.append(input[i*seq_length:(i+1)*seq_length])\n",
    "    else :\n",
    "        for i in range(int(len(input)/seq_length)):\n",
    "            result.append(np.concatenate((onehot_encoder.transform(np.ones(1).reshape(-1,1)), \n",
    "                                         input[i*seq_length:(i+1)*seq_length-1]), \n",
    "                                         axis = 0)\n",
    "                         )\n",
    "    return np.array(result)\n",
    "\n",
    "def decoder(input):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    decoded = ''\n",
    "    for i in range(len(input)):\n",
    "        # decoded= decoded+(nucleotide[np.argmax(onehot_encoder.inverse_transform(input[i].reshape(-1, 1)))])\n",
    "        #print(np.argmax(input[i]))\n",
    "        #print(nucleotide)\n",
    "        decoded= decoded+nucleotide[np.argmax(input[i])]\n",
    "    return decoded\n",
    "\n",
    "y = splice(encoded_des, False)\n",
    "X = splice(encoded_anc, False)\n",
    "\n",
    "print(X.shape)\n",
    "print(X)\n",
    "\n",
    "onehot_encoder.transform(np.ones(1).reshape(-1,1))\n",
    "for i in range (100):\n",
    "    print(decoder(X[i]), decoder(y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "# X_train = X[:-300000]\n",
    "# X_test = X[-300000:]\n",
    "# y_train1 = y1[:-300000]\n",
    "# y_test1 = y1[-300000:]\n",
    "# y_train = y[:-300000]\n",
    "# y_test = y[-300000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGACCTAATCACCTC TGACCTTATCGCCTT\n",
      "AAAGGCTGAGTGAGG AAAGGCTGAGTGAAG\n",
      "TGTGCTTTACTGGAC TGTGCATCCCTGGAG\n",
      "TCAATATCTTACATG TCAACATCGTACCTG\n",
      "ATTTATACTTTTCTA ATTTATATGTTTCTA\n",
      "TCAGCCATCTAATAA TCAGCCATCTAATAA\n",
      "TGCTATTACCTGATC TGCTGTTACCTTATC\n",
      "GGTTAAAGAATAACT GGTTAAAGAATAACT\n",
      "ATGGTGGGAGGAGAG ATGGTGGGAGGAGAG\n",
      "TTTATATGAGTGTCA TTTATATGAGTGTCA\n",
      "CCCCTTTATAAAGGA TCCCTTTATAATGGA\n",
      "ATTGGAAAGTAAGTT GTTGTCAAATAATTT\n",
      "CTGGTGTCAAATTCC CTGGTGTAAAACTGC\n",
      "CCTTCTCGGGAGGAA CCTTCTTGGGAGGAA\n",
      "AGGATAAAGGGAAAA AGGATAAAGGGAGAC\n",
      "CAGTCTGGCCTTTCC CAGCTTGGCCTTTGC\n",
      "ATGAAAATAATTAAA ATGAAAACAATAAAA\n",
      "CTTGATATAGCTACA TTTGATATGGCTACA\n",
      "ATGAAATACATCAAA ATGAAATACATCAAA\n",
      "GAAGCCCCCTTTCAT GAAGCCCCCTTTCCT\n",
      "GCAGCCTCAACGGAG ACAGCTTCAACAGAG\n",
      "TGATCCAGTACCACC TGATCCAGTACCACA\n",
      "CCTAGATCTGGTTTT TCTAGATCTGGTTTT\n",
      "CTAAGGTATATAATT CTCAGGTAGATAATT\n",
      "CTTCTAGCTTAGTTT CTTCCAGCTTAGTTT\n",
      "TAAAGAGATTTAAAT TAAAGAGATTTAGAT\n",
      "CAGGAAGGGGAGAAT CAGGAATGGGAGGAT\n",
      "TAAATGGCTTATAAG TAAATGGTTTATG--\n",
      "TTCTGATACTATCTG TTCTGATACTATATG\n",
      "AAAGACCTGGTCAGA AAAGACCTGGTGCCA\n",
      "TTCCCTCCAGTATAT TTCTCATTACTATAT\n",
      "GATAAGAGACATTAT GATAAGAGACATTAT\n",
      "CAAGGCCAGCACGAG CAAGGCCAGCTCCAG\n",
      "AGGGAGAGCTTGATG AGGGAGAGCTTGAGG\n",
      "TCCACTGTAAGCCCT TCTTTTATAAGCCCG\n",
      "CTTTAACGTCCTTTG CTTTAATGTCCTTTG\n",
      "CTGGGTGGTGCTGTG CTGGGTGATGCTGTG\n",
      "AAAAAGTGTCCTTGG --AAAATGTCCTTAG\n",
      "GTGAGACTCTATCTC GTGAGACTTCATCTC\n",
      "CTAAATATATAATTA GTAAATATACCGTTA\n",
      "TTAGGTAGGAGGAAA TTAGGTAGGAGGAAA\n",
      "ATGTTGTTTCTTTTG AGGTTGTTTCTTTTG\n",
      "AAAAAAAGAACCTGG --AAAAAGAACCTGG\n",
      "AGTTTATTTCATTCC AGTTTATTTCATTCC\n",
      "ACACCATGCCACCAG ACAGCATGCCATCAG\n",
      "ACAATAGACCATGCC ACAATAGACCATGCC\n",
      "AAATCACAAAAATTT AAAGCACAAAAATTT\n",
      "GATCCTAAACAATGT GACCTTAAACAATGC\n",
      "TGGCTGTATAGTAGT TGGCTGTATAATAAT\n",
      "AGTCTCCTAATTTGG AGCCTCCTAGTTTGG\n",
      "AGACTTTTTCTTCTT AGACTTTTTCTTCTT\n",
      "GCCCGGGTCTGCGGA GCCCGAGTCT-----\n",
      "AGGTTAAATAATATG AGTTTAAATAATATG\n",
      "AAACTTGAATATGAG AAAC-----TATGAG\n",
      "TCTTCCTTTTATTAT TTTTCCTTTTATT.T\n",
      "CCCTGTCCCCCCTGA CCCTGGTCCCTCTGA\n",
      "TTTATGGTTAATGCT TTTATGGTTAATGCT\n",
      "TTAACAGTGTACCTG TTAACAGTGTACCTG\n",
      "GCCATGCGCGTAACA GCCATGTGCATAGCA\n",
      "AGGGTCTGCCTTCCT AGGGTTTGCTGTCCT\n",
      "GCCTGAGGTCCTTTT GCCTGAGGTCCTTCT\n",
      "TTATTGTATGATGGG TTATTGTATGATGGG\n",
      "GTCTCAGGATCTACC GTCTCAGGATCTACC\n",
      "TTCTCACTGACAACA TTCTCACCACCAACA\n",
      "TCAGCCAGAGGGAAC TCAGCCAGAGGGAAC\n",
      "TCAAAGCGTTCAAAG TCAAAGTGTTCAAAG\n",
      "GAATTCAGGCCAGTG GAATTCAAGCCAGCA\n",
      "TTCCCTGCCACAGAA TTCCCTGCCACAGAA\n",
      "GTGCTCAGCAAACGG GTGCCCAACCAATGG\n",
      "CCCAACCCACCTGAC CCCAACCCACCTGAC\n",
      "CCAGTTCCTGCGGGC CCAGTTCCTACAGGC\n",
      "CTTACTCACGTGCAG CTTACTTATGTGCAG\n",
      "TCTGTTGTTTACAAG TCTATTGTTTACAAG\n",
      "GGGGGGTGCTGGCAC GGGGoGTGCTGGGAC\n",
      "ACCATCATAATCATT ACCATCATAATCATT\n",
      "GCTAAGCATGTGTTT GTTAAACATGTGTTT\n",
      "ACAACAGACATATGA ACAAGAGACATATGA\n",
      "AGGTCTGAGGGCTGC AGGTCTGAGGGCTGC\n",
      "GAGGCATAAAATCAA GAGGCATAAAATCAA\n",
      "TTCCCCAGATGCCTT TTCCCCAGATGCCTT\n",
      "TAGAAGTTTAATAAA TAAAACTTTAAT-AA\n",
      "TGCTCTGCTAACAGA TGCTCTGCTCATGGG\n",
      "ATTCTGGCTCCACCA ATTGTGGTTCCACCA\n",
      "CAAGAATGTTTAATA CAAGAATGTTTAATG\n",
      "AAGTGGAGAGGTGGG AAGTGGAGAGGTGGG\n",
      "TTTGAGTCAAATGAG TTTGAGTCAAATGAG\n",
      "CTGCACACACTAACA CTGCACGCACTAATA\n",
      "GCGGAAGCTGCTCCG GCAGAAGCTGCTCCA\n",
      "GAATTTATCCTGCTT GAATTTATCCTGCTT\n",
      "ATGTCAGACTCTGAG ATGAAGCACCCTGAG\n",
      "ATCTAGGCCGGAGGC ATCTAGG-CGGAGAC\n",
      "GGAAAGAATGACTGA GGAAAGAATGATGGA\n",
      "TGACCCCTAGCAGGA TGAGCCCCAACAGGA\n",
      "TCTAGGCATTTCATG TCTAGGCATCTCATG\n",
      "AATCAGTACTGTATT AATGTATACTGTATC\n",
      "CCTCTGCCCAGCCCT CCTCCGCCCAGCCCT\n",
      "GCGGGACATCGCATG GCAGGACATCACATG\n",
      "CATGGTGGTTCTTTG CATGGCAGCTCTTTG\n",
      "CTGCCCTGGACGCCG --GCCCTGTACTTAA\n",
      "CCTCGCCTGGGCTCC TCTCGCCTGGACTC-\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder.transform(np.ones(1).reshape(-1,1))\n",
    "for i in range (100):\n",
    "    print(decoder(X_train[i]), decoder(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHitMiss(a,b):\n",
    "    if a==b:\n",
    "        return 'Hit'\n",
    "    else:\n",
    "        return 'Miss'\n",
    "def accuracy(a, b):\n",
    "    count = 0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == b[i]:\n",
    "            count = count+1\n",
    "    return count/len(a)\n",
    "\n",
    "def accuracy2(a, b, c):\n",
    "    count = 0\n",
    "    count2 =0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != c[i]:\n",
    "            count2 = count2 +1\n",
    "        if a[i] != c[i] and b[i]==c[i]:\n",
    "            count = count+1\n",
    "    return count/count2\n",
    "\n",
    "def isMutation(a, b):\n",
    "    if a!= b:\n",
    "        print(\"mutation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1064785, 15, 86)\n",
      "Train on 851828 samples, validate on 212957 samples\n",
      "851828/851828 [==============================] - 73s 86us/sample - loss: 0.5799 - accuracy: 0.8581 - val_loss: 0.5389 - val_accuracy: 0.8706\n",
      "Train on 851828 samples, validate on 212957 samples\n",
      "Epoch 1/2\n",
      "851828/851828 [==============================] - 72s 85us/sample - loss: 0.5801 - accuracy: 0.8577 - val_loss: 0.5390 - val_accuracy: 0.8706\n",
      "Epoch 2/2\n",
      "851828/851828 [==============================] - 67s 79us/sample - loss: 0.5383 - accuracy: 0.8706 - val_loss: 0.5390 - val_accuracy: 0.8706\n",
      "Train on 851828 samples, validate on 212957 samples\n",
      "Epoch 1/10\n",
      "851828/851828 [==============================] - 71s 83us/sample - loss: 0.5825 - accuracy: 0.8577 - val_loss: 0.5397 - val_accuracy: 0.8706\n",
      "Epoch 2/10\n",
      "851828/851828 [==============================] - 67s 78us/sample - loss: 0.5385 - accuracy: 0.8706 - val_loss: 0.5386 - val_accuracy: 0.8706\n",
      "Epoch 3/10\n",
      "851828/851828 [==============================] - 66s 78us/sample - loss: 0.5378 - accuracy: 0.8707 - val_loss: 0.5374 - val_accuracy: 0.8706\n",
      "Epoch 4/10\n",
      "851828/851828 [==============================] - 66s 78us/sample - loss: 0.5375 - accuracy: 0.8706 - val_loss: 0.5375 - val_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "851828/851828 [==============================] - 67s 78us/sample - loss: 0.5373 - accuracy: 0.8706 - val_loss: 0.5373 - val_accuracy: 0.8706\n",
      "Epoch 6/10\n",
      "851828/851828 [==============================] - 66s 78us/sample - loss: 0.5371 - accuracy: 0.8706 - val_loss: 0.5372 - val_accuracy: 0.8706\n",
      "Epoch 7/10\n",
      "851828/851828 [==============================] - 67s 78us/sample - loss: 0.5370 - accuracy: 0.8706 - val_loss: 0.5375 - val_accuracy: 0.8706\n",
      "Epoch 8/10\n",
      "851828/851828 [==============================] - 66s 78us/sample - loss: 0.5369 - accuracy: 0.8706 - val_loss: 0.5380 - val_accuracy: 0.8706\n",
      "Epoch 9/10\n",
      "851828/851828 [==============================] - 66s 78us/sample - loss: 0.5368 - accuracy: 0.8706 - val_loss: 0.5374 - val_accuracy: 0.8706\n",
      "Epoch 10/10\n",
      "851828/851828 [==============================] - 66s 77us/sample - loss: 0.5367 - accuracy: 0.8706 - val_loss: 0.5382 - val_accuracy: 0.8706\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train.shape)\n",
    "def lstm_model(latent_dim, half):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(half, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.LSTM(half, return_sequences=True))\n",
    "    \n",
    "    model.add(layers.Dense(encode_dimension, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "                  )\n",
    "\n",
    "#     model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def modelFit(epoch, batchSize, latent_dim, half, X_train, y_train):\n",
    "    model1 = lstm_model(latent_dim, half)\n",
    "    hist1 = model1.fit(X_train, y_train,\n",
    "          batch_size=batchSize,\n",
    "          epochs=epoch,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1\n",
    "         )\n",
    "    return hist1, model1\n",
    "\n",
    "def grid_search(latent, half,train_size, X_train, y_train):\n",
    "    hist1, model1 = modelFit(1, 256, latent, half, X_train, y_train)\n",
    "    hist2 ,model2 = modelFit(2, 256, latent, half, X_train, y_train)\n",
    "    hist3 ,model3 = modelFit(10, 256, latent, half, X_train, y_train)\n",
    "    #hist4 ,model4, encoder_model4, decoder_model4 = modelFit(30, 1000, latent, half, X_train, y_train)\n",
    "    #hist5 ,model5, encoder_model5, decoder_model5 = modelFit(50, 100, latent, half, X_train, y_train)\n",
    "    #hist6 ,model6, encoder_model6, decoder_model6 = modelFit(80, 100, latent, half, X_train, y_train)\n",
    "    #hist7 ,model7, encoder_model7, decoder_model7 = modelFit(100, 100, latent, half, X_train, y_train)\n",
    "    #hist8 ,model8, encoder_model8, decoder_model8 = modelFit(500, 100, latent, half)\n",
    "\n",
    "    model1.save(\"models/{}_{}_{}_{}_{}_1.h5\".format(modelName,ancName, desName,train_size,half))\n",
    "    model2.save(\"models/{}_{}_{}_{}_{}_2.h5\".format(modelName,ancName, desName,train_size,half))\n",
    "    model3.save(\"models/{}_{}_{}_{}_{}_10.h5\".format(modelName,ancName, desName,train_size,half))\n",
    "    #model4.save(\"models/{}_{}_{}_30_double.h5\".format(train_size,half))\n",
    "    #model5.save(\"models/_gap_hg38_{}_{}_50_double.h5\".format(train_size,half))\n",
    "    #model6.save(\"models/_gap_hg38_{}_{}_80_double.h5\".format(train_size,half))\n",
    "    #model7.save(\"models/_gap_hg38_{}_{}_100_double.h5\".format(train_size,half))\n",
    "    #model8.save(\"_gap_hg38_{}_{}_500.h5\".format(train_size,half))\n",
    "\n",
    "\n",
    "# grid_search(2, 1, 000, X_train, y_train, y_train1)\n",
    "# grid_search(16, 8, 000, X_train, y_train, y_train1)        \n",
    "# grid_search(32, 16, 000, X_train, y_train, y_train1)\n",
    "# grid_search(64, 32, 000, X_train, y_train, y_train1)\n",
    "# grid_search(128, 64, 000, X_train, y_train, y_train1)\n",
    "# grid_search(256, 128, 000, X_train, y_train, y_train1)\n",
    "# grid_search(512, 256, 000, X_train, y_train, y_train1)\n",
    "# grid_search(1024, 512, 000, X_train, y_train)\n",
    "#grid_search(8192, 4096, 000, X_train, y_train, y_train1)\n",
    "\n",
    "with open('loss_hist.txt', 'wb') as fp:\n",
    "    pickle.dump(val_loss_hist, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '$', '%', '&', '(', ')', '*', '+', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'AC', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'CA', 'AA', 'R', 'S', 'T', 'U', 'TG', 'TA', 'X', 'AG', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'GT', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'TT', 'CG', 'n', 'o', 'CT', 'q', 's', 't', 'AT', 'GA', 'GC', 'z', '{', '|', '}', '~']\n",
      "Anc : _HPGPNRMPCCSO, Des : hg38, Train size = 0, hidden_size = 512, epoch = 10\n",
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n",
      "(100000, 15, 86)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2224d5fb5f74127aef1e225cfea667d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%precision 2\n",
    "seq_length = 11\n",
    "test_size = len(y_test)\n",
    "val_size = 30000\n",
    "\n",
    "key = list(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "\n",
    "mapDict = np.load('mut_dict.npy', allow_pickle = True).item()\n",
    "\n",
    "rev_dict = {v: k for k, v in mapDict.items()}\n",
    "#print(rev_dict.keys())\n",
    "rev_key = []\n",
    "for item in key:\n",
    "    #print(item)\n",
    "    if item in list(rev_dict.keys()):\n",
    "        rev_key.append(rev_dict[item])\n",
    "        #print('hi')\n",
    "    else :\n",
    "        rev_key.append(item)\n",
    "print(rev_key)\n",
    "\n",
    "nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "\n",
    "def printHitMiss(a,b):\n",
    "    if a==b:\n",
    "        return 'Hit'\n",
    "    else:\n",
    "        return 'Miss'\n",
    "    \n",
    "def accuracy(a, b):\n",
    "    count = 0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == b[i]:\n",
    "            count = count+1\n",
    "    return count/len(a)\n",
    "\n",
    "def accuracy2(a, b, c):\n",
    "    count = 0\n",
    "    count2 =0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != c[i]:\n",
    "            count2 = count2 +1\n",
    "        if a[i] != c[i] and b[i]==c[i]:\n",
    "            count = count+1\n",
    "    return count/count2\n",
    "\n",
    "def isMutation(a, b):\n",
    "    if a!= b:\n",
    "        print(\"mutation\")\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq, model):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    # Encode the input as state vectors.\n",
    "    #print(input_seq[0,0])\n",
    "    index = 0\n",
    "#     states_value = model.predict(input_seq)\n",
    "#     target_seq = np.zeros((1, 1, encode_dimension*2))\n",
    "#     target_seq[0][0]= np.hstack((input_seq[0,index], onehot_encoder.transform(np.ones(1).reshape(-1,1))[0]))\n",
    "    stop_condition = False\n",
    "    decoded_seq = ''\n",
    "    probability = 1\n",
    "    \n",
    "    predicted = model.predict(input_seq)\n",
    "    while not stop_condition:\n",
    "        index = index +1\n",
    "#         print([input_seq[index-1]])\n",
    "        output_tokens = predicted[0][index-1]\n",
    "#        sampled_token_index = np.random.choice(encode_dimension, 1, p=output_tokens)[0]\n",
    "        sampled_nucleotide = nucleotide[np.random.choice(encode_dimension, 1, p=output_tokens)[0]]\n",
    "        \n",
    "        decoded_seq += sampled_nucleotide\n",
    "        if (len(decoded_seq) == seq_length):\n",
    "            break\n",
    "\n",
    "    return decoded_seq\n",
    "\n",
    "def get_prob(input_seq, target, model):\n",
    "    # Encode the input as state vectors.\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    index = 0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_seq = ''\n",
    "    probability = []\n",
    "    predicted = model.predict(input_seq)\n",
    "    \n",
    "    while not stop_condition:\n",
    "        index = index +1\n",
    "        output_tokens = predicted[0][index-1]\n",
    "        sampled_token_index = np.argmax(target[index-1])\n",
    "          \n",
    "        probability.append(output_tokens[sampled_token_index])\n",
    "        sampled_nucleotide = nucleotide[np.random.choice(encode_dimension, 1, p=output_tokens)[0]]\n",
    "        \n",
    "        decoded_seq += sampled_nucleotide\n",
    "        if (len(decoded_seq) == seq_length):\n",
    "            break\n",
    "\n",
    "\n",
    "    return decoded_seq, probability\n",
    "\n",
    "def diffList(a, b):\n",
    "    count = 0\n",
    "    length = len(a)\n",
    "    for i in range(length):\n",
    "        if a[i] != b[i]:\n",
    "            count = count+1\n",
    "    return count\n",
    "\n",
    "def decoder(input):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    decoded = ''\n",
    "    for i in range(len(input)):\n",
    "        # decoded= decoded+(nucleotide[np.argmax(onehot_encoder.inverse_transform(input[i].reshape(-1, 1)))])\n",
    "        #print(np.argmax(input[i]))\n",
    "        #print(nucleotide)\n",
    "        decoded= decoded+nucleotide[np.argmax(input[i])]\n",
    "    return decoded\n",
    "\n",
    "#for seq_index in range(1):\n",
    "def predict2(X_test, y_test, model, gru=False):\n",
    "    print(X_test.shape)\n",
    "    x_true =[]\n",
    "    y_hat =[]\n",
    "    y_true =[]\n",
    "    probList=[]\n",
    "    generator_output = []\n",
    "    productProb = [0]*seq_length\n",
    "\n",
    "    for seq_index in notebook.tqdm(range(len(X_test))):\n",
    "        input_seq = X_test[seq_index: seq_index + 1]\n",
    "#         if gru:\n",
    "#             decoded_sentence = decode_gru(input_seq, model)\n",
    "#         else :\n",
    "#             decoded_sentence = decode_sequence(input_seq, model)\n",
    "        decoded_sentence, prob = get_prob(input_seq, y_test[seq_index], model)\n",
    "        prob = [math.log(x) for x in prob]\n",
    "        productProb = [sum(x) for x in zip(productProb, prob)]\n",
    "        input_sen = decoder(input_seq[0])\n",
    "#         inputAll = inputAll + input_sen\n",
    "#         predAll = predAll + decoded_sentence\n",
    "#         outputAll = outputAll + decoder(y_test[seq_index])\n",
    "#         print(input_sen, ' -> ',\n",
    "#               decoded_sentence, 'True:', decoder(y_test[seq_index]), \n",
    "#               printHitMiss(decoded_sentence, decoder(y_test[seq_index]))\n",
    "#               #diffList(input_sen, decoded_sentence)\n",
    "#              )\n",
    "#         print(input_sen, ' -> ',\n",
    "#               decoder(y_test[seq_index]), 'True:', decoder(y_test[seq_index]), \n",
    "#               prob,\n",
    "#               printHitMiss(decoded_sentence, decoder(y_test[seq_index]))\n",
    "#               #diffList(input_sen, decoded_sentence)\n",
    "#              )\n",
    "        x_true.append(input_sen)\n",
    "        y_hat.append(decoded_sentence)\n",
    "        y_true.append(decoder(y_test[seq_index]))\n",
    "    #generator_output.append(input_sen+decoded_seq)\n",
    "    print(productProb)\n",
    "    productProb = [x/test_size for x in productProb]\n",
    "    print(\"Sum of log probabilities : {}\".format(productProb))\n",
    "    print(\"Percentage of target and prediction being identical: {}\".format(accuracy(y_hat, y_true)))\n",
    "    print(\"Percentage of training and prediction being identical: {}\".format(accuracy(y_hat, x_true)))\n",
    "    print(\"Accuracy given mutation happened : {}\".format(accuracy2(x_true, y_hat, y_true)))\n",
    "    #np.save('data/hg38_output.npy', generator_output)\n",
    "    \n",
    "    return x_true, y_hat, y_true\n",
    "\n",
    "def grid_predict(train_size, half, epoch, X_test, y_test):\n",
    "    model1 = tf.keras.models.load_model(\"models/{}_{}_{}_{}_{}_{}.h5\".format(modelName, ancName, desName,train_size,half,epoch))\n",
    "\n",
    "   \n",
    "\n",
    "    inputAll, predAll, outputAll = predict2(X_test, y_test, model1, gru=False)\n",
    "    \n",
    "    return inputAll, predAll, outputAll\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "def concat(input1, input2):\n",
    "    result = []\n",
    "    for x, y in zip(input1, input2):\n",
    "        result.append(np.hstack((x, y)))\n",
    "    \n",
    "    return np.array(result)\n",
    "\n",
    "# def get_data(trainInd, valInd, testInd):\n",
    "#     X_train=np.load('prepData/X_train_gap_hg38_v3_chr2_size10.npy')[:trainInd]\n",
    "#     X_val=np.load('prepData/X_val_gap_hg38_v3_chr2_size10.npy')[:valInd]\n",
    "#     X_test=np.load('prepData/X_test_gap_hg38_v3_chr2_size10.npy')[:testInd]\n",
    "#     y_train=np.load('prepData/y_train_gap_hg38_v3_chr2_size10.npy')[:trainInd]\n",
    "#     y_val=np.load('prepData/y_val_gap_hg38_v3_chr2_size10.npy')[:valInd]\n",
    "#     y_test=np.load('prepData/y_test_gap_hg38_v3_chr2_size10.npy')[:testInd]\n",
    "\n",
    "#     y_train1 = np.load('prepData/y_train1_gap_hg38_v3_chr2_size10.npy')[:trainInd]\n",
    "#     y_val1 = np.load('prepData/y_val1_gap_hg38_v3_chr2_size10.npy')[:valInd]\n",
    "#     y_test1 = np.load('prepData/y_test1_gap_hg38_v3_chr2_size10.npy')[:testInd]\n",
    "\n",
    "#     y_train1 = concat(X_train, y_train1)\n",
    "#     y_val1 = concat(X_val, y_val1)\n",
    "#     y_test1 = concat(X_test, y_test1)\n",
    "#     return X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "# hidden = [16, 32, 64,128,256,512]\n",
    "# epoch = [10, 10, 2, 2, 2, 1]\n",
    "hidden = [512]\n",
    "epoch = [10]\n",
    "#X_test, y_test = get_data(train_size, val_size, test_size)\n",
    "for h, e in zip(hidden, epoch):\n",
    "    print(\"Anc : {}, Des : {}, Train size = {}, hidden_size = {}, epoch = {}\".format(ancName, desName, train_size, h, e))\n",
    "    inputAll, predAll, outputAll = grid_predict(train_size, h, e, X_test[-100000:], y_test[-100000:])\n",
    "    print(\"The end of Anc : {}, Des : {}, Train size = {}, hidden_size = {}, epoch = {}\".format(ancName, desName,train_size, h, e))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# mapDict = {'A': 'A', 'C': 'C', 'G': 'G', 'T': 'T', '-': '-', 'AA': 'O', 'AC': 'h', '0': '0',\n",
    "#        'AT': 'b', 'AG': 'V', 'CA': 'r', 'CC': 'p', 'CT': 'o', 'CG': 'i', 'TA': 'g', \n",
    "#        'TC': 'I', 'TT': 'f', 'TG': 'L', 'GA': 'B', 'GC': 'c', 'GT': 'X', 'GG': 'P'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def contextMut(size, ancNuc, desNuc, anc, des):\n",
    "    cont = list(itertools.product('ACGT-', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont:\n",
    "        for j in cont:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(seq_length-size*2):\n",
    "            if a[i+size] == ancNuc :\n",
    "                count_dict[(a[i:i+size*2+1])] += 1\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(seq_length-size*2):\n",
    "            if a[i+size] == ancNuc and b[i+size] == desNuc:\n",
    "                context_dict[(a[i:i+size*2+1])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    sorted_context = dict(sorted_context)\n",
    "    return sorted_context\n",
    "\n",
    "# pred_contextAG = contextMut(contextLen, 'A', 'G', inputAll, predAll)\n",
    "# true_contextAG = contextMut(contextLen, 'A', 'G', inputAll, outputAll)\n",
    "# pred_contextCT = contextMut(contextLen, 'C', 'T', inputAll, predAll)\n",
    "# true_contextCT = contextMut(contextLen, 'C', 'T', inputAll, outputAll)\n",
    "# print(pred_context)\n",
    "# print(true_context)\n",
    "    \n",
    "# for i in range(100):\n",
    "#     print(pred_context[i], true_context[i])\n",
    "\n",
    "def plotPointMut(n_groups, predSeq, trueSeq, ancNuc, desNuc):\n",
    "    true = list(trueSeq.values())[:n_groups]\n",
    "    true_context = list(trueSeq.keys())[:n_groups]\n",
    "    pred = []\n",
    "    for i in true_context:\n",
    "        pred.append(predSeq[i])\n",
    "    \n",
    "\n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.05\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, pred, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='b',\n",
    "    label='pred')\n",
    "\n",
    "    rects2 = plt.bar(index + bar_width, true, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='g',\n",
    "    label='true')\n",
    "\n",
    "    plt.xlabel('context')\n",
    "    plt.ylabel('number')\n",
    "    plt.title('{} to {} point mutation'.format(ancNuc, desNuc))\n",
    "    plt.xticks(index + bar_width, list(trueSeq.values())[:n_groups])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "contextLen = 2\n",
    "numBin = 40\n",
    "# np.save('inputAll_{}_{}_{}'.format(modelName, ancName, desName), inputAll)\n",
    "# np.save('predAll_{}_{}_{}'.format(modelName, ancName, desName), predAll)\n",
    "# np.save('outputAll_{}_{}_{}'.format(modelName, ancName, desName), outputAll)\n",
    "\n",
    "inputAll = np.load('inputAll_lstm__HPGPNRMPC_hg38.npy')\n",
    "predAll = np.load('predAll_lstm__HPGPNRMPC_hg38.npy')\n",
    "outputAll = np.load('outputAll_lstm__HPGPNRMPC_hg38.npy')\n",
    "\n",
    "pred_contextAG = contextMut(contextLen, 'A', 'G', inputAll, predAll)\n",
    "true_contextAG = contextMut(contextLen, 'A', 'G', inputAll, outputAll)\n",
    "pred_contextAT = contextMut(contextLen, 'A', 'T', inputAll, predAll)\n",
    "true_contextAT = contextMut(contextLen, 'A', 'T', inputAll, outputAll)\n",
    "pred_contextAC = contextMut(contextLen, 'A', 'C', inputAll, predAll)\n",
    "true_contextAC = contextMut(contextLen, 'A', 'C', inputAll, outputAll)\n",
    "pred_contextCT = contextMut(contextLen, 'C', 'T', inputAll, predAll)\n",
    "true_contextCT = contextMut(contextLen, 'C', 'T', inputAll, outputAll)\n",
    "pred_contextCG = contextMut(contextLen, 'C', 'G', inputAll, predAll)\n",
    "true_contextCG = contextMut(contextLen, 'C', 'G', inputAll, outputAll)\n",
    "pred_contextCA = contextMut(contextLen, 'C', 'A', inputAll, predAll)\n",
    "true_contextCA = contextMut(contextLen, 'C', 'A', inputAll, outputAll)\n",
    "pred_contextGA = contextMut(contextLen, 'G', 'A', inputAll, predAll)\n",
    "true_contextGA = contextMut(contextLen, 'G', 'A', inputAll, outputAll)\n",
    "pred_contextGT = contextMut(contextLen, 'G', 'T', inputAll, predAll)\n",
    "true_contextGT = contextMut(contextLen, 'G', 'T', inputAll, outputAll)\n",
    "pred_contextGC = contextMut(contextLen, 'G', 'C', inputAll, predAll)\n",
    "true_contextGC = contextMut(contextLen, 'G', 'C', inputAll, outputAll)\n",
    "pred_contextTA = contextMut(contextLen, 'T', 'A', inputAll, predAll)\n",
    "true_contextTA = contextMut(contextLen, 'T', 'A', inputAll, outputAll)\n",
    "pred_contextTC = contextMut(contextLen, 'T', 'C', inputAll, predAll)\n",
    "true_contextTC = contextMut(contextLen, 'T', 'C', inputAll, outputAll)\n",
    "pred_contextTG = contextMut(contextLen, 'T', 'G', inputAll, predAll)\n",
    "true_contextTG = contextMut(contextLen, 'T', 'G', inputAll, outputAll)\n",
    "true_contextAgap = contextMut(contextLen, 'A', '-', inputAll, outputAll)\n",
    "pred_contextAgap = contextMut(contextLen, 'A', '-', inputAll, predAll)\n",
    "true_contextCgap = contextMut(contextLen, 'C', '-', inputAll, outputAll)\n",
    "pred_contextCgap = contextMut(contextLen, 'C', '-', inputAll, predAll)\n",
    "true_contextGgap = contextMut(contextLen, 'G', '-', inputAll, outputAll)\n",
    "pred_contextGgap = contextMut(contextLen, 'G', '-', inputAll, predAll)\n",
    "true_contextTgap = contextMut(contextLen, 'T', '-', inputAll, outputAll)\n",
    "pred_contextTgap = contextMut(contextLen, 'T', '-', inputAll, predAll)\n",
    "# print(pred_context)\n",
    "# print(true_context)\n",
    "    \n",
    "plotPointMut(numBin, pred_contextAG, true_contextAG, 'A','G')\n",
    "plotPointMut(numBin, pred_contextAT, true_contextAT, 'A','T')\n",
    "plotPointMut(numBin, pred_contextAC, true_contextAC, 'A','C')\n",
    "plotPointMut(numBin, pred_contextCT, true_contextCT, 'C','T')\n",
    "plotPointMut(numBin, pred_contextCA, true_contextCA, 'C','A')\n",
    "plotPointMut(numBin, pred_contextCG, true_contextCG, 'C','G')\n",
    "plotPointMut(numBin, pred_contextGA, true_contextGA, 'G','A')\n",
    "plotPointMut(numBin, pred_contextGT, true_contextGT, 'G','T')\n",
    "plotPointMut(numBin, pred_contextGC, true_contextGC, 'G','C')\n",
    "plotPointMut(numBin, pred_contextTC, true_contextTC, 'T','C')\n",
    "plotPointMut(numBin, pred_contextTA, true_contextTA, 'T','A')\n",
    "plotPointMut(numBin, pred_contextTG, true_contextTG, 'T','G')\n",
    "plotPointMut(numBin, pred_contextAgap, true_contextAgap, 'A','-')\n",
    "plotPointMut(numBin, pred_contextCgap, true_contextCgap, 'C','-')\n",
    "plotPointMut(numBin, pred_contextGgap, true_contextGgap, 'G','-')\n",
    "plotPointMut(numBin, pred_contextTgap, true_contextTgap, 'T','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def freqCases(mutList):\n",
    "#     sum = 0\n",
    "#     for item in mutList:\n",
    "#         sum += item[1]\n",
    "#     print(sum)\n",
    "\n",
    "# freqCases(pred_contextAG)\n",
    "# freqCases(pred_contextAgap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScatter(n_groups, predSeq, trueSeq, ancNuc, desNuc):\n",
    "    true = list(trueSeq.values())[:n_groups]\n",
    "    true_context = list(trueSeq.keys())[:n_groups]\n",
    "    pred = []\n",
    "    for i in true_context:\n",
    "        pred.append(predSeq[i])\n",
    "\n",
    "    \n",
    "    plt.scatter(pred, true, color = 'm')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.axis('scaled')\n",
    "    plt.axis('square')\n",
    "    plt.title('{} to {} point mutation'.format(ancNuc, desNuc))\n",
    "    plt.savefig('figures/scatter_{}_{}_{}_{}_{}->{}.png'.format(ancName, desName, train_size, seq_length, ancNuc, desNuc))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "plotScatter(numBin, pred_contextAG, true_contextAG, 'A','G')\n",
    "plotScatter(numBin, pred_contextAT, true_contextAT, 'A','T')\n",
    "plotScatter(numBin, pred_contextAC, true_contextAC, 'A','C')\n",
    "plotScatter(numBin, pred_contextCT, true_contextCT, 'C','T')\n",
    "plotScatter(numBin, pred_contextCA, true_contextCA, 'C','A')\n",
    "plotScatter(numBin, pred_contextCG, true_contextCG, 'C','G')\n",
    "plotScatter(numBin, pred_contextGA, true_contextGA, 'G','A')\n",
    "plotScatter(numBin, pred_contextGT, true_contextGT, 'G','T')\n",
    "plotScatter(numBin, pred_contextGC, true_contextGC, 'G','C')\n",
    "plotScatter(numBin, pred_contextTC, true_contextTC, 'T','C')\n",
    "plotScatter(numBin, pred_contextTA, true_contextTA, 'T','A')\n",
    "plotScatter(numBin, pred_contextTG, true_contextTG, 'T','G')\n",
    "plotScatter(numBin, pred_contextAgap, true_contextAgap, 'A','-')\n",
    "plotScatter(numBin, pred_contextCgap, true_contextCgap, 'C','-')\n",
    "plotScatter(numBin, pred_contextGgap, true_contextGgap, 'G','-')\n",
    "plotScatter(numBin, pred_contextTgap, true_contextTgap, 'T','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newInputAll = ''\n",
    "# newOutputAll = ''\n",
    "# for i in range(len(inputAll)):\n",
    "#     newInputAll =+ \n",
    "    \n",
    "contextLen = 2\n",
    "numBin = 20\n",
    "\n",
    "pred_contextAG = contextMut(contextLen, 'A', 'G', inputAll, predAll)\n",
    "true_contextAG = contextMut(contextLen, 'A', 'G', inputAll, outputAll)\n",
    "pred_contextAT = contextMut(contextLen, 'A', 'T', inputAll, predAll)\n",
    "true_contextAT = contextMut(contextLen, 'A', 'T', inputAll, outputAll)\n",
    "pred_contextAC = contextMut(contextLen, 'A', 'C', inputAll, predAll)\n",
    "true_contextAC = contextMut(contextLen, 'A', 'C', inputAll, outputAll)\n",
    "pred_contextCT = contextMut(contextLen, 'C', 'T', inputAll, predAll)\n",
    "true_contextCT = contextMut(contextLen, 'C', 'T', inputAll, outputAll)\n",
    "pred_contextCG = contextMut(contextLen, 'C', 'G', inputAll, predAll)\n",
    "true_contextCG = contextMut(contextLen, 'C', 'G', inputAll, outputAll)\n",
    "pred_contextCA = contextMut(contextLen, 'C', 'A', inputAll, predAll)\n",
    "true_contextCA = contextMut(contextLen, 'C', 'A', inputAll, outputAll)\n",
    "pred_contextGA = contextMut(contextLen, 'G', 'A', inputAll, predAll)\n",
    "true_contextGA = contextMut(contextLen, 'G', 'A', inputAll, outputAll)\n",
    "pred_contextGT = contextMut(contextLen, 'G', 'T', inputAll, predAll)\n",
    "true_contextGT = contextMut(contextLen, 'G', 'T', inputAll, outputAll)\n",
    "pred_contextGC = contextMut(contextLen, 'G', 'C', inputAll, predAll)\n",
    "true_contextGC = contextMut(contextLen, 'G', 'C', inputAll, outputAll)\n",
    "pred_contextTA = contextMut(contextLen, 'T', 'A', inputAll, predAll)\n",
    "true_contextTA = contextMut(contextLen, 'T', 'A', inputAll, outputAll)\n",
    "pred_contextTC = contextMut(contextLen, 'T', 'C', inputAll, predAll)\n",
    "true_contextTC = contextMut(contextLen, 'T', 'C', inputAll, outputAll)\n",
    "pred_contextTG = contextMut(contextLen, 'T', 'G', inputAll, predAll)\n",
    "true_contextTG = contextMut(contextLen, 'T', 'G', inputAll, outputAll)\n",
    "true_contextAgap = contextMut(contextLen, 'A', '-', inputAll, outputAll)\n",
    "pred_contextAgap = contextMut(contextLen, 'A', '-', inputAll, predAll)\n",
    "true_contextCgap = contextMut(contextLen, 'C', '-', inputAll, outputAll)\n",
    "pred_contextCgap = contextMut(contextLen, 'C', '-', inputAll, predAll)\n",
    "true_contextGgap = contextMut(contextLen, 'G', '-', inputAll, outputAll)\n",
    "pred_contextGgap = contextMut(contextLen, 'G', '-', inputAll, predAll)\n",
    "true_contextTgap = contextMut(contextLen, 'T', '-', inputAll, outputAll)\n",
    "pred_contextTgap = contextMut(contextLen, 'T', '-', inputAll, predAll)\n",
    "# print(pred_context)\n",
    "# print(true_context)\n",
    "    \n",
    "plotPointMut(numBin, pred_contextAG, true_contextAG, 'A','G')\n",
    "plotPointMut(numBin, pred_contextAT, true_contextAT, 'A','T')\n",
    "plotPointMut(numBin, pred_contextAC, true_contextAC, 'A','C')\n",
    "plotPointMut(numBin, pred_contextCT, true_contextCT, 'C','T')\n",
    "plotPointMut(numBin, pred_contextCA, true_contextCA, 'C','A')\n",
    "plotPointMut(numBin, pred_contextCG, true_contextCG, 'C','G')\n",
    "plotPointMut(numBin, pred_contextGA, true_contextGA, 'G','A')\n",
    "plotPointMut(numBin, pred_contextGT, true_contextGT, 'G','T')\n",
    "plotPointMut(numBin, pred_contextGC, true_contextGC, 'G','C')\n",
    "plotPointMut(numBin, pred_contextTC, true_contextTC, 'T','C')\n",
    "plotPointMut(numBin, pred_contextTA, true_contextTA, 'T','A')\n",
    "plotPointMut(numBin, pred_contextTG, true_contextTG, 'T','G')\n",
    "plotPointMut(numBin, pred_contextAgap, true_contextAgap, 'A','-')\n",
    "plotPointMut(numBin, pred_contextCgap, true_contextCgap, 'C','-')\n",
    "plotPointMut(numBin, pred_contextGgap, true_contextGgap, 'G','-')\n",
    "plotPointMut(numBin, pred_contextTgap, true_contextTgap, 'T','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder.transform(np.ones(1).reshape(-1,1))\n",
    "for i in range (100):\n",
    "    print(decoder(X_train[i]), decoder(y_train[i]), decoder(y_train1[i]))\n",
    "    \n",
    "print(y_train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancList = ['_HPGPNRMPC', '_HPGPN' ,'_HPGP' ,'_HPG', '_HP']\n",
    "trainL = [100000, 1000000, 1500000, 2000000]\n",
    "lenL = [1, 5, 11, 15, 21, 51, 101]\n",
    "\n",
    "for a in ancList:\n",
    "    for b in trainL:\n",
    "        for c in lenL:\n",
    "            print('sbatch insert1Train_general_size.sh {} \\'hg38\\' {} {}'.format(a, b, c))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
