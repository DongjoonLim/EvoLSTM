{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 26 18:05:07 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 29%   23C    P8     6W / 250W |  10644MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 30%   27C    P8    22W / 250W |  10946MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8     1W / 250W |  10644MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 30%   26C    P8    20W / 250W |    164MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  On   | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 30%   27C    P8     6W / 250W |   4113MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  On   | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 38%   51C    P8     1W / 250W |     11MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  On   | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 30%   24C    P8    15W / 250W |  10568MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  On   | 00000000:3F:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8     3W / 250W |     11MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   8  GeForce RTX 208...  On   | 00000000:40:00.0 Off |                  N/A |\n",
      "| 30%   24C    P8    18W / 250W |     11MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   9  GeForce RTX 208...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 30%   24C    P8    12W / 250W |  10946MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     13619      C   ...m63/miniconda3/envs/research/bin/python 10633MiB |\n",
      "|    1     30377      C   ...lu41/miniconda3/envs/gpu_env/bin/python 10933MiB |\n",
      "|    2     12274      C   ...m63/miniconda3/envs/research/bin/python 10633MiB |\n",
      "|    3     19815      C   ...a5/.virtualenvs/single_cell/bin/python3   153MiB |\n",
      "|    4     19714      C   ...a3/envs/tensorflow-gpu-rdkit/bin/python  3949MiB |\n",
      "|    4     19815      C   ...a5/.virtualenvs/single_cell/bin/python3   153MiB |\n",
      "|    6     33851      C   ...m63/miniconda3/envs/research/bin/python 10557MiB |\n",
      "|    9     38571      C   ...lu41/miniconda3/envs/gpu_env/bin/python 10933MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import itertools\n",
    "import operator\n",
    "from tensorflow.python.keras import backend as k\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "!nvidia-smi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Activation, LSTM, TimeDistributed, Dense, RepeatVector, CuDNNLSTM, GRU, Bidirectional, Input, CuDNNGRU\n",
    "# #from keras.utils import np_utils\n",
    "# from keras.callbacks import TensorBoard\n",
    "# # import tensorflow as tf\n",
    "\n",
    "# from keras import backend as K\n",
    "# from keras.models import Model\n",
    "# from keras.layers.core import Dense, Reshape\n",
    "# from keras.layers.wrappers import TimeDistributed\n",
    "# from keras.layers import concatenate\n",
    "# import difflib\n",
    "# from keras.models import load_model\n",
    "# import keras\n",
    "# from keras import losses\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import choice\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "ancName = '_HPGPNRMPC'\n",
    "desName = 'hg38'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "seq_length = 11\n",
    "train_size = 0\n",
    "val_loss_hist = []\n",
    "\n",
    "#K.clear_session()\n",
    "#keras.backend.clear_session()\n",
    "\n",
    "anc = str(np.load('prepData/insert1Anc_{}_{}.npy'.format(ancName, desName)))\n",
    "des = str(np.load('prepData/insert1Des_{}_{}.npy'.format(ancName, desName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "anc = np.array(list(anc+'0'))\n",
    "des = np.array(list(des+'0'))\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(des)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded_des = label_encoder.transform(des)\n",
    "integer_encoded_anc = label_encoder.transform(anc)\n",
    "#one hot the sequence\n",
    "integer_des = integer_encoded_des.reshape(len(integer_encoded_des), 1)\n",
    "\n",
    "onehot_encoder.fit(integer_des)\n",
    "encoded_des =onehot_encoder.transform(integer_des)\n",
    "\n",
    "integer_anc = integer_encoded_anc.reshape(len(integer_encoded_anc), 1)\n",
    "encoded_anc = onehot_encoder.transform(integer_anc)\n",
    "\n",
    "print(encoded_des)\n",
    "print(encoded_anc)\n",
    "\n",
    "print(len(encoded_des[0]))\n",
    "encode_dimension= len(encoded_des[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_des.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-' '0' 'A' 'C' 'E' 'G' 'O' 'P' 'Q' 'T' 'V' 'W' 'Y' 'c' 'l' 'm' 'p' 'r'\n",
      " 'u' 'w' 'x' 'y']\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "print(onehot_encoder.transform(np.ones(1).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59c7c64c29447d69efc758beea0f930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2292728), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d48b2fc788486d9cdabdf0a6a6f75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2292728), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4581dacbb1e24ac59441acdc9ec8a1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2292728), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 27413.75it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37058.11it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19683.17it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19096.58it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 14778.14it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 32017.59it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 44706.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 32286.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17875.76it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 49503.59it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24181.00it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17704.28it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 36072.98it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 41378.78it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 31407.31it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 38544.15it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22908.31it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22149.47it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 7921.93it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 28817.83it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12395.85it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21804.04it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 30881.76it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22054.18it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22407.65it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23045.63it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22234.86it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24437.15it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 27627.15it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 26409.47it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 26304.07it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 29556.27it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17704.28it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 25294.60it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 25129.27it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 31110.82it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23794.40it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16314.48it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16297.19it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37632.42it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 28550.34it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15171.77it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39433.63it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23491.52it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24925.63it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35165.66it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 38673.38it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17357.92it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 9410.02it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 25746.29it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 27300.20it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35246.25it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 38705.83it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39945.75it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 8903.39it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 43159.35it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23360.68it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 8977.88it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16360.76it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19255.99it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 46603.38it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16993.50it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 34074.85it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39066.34it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 25184.14it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 14960.23it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21670.90it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21897.17it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35932.51it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 27726.77it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 38511.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2292728, 11, 22)\n",
      "(2292728, 11, 22)\n",
      "[[[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "AAAAAATTTTA 0AAAAAATTTT AAAAAATTTTA\n",
      "AAGGAAAACTA 0AAGGAAAACT AAGGAAAACTA\n",
      "TAGCCCTTGTG 0CAGCCATTGT CAGCCATTGTG\n",
      "GGTTATCAGAT 0GGTTATCAGA GGTTATCAGAT\n",
      "TCTAGTCTTGT 0TCTAGTCTTG TCTAGTCTTGT\n",
      "TTCTTGTCTTT 0TTCTTGTTTC TTCTTGTTTCT\n",
      "GGGCTATTTTT 0GGGCTATTTT GGGCTATTTTT\n",
      "ACCTCTTTGTA 0ACCTCTTTGT ACCTCTTTGTA\n",
      "AACTGGATCCT 0AACTGCATCC AACTGCATCCT\n",
      "GCCATCTGATG 0GCCATCTGAT GCCATCTGATG\n",
      "AATTTTGCCAC 0AATTTTGCCA AATTTTGCCAC\n",
      "AATGATACTTG 0AATGATACTT AATGATACTTG\n",
      "TGGAACAAGAA 0GGGAACAAGA GGGAACAAGAA\n",
      "GCCAAATATTG 0GCCAATTATT GCCAATTATTG\n",
      "TCTCTCCTATT 0TCTCTCCTAC TCTCTCCTACT\n",
      "AATGTATCTAT 0AATGTATCTA AATGTATCTAT\n",
      "TGTCAGTTAAT 0TGTCAGTTAA TGTCAGTTAAT\n",
      "TTGAAGGTCTC 0TTGAAGGTCT TTGAAGGTCTC\n",
      "CAACCCTGGAA 0CAACCCTGGA CAACCCTGGAA\n",
      "CAAAGTTAGAA 0CAAAGTTAGA CAAAGTTAGAA\n",
      "GAAGGTTTTTC 0GAAGGTTCTG GAAGGTTCTGC\n",
      "TCCCCAAATTA 0TCCCPAAATT TCCCPAAATTA\n",
      "ACCAAATTGTG 0ACCAAATTGT ACCAAATTGTG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 17241.16it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37177.55it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 34379.54it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 13846.74it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 14399.92it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22528.00it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19801.44it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 26592.13it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19025.71it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 53585.77it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24282.81it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 36072.98it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24885.30it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 25646.11it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39099.44it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 26980.90it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 26746.29it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 5300.10it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16968.50it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 38576.37it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39945.75it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 28621.18it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35032.15it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12014.93it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37267.64it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12462.82it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16053.36it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37510.04it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37327.95it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19304.33it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19475.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19426.25it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 34482.32it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 10483.38it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37973.12it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 8578.90it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16436.53it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 13118.38it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22128.22it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23231.29it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 34125.25it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23967.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21650.56it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 9249.67it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35435.75it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 13077.48it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17228.28it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 18484.51it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 28270.43it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 9845.78it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 20496.38it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 13242.64it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 38608.66it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37601.75it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 8468.68it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35354.29it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 28621.18it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 9564.13it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 29862.36it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 42759.35it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35192.48it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 33216.23it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23503.49it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15571.16it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 25211.66it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16656.08it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35682.40it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 10481.00it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15608.03it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15196.75it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23184.59it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 26394.36it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTACATTCATG 0GTACATTCAT GTACATTCATG\n",
      "CAATGGAACAC 0TAATGGAACA TAATGGAACAC\n",
      "TATTTAGCCAT 0TATTTAGCCA TATTTAGCCAT\n",
      "AGAAAGGAACA 0AGAAACGAAC AGAAACGAACA\n",
      "AGCTGACATGA 0AGCTGACATG AGCTGACATGA\n",
      "GTGAATCTTGC 0GTGAATCTTG GTGAATCTTGC\n",
      "ATGCACATTGC 0ATGCACATTG ATGCACATTGC\n",
      "TAAGTGGAAGA 0TAAGTGGAAG TAAGTGGAAGA\n",
      "AGACAGTCTGA 0AGACAGTCTG AGACAGTCTGA\n",
      "GGAGGATACAC 0GGAGGATACA GGAGGATACAC\n",
      "ACAGTGACTGA 0ACAGTG--TG ACAGTG--TGA\n",
      "CTTCATTTAAT 0CCTCATTTAA CCTCATTTAAT\n",
      "GAGATTCTGGA 0GAGACACTGG GAGACACTGGA\n",
      "GAAGGCAAAAC 0GAAGGC-AAA GAAGGC-AAAC\n",
      "TACACAGATGG 0TACACAGATG TACACAGATGG\n",
      "GAAGCCATTGG 0GAAGCCATTG GAAGCCATTGG\n",
      "CTCCATGGGGT 0CTCCATGGGG CTCCATGGGGT\n",
      "GGGGGTTTGAA 0GGGGGTTTGA GGGGGTTTGAA\n",
      "GCATTCCATAT 0GCATTCCATA GCATTCCATAT\n",
      "GATACTTTAAT 0GATACTTTAA GATACTTTAAT\n",
      "TGCCACTATGC 0TGCCACAATG TGCCACAATGC\n",
      "ATTTGTCAAAA 0ATTTGTCAAA ATTTGTCAAAA\n",
      "CACGCAGAATT 0TATGCAGAAT TATGCAGAATT\n",
      "TTACAGCCAAA 0TTACAGCCAT TTACAGCCATA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 12927.25it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 28710.23it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 18816.21it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 11517.06it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 18236.10it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 33924.52it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12791.06it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12189.52it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24606.58it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15057.88it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 38320.05it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 41341.71it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 14902.24it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 9114.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17834.30it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15854.76it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 36271.50it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19784.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37510.04it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16465.86it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22256.32it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 26546.23it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 25589.21it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22234.86it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 40865.67it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 8896.52it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 18107.28it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 18036.49it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12956.29it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39773.57it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 36880.37it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 25905.30it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 41490.42it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 26364.20it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24659.19it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 13036.83it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19491.91it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 8731.52it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39945.75it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15997.69it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37117.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35138.88it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 9883.75it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39980.37it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 42289.04it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39670.98it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 34873.28it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17973.25it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 20450.95it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35654.83it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 41194.06it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15471.95it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 13219.87it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 11772.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 20661.60it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 7292.14it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 40294.62it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24593.47it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 20990.60it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17834.30it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23831.27it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15534.46it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 44491.17it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 31557.69it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16912.52it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21834.99it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 27676.87it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17062.63it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 43898.52it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 26715.31it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 29349.46it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 51839.71it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21589.77it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 29312.16it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39066.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGGGTAAACCA 0TGGTTAGAGC TGGTTAGAGCA\n",
      "AATCTATTCAA 0AETCTATTCA AETCTATTCAA\n",
      "ATTAAATAAAA 0ATTAAATAAA ATTAAATAAAA\n",
      "TTATTCAGATG 0TTACTCYGAT TTACTCYGATG\n",
      "TGGAGTACCCA 0TGGAGTuCCC TGGAGTuCCCA\n",
      "GCACAGAATAC 0GGACAGAATA GGACAGAATAC\n",
      "ATCATGTGAAA 0ATCATGTGAA ATCATGTGAAA\n",
      "AAGACATGGGA 0AAGACATGGG AAGACATGGGA\n",
      "GAGTGAAGGTG 0GAGTGAAGGV GAGTGAAGGVG\n",
      "GTTAAAACGTT 0GTTAAAACAT GTTAAAACATT\n",
      "CATATTAAAGA 0CATATTAAAG CATATTAAAGA\n",
      "ACTTCCACCCA 0ACTTCCACTC ACTTCCACTCA\n",
      "GATTGCAAGAA 0GATTGCAAGA GATTGCAAGAA\n",
      "AAGAGAGAGGA 0AAGAGAGAGG AAGAGAGAGGA\n",
      "ATGGAGATGGC 0ATGGAGATGG ATGGAGATGGT\n",
      "AGCACGAGTCC 0AGCACAAGTC AGCACAAGTCC\n",
      "CTACAATAAAA 0CTACAATAAA CTACAATAAAA\n",
      "GCAGATGTTTT 0GTAGATGTTT GTAGATGTTTT\n",
      "GAGATCAGTTA 0GAGATCAGTT GAGATCAGTTC\n",
      "TATTTGTTCTG 0TATTTGTTCT TATTTGTTCTG\n",
      "ACAAAAATTAA 0ACAAAAATTA ACAAAAATTAA\n",
      "AGACAGAAACC 0AGACAGAAAC AGACAGAAACC\n",
      "AAAGTTTAGCC 0AAAGTTTAGC AAAGTTTAGCC\n",
      "TGAGGCTACAA 0TGAGGCAACA TGAGGCAACAA\n",
      "TTAATTGGGCA 0TTAGTTGGGG TTAGTTGGGGA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 11/11 [00:00<00:00, 28926.23it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 48770.98it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 26274.11it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 14231.14it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 43078.75it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12830.18it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24463.07it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 31385.95it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 32377.08it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 28980.74it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 38320.05it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 11016.56it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 14572.76it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 43608.08it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 9654.18it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 40154.35it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 25253.06it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 40224.36it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 14087.74it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 11701.08it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37117.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 40224.36it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 5724.24it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19641.27it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12402.51it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39033.29it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 29823.75it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 32263.88it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 11040.28it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 23278.18it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16291.44it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12296.73it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 43484.77it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15762.67it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 12280.37it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17094.24it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 20532.86it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 40435.88it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 27107.72it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 10912.33it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 10021.14it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 13549.88it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24463.07it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39199.10it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 33002.39it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 29575.22it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 2982.38it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 53153.62it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 29862.36it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 33216.23it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39433.63it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 31006.28it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37028.37it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 38320.05it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 16165.85it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 44277.68it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 42838.76it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 42838.76it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 5257.82it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 30135.43it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 28098.26it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 6703.09it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 10207.38it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 34405.18it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 34074.85it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 39636.89it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 47810.72it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 4323.62it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17331.83it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 18221.70it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 13307.57it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 40542.48it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATAAGCCAGAG 0ATAAGCCAGA ATAAGCCAGAG\n",
      "GCACATATGGC 0GCATATATGG GCATATATGGC\n",
      "ATAGACAGATT 0ATAGACACAT ATAGACACATT\n",
      "TAAACATTTCT 0TAAACATTTC TAAACATTTCT\n",
      "CCCTTATATTA 0CTC--ATATT CTC--ATATTA\n",
      "ATACAAATACT 0ATACAAATAC ATACAAATACT\n",
      "AAAATTACAAA 0AAAATGACAT AAAATGACATA\n",
      "TAAATTGATTC 0TCAATTGATT TCAATTGATTC\n",
      "CAAATAAAACA 0CAAATAAAAC CAAATAAAACA\n",
      "AATATTTAAAA 0AATATTTAAA AATATTTAAAA\n",
      "AATTTAATGAA 0CATTTAATGA CATTTAATGAA\n",
      "TAAACACTGGG 0TAAACACTGG TAAACACTGGG\n",
      "GTCTACAGTAG 0GTCTACAGTA GTCTACAGTAG\n",
      "TATTTAAAGGA 0TAGTTAAAGG TAGTTAAAGGA\n",
      "GATCTCACAAA 0GATCTCACAA GATCTCACAAA\n",
      "CAGGTTTGGTT 0CAGGTTTGGT CAGGTTTGGTT\n",
      "TTTGAAGGTTA 0TTTGAAGGTT TTTGAAGGTTA\n",
      "GAACTGATGGT 0GAAATGATGG GAAATGATGGT\n",
      "CTAGAGAATTC 0CTAGAGAATT CTAGAGAATTC\n",
      "ATTTCATTCCA 0ATTTCATTCC ATTTCATTCCA\n",
      "GAGAGAGAAAG 0GAGACAGAAA GAGACAGAAA-\n",
      "GAGGAATTTCT 0GAGGAATATC GAGGAATATCT\n",
      "TGGGTTCCTTC 0TGGGTTCCTT TGGGTTCCTTC\n",
      "AGGAATGCGTC 0AGGAATACAT AGGAATACATC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 19223.89it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 40757.37it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 49292.03it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 25476.17it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 41378.78it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 35192.48it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 37693.91it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 6102.02it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15497.93it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 24092.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGGCTTTGCCT 0TGGCTTTGCC TGGCTTTGCCT\n",
      "CATCTTTGTGT 0CATCTTTGTG CATCTTTGTGT\n",
      "GTTTGAACTAT 0GTTTGAACTA GTTTGAACTAT\n",
      "GCATATGGCAG 0GCATACGGCA GCATACGGCAG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def splice(input, pad):\n",
    "    result = []\n",
    "    if pad == False:\n",
    "        for i in notebook.tqdm(range(int(len(input)/seq_length))):\n",
    "            result.append(input[i*seq_length:(i+1)*seq_length])\n",
    "    else :\n",
    "        for i in notebook.tqdm(range(int(len(input)/seq_length))):\n",
    "            result.append(np.concatenate((onehot_encoder.transform(np.ones(1).reshape(-1,1)), \n",
    "                                         input[i*seq_length:(i+1)*seq_length-1]), \n",
    "                                         axis = 0)\n",
    "                         )\n",
    "    return np.array(result)\n",
    "\n",
    "def decoder(input):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    decoded = ''\n",
    "    for i in tqdm(range(len(input))):\n",
    "        # decoded= decoded+(nucleotide[np.argmax(onehot_encoder.inverse_transform(input[i].reshape(-1, 1)))])\n",
    "        #print(np.argmax(input[i]))\n",
    "        #print(nucleotide)\n",
    "        decoded= decoded+nucleotide[np.argmax(input[i])]\n",
    "    return decoded\n",
    "\n",
    "y = splice(encoded_des, False)\n",
    "y1 = splice(encoded_des, pad = True)\n",
    "X = splice(encoded_anc, False)\n",
    "\n",
    "print(y1.shape)\n",
    "print(X.shape)\n",
    "print(X)\n",
    "\n",
    "onehot_encoder.transform(np.ones(1).reshape(-1,1))\n",
    "for i in range (100):\n",
    "    print(decoder(X[i]), decoder(y1[i]), decoder(y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1287d44c4ac424281c499e50feff6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fd3437da704eb5bad669cf20c67cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train1, y_test1, y_train, y_test = train_test_split(\n",
    "    X, y1, y, test_size=0.2, random_state=42)\n",
    "# X_train = X[:-300000]\n",
    "# X_test = X[-300000:]\n",
    "# y_train1 = y1[:-300000]\n",
    "# y_test1 = y1[-300000:]\n",
    "# y_train = y[:-300000]\n",
    "# y_test = y[-300000:]\n",
    "\n",
    "def concat(input1, input2):\n",
    "    result = []\n",
    "    for x, y in notebook.tqdm(zip(input1, input2)):\n",
    "        result.append(np.concatenate((x, y), axis=1))\n",
    "        # print(decoder(x), decoder(y), decoder(np.concatenate((x, y))))\n",
    "    \n",
    "    return np.array(result).astype(np.uint8)\n",
    "\n",
    "y_train1 = concat(X_train, y_train1)\n",
    "#y_val1 = concat(X_val, y_val1)\n",
    "y_test1 = concat(X_test, y_test1)\n",
    "\n",
    "# for i in range (100):\n",
    "#     print(decoder(y_train[i]))\n",
    "    \n",
    "nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "\n",
    "def decoder(input):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    decoded = ''\n",
    "    for i in range(len(input)):\n",
    "        # decoded= decoded+(nucleotide[np.argmax(onehot_encoder.inverse_transform(input[i].reshape(-1, 1)))])\n",
    "        #print(np.argmax(input[i]))\n",
    "        #print(nucleotide)\n",
    "        decoded= decoded+nucleotide[np.argmax(input[i])]\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCAGCTGTGTC CCAGCTGTGTC CCAGCTGTGTC\n",
      "CCAGAATGCTT CCAGAATGCTT CCAGAATGCTT\n",
      "CAATTTGGACA CAATTTGGACA CAATTTGGGCA\n",
      "AGGCCGAGGAC AGGCCGAGGAC AGGCCGAGGAC\n",
      "GTGAGCAGAGG GTGAGCAGAGG GTGAGCAGAGG\n",
      "CAGTTGGAAGC CAGTTGGAAGC CAGTTGGAAGC\n",
      "TAAGTACTACA TAAGTACTACA TAAGTACTACA\n",
      "CATCAGATCTC CATCAGATCTC CATCAGATCTC\n",
      "CTTTATAATAG CTTTATAATAG CTTTATAATAG\n",
      "TGATGGTATGT TGATGGTATGT TTATCTTATGT\n",
      "GATGAGGGTGG GATGAGGGTGG GATGAGGGTGG\n",
      "CCAAATACAGG CCAAATACAGG CCAAACACAGA\n",
      "CTGCTATCCCA CTGCTATCCCA CTGCTATCCCA\n",
      "CGAATCACTGT CGAATCACTGT CGAATCACTGT\n",
      "GTATTAGACTT GTATTAGACTT GTATTAGACTT\n",
      "TGCTGATTTAC TGCTGATTTAC TGCTAATTTAC\n",
      "GGTATGAAATG GGTATGAAATG GGTTTCAAATG\n",
      "ATACCATAGTA ATACCATAGTA ATACCATAGTA\n",
      "GAGAAAATAAA GAGAAAATAAA GAGAAAATAAA\n",
      "AAACCAACACT AAACCAACACT AAACCAACACT\n",
      "TCAGAAACAGG TCAGAAACAGG TCAGAAATAGG\n",
      "AGGGACGGCAA AGGGACGGCAA AGGGACGGCAA\n",
      "AGTACACATAG AGTACACATAG AGTACACATAG\n",
      "CAGAGGCTGTC CAGAGGCTGTC CAGAGGCTGTC\n",
      "CTCCGTGAGGA CTCCGTGAGGA CTCCGTGAGGA\n",
      "TGCCTTTTGGA TGCCTTTTGGA TGCCTTTTGGA\n",
      "AACTCTGTATG AACTCTGTATG AACTCTGTATG\n",
      "CAGTGCTTCAA CAGTGCTTCAA CAGTGCTTCAA\n",
      "AGCAATGAGGT AGCAATGAGGT AGCAATGAGGT\n",
      "TTAAGATTCAG TTAAGATTCAG TTAAGATTCAG\n",
      "GTCATCTTCTT GTCATCTTCTT GTCATATTCTT\n",
      "TCATTTATGGA TCATTTATGGA TCGTTTATGGA\n",
      "CAAAAAAGGGC CAAAAAAGGGC CAAAAAAGGGC\n",
      "GATGAGGAAGG GATGAGGAAGG GATGAGGAAGG\n",
      "CTTTACACCAA CTTTACACCAA CTTTACACCAA\n",
      "GTGTGTCACTT GTGTGTCACTT GTGTGTCACGT\n",
      "TTACCCGTAAC TTACCCGTAAC TTACCCATAAC\n",
      "GCTAATTTTTG GCTAATTTTTG GCTAATTTTTG\n",
      "GTGCACAGCTG GTGCACAGCTG GTGCCCAGCTG\n",
      "GATGCAAAAAG GATGCAAAAAG GATGCAAAAAG\n",
      "GTCCAGCCCCG GTCCAGCCCCG GTCCAGCCCTG\n",
      "TAAACATTTTA TAAACATTTTA TAAACATTTTA\n",
      "AAATTCTCAAG AAATTCTCAAG AAATTATCAAG\n",
      "CAAGACCACGC CAAGACCACGC CAAGACCACGC\n",
      "TGAGATTTTTG TGAGATTTTTG TGAGATTTTTG\n",
      "AGGTGCACGGG AGGTGCACGGG AGGTGCATGGG\n",
      "TATATATATAT TATATATATAT --TATATATAT\n",
      "ACTCTTAACTC ACTCTTAACTC ACTCTTAACTC\n",
      "TTACCAACTGC TTACCAACTGC TTACCAACTGC\n",
      "AGGTTGACAGG AGGTTGACAGG AGGTTGACAGG\n",
      "AGAAAGTTCAA AGAAAGTTCAA AGAAAGTTCAA\n",
      "TTGAGATGGGA TTGAGATGGGA TTGAGATGGGA\n",
      "CTCAATACCTA CTCAATACCTA CTCAATACCTA\n",
      "TCTTACCTATG TCTTACCTATG TCTTACCTATG\n",
      "AAGAAGTCATC AAGAAGTCATC AAGAAGTCATC\n",
      "TACCTGTGGCA TACCTGTGGCA ---------CA\n",
      "TTCACCAATTC TTCACCAATTC TTCACTAATTC\n",
      "GGAATGTGGAG GGAATGTGGAG AGAATGTGGAA\n",
      "GACTGATGAAT GACTGATGAAT GACTGATGAAT\n",
      "CCCTTGAACAA CCCTTGAACAA CCCTTGAACAA\n",
      "TATATCATACT TATATCATACT TATATCACACT\n",
      "GCTGCCGTGAT GCTGCCGTGAT GCTGCCGTGAT\n",
      "TTTGTTGGGCA TTTGTTGGGCA TTTGTTGGGCA\n",
      "TAGGTGTGAAG TAGGTGTGAAG TAGGTGTGAAG\n",
      "TTCTTCATTTT TTCTTCATTTT GTCTTCATTTT\n",
      "TTTGCCATGTA TTTGCCATGTA TTTGCCATGTA\n",
      "GTAGGAAGCCT GTAGGAAGCCT GTAGGAAGCCT\n",
      "CCTAGTGCCAC CCTAGTGCCAC CCTAGTGCCAC\n",
      "GGGCACCCTGT GGGCACCCTGT GGGCACCCTTT\n",
      "GCTATTTTAGG GCTATTTTAGG GCTATTTTAGG\n",
      "ACTTAATGACA ACTTAATGACA ACTTAATGACA\n",
      "AGACATAGCTC AGACATAGCTC AGACATAGCTC\n",
      "AGAAGTTTATT AGAAGTTTATT AGAAGTTTATT\n",
      "AAAATACAAAA AAAATACAAAA AAAATACAAAA\n",
      "CCTCCACAGTC CCTCCACAGTC CCTCCACAGTC\n",
      "GCAGCACAAGA GCAGCACAAGA GCAGCACACAA\n",
      "TTTTGTATGCT TTTTGTATGCT TTTTGCATGCT\n",
      "CCCATCTTCTC CCCATCTTCTC CCCATCTTCTT\n",
      "CATAATGGTCA CATAATGGTCA CATAATGGTCC\n",
      "GATATGGCAGG GATATGGCAGG GATATGGCAGG\n",
      "AATCTCCACCT AATCTCCACCT AATCTCCATCT\n",
      "TAATAAATATA TAATAAATATA TAATAAATATA\n",
      "AAATCAAAGAA AAATCAAAGAA AAATCAAAGGA\n",
      "TTTGTTCACCA TTTGTTCACCA TTTGTTCACCA\n",
      "TTTATGAGGGG TTTATGAGGGG TTTTTGAGGGG\n",
      "ATTTGCTGTCC ATTTGCTGTCC ATTTGCTGTCC\n",
      "AACCTCTGCCT AACCTCTGCCT AACCTCTGCCT\n",
      "TAAGATTGCCA TAAGATTGCCA TAAGATTGCCA\n",
      "AGTAAAACTTA AGTAAAACTTA AGTAAAGCTTA\n",
      "TATATTTTTGT TATATTTTTGT TATATTTTTGT\n",
      "TAGACTATGAG TAGACTATGAG TAGACTGTGAG\n",
      "GAACTGAAGCC GAACTGAAGCC GAACTGAAGCC\n",
      "CTGGTGTTGAC CTGGTGTTGAC CTGGTGTTGAC\n",
      "ATATGTTTTCT ATATGTTTTCT ATATGTTTTCT\n",
      "GAGGCAGAGGT GAGGCAGAGGT GAGGCAGAGGT\n",
      "ACAGACAGCCA ACAGACAGCCA ACAGACAGCCA\n",
      "CTAGTCATTGC CTAGTCATTGC CTAGTCATTGC\n",
      "AAGAGCCCACA AAGAGCCCACA AAGAGCCCACA\n",
      "GTTTCTAAATA GTTTCTAAATA GTTTCTAAATA\n",
      "CAACAGAGATT CAACAGAGATT CAACAGAGATT\n",
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder.transform(np.ones(1).reshape(-1,1))\n",
    "for i in range (100):\n",
    "    print(decoder(X_train[i]), decoder(y_train1[i]), decoder(y_train[i]))\n",
    "print(y_train1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHitMiss(a,b):\n",
    "    if a==b:\n",
    "        return 'Hit'\n",
    "    else:\n",
    "        return 'Miss'\n",
    "def accuracy(a, b):\n",
    "    count = 0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == b[i]:\n",
    "            count = count+1\n",
    "    return count/len(a)\n",
    "\n",
    "def accuracy2(a, b, c):\n",
    "    count = 0\n",
    "    count2 =0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != c[i]:\n",
    "            count2 = count2 +1\n",
    "        if a[i] != c[i] and b[i]==c[i]:\n",
    "            count = count+1\n",
    "    return count/count2\n",
    "\n",
    "def isMutation(a, b):\n",
    "    if a!= b:\n",
    "        print(\"mutation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1467345 samples, validate on 366837 samples\n",
      "1467345/1467345 [==============================] - 105s 72us/sample - loss: 0.2380 - accuracy: 0.9479 - val_loss: 0.1753 - val_accuracy: 0.9659\n",
      "Train on 1467345 samples, validate on 366837 samples\n",
      "Epoch 1/2\n",
      "1467345/1467345 [==============================] - 102s 69us/sample - loss: 0.2414 - accuracy: 0.9472 - val_loss: 0.1753 - val_accuracy: 0.9659\n",
      "Epoch 2/2\n",
      "1467345/1467345 [==============================] - 97s 66us/sample - loss: 0.1746 - accuracy: 0.9658 - val_loss: 0.1738 - val_accuracy: 0.9659\n",
      "Train on 1467345 samples, validate on 366837 samples\n",
      "Epoch 1/10\n",
      "1467345/1467345 [==============================] - 104s 71us/sample - loss: 0.2441 - accuracy: 0.9450 - val_loss: 0.1749 - val_accuracy: 0.9659\n",
      "Epoch 2/10\n",
      "1467345/1467345 [==============================] - 97s 66us/sample - loss: 0.1744 - accuracy: 0.9658 - val_loss: 0.1737 - val_accuracy: 0.9659\n",
      "Epoch 3/10\n",
      "1467345/1467345 [==============================] - 97s 66us/sample - loss: 0.1735 - accuracy: 0.9659 - val_loss: 0.1729 - val_accuracy: 0.9660\n",
      "Epoch 4/10\n",
      "1467345/1467345 [==============================] - 97s 66us/sample - loss: 0.1730 - accuracy: 0.9659 - val_loss: 0.1727 - val_accuracy: 0.9660\n",
      "Epoch 5/10\n",
      "1467345/1467345 [==============================] - 97s 66us/sample - loss: 0.1726 - accuracy: 0.9659 - val_loss: 0.1724 - val_accuracy: 0.9660\n",
      "Epoch 6/10\n",
      "1467345/1467345 [==============================] - 97s 66us/sample - loss: 0.1722 - accuracy: 0.9660 - val_loss: 0.1721 - val_accuracy: 0.9660\n",
      "Epoch 7/10\n",
      "1467345/1467345 [==============================] - 97s 66us/sample - loss: 0.1719 - accuracy: 0.9660 - val_loss: 0.1719 - val_accuracy: 0.9661\n",
      "Epoch 8/10\n",
      "1467345/1467345 [==============================] - 97s 66us/sample - loss: 0.1716 - accuracy: 0.9660 - val_loss: 0.1719 - val_accuracy: 0.9661\n",
      "Epoch 9/10\n",
      "1467345/1467345 [==============================] - 97s 66us/sample - loss: 0.1714 - accuracy: 0.9660 - val_loss: 0.1718 - val_accuracy: 0.9661\n",
      "Epoch 10/10\n",
      " 159000/1467345 [==>...........................] - ETA: 1:18 - loss: 0.1714 - accuracy: 0.9660"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "def lstm_model(latent_dim, half):\n",
    "    batch_size = 1000  # Batch size for training.\n",
    "    epochs = 45  # Number of epochs to train for.\n",
    "#     latent_dim = 128  # Latent dimensionality of the encoding space.\n",
    "#     half = 64\n",
    "    num_samples = 10000  # Number of samples to train on.\n",
    "    encoder_inputs = layers.Input(shape=(None, encode_dimension))\n",
    "    \n",
    "    encoder = layers.Bidirectional(layers.LSTM(half, return_state=True))\n",
    "    encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
    "    state_h = layers.concatenate([forward_h, backward_h])\n",
    "    state_c = layers.concatenate([forward_c, backward_c])\n",
    "    \n",
    "    \n",
    "    # only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder\n",
    "    decoder_inputs = layers.Input(shape=(None, 2*encode_dimension))\n",
    "    decoder_lstm = layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = layers.Dense(encode_dimension, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    # inference\n",
    "    encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = layers.Input(shape=(latent_dim,))\n",
    "    decoder_state_input_c = layers.Input(shape=(latent_dim,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "    # Run training\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy']\n",
    "                  )\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "\n",
    "def modelFit(epoch, batchSize, latent_dim, half, X_train, y_train, y_train1):\n",
    "    model1, encoder_model1, decoder_model1 = lstm_model(latent_dim, half)\n",
    "    hist1 = model1.fit([X_train, y_train1], y_train,\n",
    "          batch_size=batchSize,\n",
    "          epochs=epoch,\n",
    "          #validation_data=([X_test,y_test1], y_test),\n",
    "          validation_split=0.2,\n",
    "          verbose = 1\n",
    "         )\n",
    "    return hist1, model1, encoder_model1, decoder_model1\n",
    "\n",
    "def grid_search(latent, half,train_size, X_train, y_train, y_train1):\n",
    "    hist1, model1, encoder_model1, decoder_model1 = modelFit(1, 1000, latent, half, X_train, y_train, y_train1)\n",
    "    hist2 ,model2, encoder_model2, decoder_model2 = modelFit(2, 1000, latent, half, X_train, y_train, y_train1)\n",
    "    hist3 ,model3, encoder_model3, decoder_model3 = modelFit(10, 1000, latent, half, X_train, y_train, y_train1)\n",
    "    #hist4 ,model4, encoder_model4, decoder_model4 = modelFit(30, 1000, latent, half, X_train, y_train, y_train1)\n",
    "    #hist5 ,model5, encoder_model5, decoder_model5 = modelFit(50, 100, latent, half, X_train, y_train, y_train1)\n",
    "    #hist6 ,model6, encoder_model6, decoder_model6 = modelFit(80, 100, latent, half, X_train, y_train, y_train1)\n",
    "    #hist7 ,model7, encoder_model7, decoder_model7 = modelFit(100, 100, latent, half, X_train, y_train, y_train1)\n",
    "    #hist8 ,model8, encoder_model8, decoder_model8 = modelFit(500, 100, latent, half)\n",
    "\n",
    "    model1.save(\"models/insert1_{}_{}_{}_{}_1.h5\".format(ancName, desName,train_size,half))\n",
    "    model2.save(\"models/insert1_{}_{}_{}_{}_2.h5\".format(ancName, desName,train_size,half))\n",
    "    model3.save(\"models/insert1_{}_{}_{}_{}_10.h5\".format(ancName, desName,train_size,half))\n",
    "    #model4.save(\"models/insert1_{}_{}_30_double.h5\".format(train_size,half))\n",
    "    #model5.save(\"models/_gap_hg38_{}_{}_50_double.h5\".format(train_size,half))\n",
    "    #model6.save(\"models/_gap_hg38_{}_{}_80_double.h5\".format(train_size,half))\n",
    "    #model7.save(\"models/_gap_hg38_{}_{}_100_double.h5\".format(train_size,half))\n",
    "    #model8.save(\"_gap_hg38_{}_{}_500.h5\".format(train_size,half))\n",
    "    \n",
    "    encoder_model1.save(\"models/E_insert1_{}_{}_{}_{}_1.h5\".format(ancName, desName,train_size,half))\n",
    "    encoder_model2.save(\"models/E_insert1_{}_{}_{}_{}_2.h5\".format(ancName, desName,train_size,half))\n",
    "    encoder_model3.save(\"models/E_insert1_{}_{}_{}_{}_10.h5\".format(ancName, desName,train_size,half))\n",
    "    #encoder_model4.save(\"models/E_insert1_{}_{}_30_double.h5\".format(train_size,half))\n",
    "    #encoder_model5.save(\"models/E_gap_hg38_{}_{}_50_double.h5\".format(train_size,half))\n",
    "    #encoder_model6.save(\"models/E_gap_hg38_{}_{}_80_double.h5\".format(train_size,half))\n",
    "    #encoder_model7.save(\"models/E_gap_hg38_{}_{}_100_double.h5\".format(train_size,half))\n",
    "    #encoder_model8.save(\"E_gap_hg38_{}_{}_500.h5\".format(train_size,half))\n",
    "    \n",
    "    decoder_model1.save(\"models/D_insert1_{}_{}_{}_{}_1.h5\".format(ancName, desName,train_size,half))\n",
    "    decoder_model2.save(\"models/D_insert1_{}_{}_{}_{}_2.h5\".format(ancName, desName,train_size,half))\n",
    "    decoder_model3.save(\"models/D_insert1_{}_{}_{}_{}_10.h5\".format(ancName, desName,train_size,half))\n",
    "    #decoder_model4.save(\"models/D_insert1_{}_{}_30_double.h5\".format(train_size,half))\n",
    "    #decoder_model5.save(\"models/D_gap_hg38_{}_{}_50_double.h5\".format(train_size,half))\n",
    "    #decoder_model6.save(\"models/D_gap_hg38_{}_{}_80_double.h5\".format(train_size,half))\n",
    "    #decoder_model7.save(\"models/D_gap_hg38_{}_{}_100_double.h5\".format(train_size,half))\n",
    "    #decoder_model8.save(\"D_gap_hg38_{}_{}_500.h5\".format(train_size,half))\n",
    "    \n",
    "#     count = [i for i in range(len(hist3.history['val_loss']))]\n",
    "#     val_loss_hist.append([hist3.history['val_loss'].index(min(hist3.history['val_loss'])),min(hist3.history['val_loss'])])\n",
    "#     print(val_loss_hist)\n",
    "#     for i, value in zip(count, hist3.history['val_loss']):\n",
    "#         print(i, value)\n",
    "\n",
    "# grid_search(2, 1, 000, X_train, y_train, y_train1)\n",
    "# grid_search(16, 8, 000, X_train, y_train, y_train1)        \n",
    "# grid_search(32, 16, 000, X_train, y_train, y_train1)\n",
    "# grid_search(64, 32, 000, X_train, y_train, y_train1)\n",
    "# grid_search(128, 64, 000, X_train, y_train, y_train1)\n",
    "# grid_search(256, 128, 000, X_train, y_train, y_train1)\n",
    "# grid_search(512, 256, 000, X_train, y_train, y_train1)\n",
    "grid_search(1024, 512, 000, X_train, y_train, y_train1)\n",
    "#grid_search(8192, 4096, 000, X_train, y_train, y_train1)\n",
    "\n",
    "with open('loss_hist.txt', 'wb') as fp:\n",
    "    pickle.dump(val_loss_hist, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%precision 2\n",
    "seq_length = 11\n",
    "test_size = len(y_test)\n",
    "val_size = 30000\n",
    "\n",
    "key = ['-', '0', 'A', 'B', 'C', 'G', 'I', 'L', 'N', 'O', 'P', 'T', 'V' ,'X' ,'b', 'c', 'f', 'g', 'h', 'i',\n",
    "       'o', 'p' ,'r']\n",
    "\n",
    "mapDict = {'A': 'A', 'C': 'C', 'G': 'G', 'T': 'T', '-': '-', 'AA': 'O', 'AC': 'h', '0': '0',\n",
    "           'AT': 'b', 'AG': 'V', 'CA': 'r', 'CC': 'p', 'CT': 'o', 'CG': 'i', 'TA': 'g', \n",
    "           'TC': 'I', 'TT': 'f', 'TG': 'L', 'GA': 'B', 'GC': 'c', 'GT': 'X', 'GG': 'P'}\n",
    "\n",
    "rev_dict = {v: k for k, v in mapDict.items()}\n",
    "#print(rev_dict.keys())\n",
    "rev_key = []\n",
    "for item in key:\n",
    "    #print(item)\n",
    "    if item in list(rev_dict.keys()):\n",
    "        rev_key.append(rev_dict[item])\n",
    "        #print('hi')\n",
    "    else :\n",
    "        rev_key.append(item)\n",
    "print(rev_key)\n",
    "\n",
    "nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "\n",
    "def printHitMiss(a,b):\n",
    "    if a==b:\n",
    "        return 'Hit'\n",
    "    else:\n",
    "        return 'Miss'\n",
    "    \n",
    "def accuracy(a, b):\n",
    "    count = 0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == b[i]:\n",
    "            count = count+1\n",
    "    return count/len(a)\n",
    "\n",
    "def accuracy2(a, b, c):\n",
    "    count = 0\n",
    "    count2 =0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != c[i]:\n",
    "            count2 = count2 +1\n",
    "        if a[i] != c[i] and b[i]==c[i]:\n",
    "            count = count+1\n",
    "    return count/count2\n",
    "\n",
    "def isMutation(a, b):\n",
    "    if a!= b:\n",
    "        print(\"mutation\")\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq, model, encoder_model, decoder_model):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    # Encode the input as state vectors.\n",
    "    #print(input_seq[0,0])\n",
    "    index = 0\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    #print(len(states_value))\n",
    "    #print(states_value)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, encode_dimension*2))\n",
    "    target_seq[0][0]= np.hstack((input_seq[0,index], onehot_encoder.transform(np.ones(1).reshape(-1,1))[0]))\n",
    "    #print(target_seq)\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_seq = ''\n",
    "    probability = 1\n",
    "    \n",
    "    while not stop_condition:\n",
    "        index = index +1\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.random.choice(encode_dimension, 1, p=output_tokens[0, -1, :])[0]\n",
    "        #list(mapDict.keys())\n",
    "#         for i in range(len(output_tokens[0])):\n",
    "#             print(i, dict(zip(rev_key, output_tokens[0][i])))\n",
    "        sampled_nucleotide = nucleotide[sampled_token_index]\n",
    "        \n",
    "        decoded_seq += sampled_nucleotide\n",
    "        #print(sampled_nucleotide, decoded_seq)\n",
    "        #print(decoded_sentence)\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (len(decoded_seq) == seq_length):\n",
    "            break\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, encode_dimension*2))\n",
    "        temp = np.zeros((encode_dimension))\n",
    "        temp[sampled_token_index] = 1\n",
    "        target_seq[0][0]= np.hstack((input_seq[0, index], temp))\n",
    "        # target_seq[0, 0, sampled_token_index] = 1\n",
    "        \n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_seq\n",
    "\n",
    "def get_prob(input_seq, target, model, encoder_model, decoder_model):\n",
    "    # Encode the input as state vectors.\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    index = 0\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, encode_dimension*2))\n",
    "    target_seq[0][0]= np.hstack((input_seq[0,index], onehot_encoder.transform(np.ones(1).reshape(-1,1))[0]))\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_seq = ''\n",
    "    probability = []\n",
    "    \n",
    "    while not stop_condition:\n",
    "        index = index +1\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(target[index-1])\n",
    "        \n",
    "        probability.append(output_tokens[0, -1, :][sampled_token_index])\n",
    "        sampled_nucleotide = nucleotide[sampled_token_index]\n",
    "#         sampled_nucleotide = nucleotide[np.random.choice(encode_dimension, 1, p=output_tokens[0, -1, :])[0]]\n",
    "        \n",
    "        decoded_seq += sampled_nucleotide\n",
    "        if (len(decoded_seq) == seq_length):\n",
    "            break\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, encode_dimension*2))\n",
    "        temp = np.zeros((encode_dimension))\n",
    "        temp[sampled_token_index] = 1\n",
    "        target_seq[0][0]= np.hstack((input_seq[0, index], temp))\n",
    "        # target_seq[0, 0, sampled_token_index] = 1\n",
    "        \n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_seq, probability\n",
    "\n",
    "def diffList(a, b):\n",
    "    count = 0\n",
    "    length = len(a)\n",
    "    for i in range(length):\n",
    "        if a[i] != b[i]:\n",
    "            count = count+1\n",
    "    return count\n",
    "\n",
    "def decoder(input):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    decoded = ''\n",
    "    for i in range(len(input)):\n",
    "        # decoded= decoded+(nucleotide[np.argmax(onehot_encoder.inverse_transform(input[i].reshape(-1, 1)))])\n",
    "        #print(np.argmax(input[i]))\n",
    "        #print(nucleotide)\n",
    "        decoded= decoded+nucleotide[np.argmax(input[i])]\n",
    "    return decoded\n",
    "\n",
    "#for seq_index in range(1):\n",
    "def predict2(X_test, y_test, model, encoder_model, decoder_model, gru=False):\n",
    "    x_true =[]\n",
    "    y_hat =[]\n",
    "    y_true =[]\n",
    "    probList=[]\n",
    "    generator_output = []\n",
    "    productProb = [0]*seq_length\n",
    "\n",
    "    for seq_index in notebook.tqdm(range(len(X_test))):\n",
    "        input_seq = X_test[seq_index: seq_index + 1]\n",
    "        if gru:\n",
    "            decoded_sentence = decode_gru(input_seq, model, encoder_model, decoder_model)\n",
    "        else :\n",
    "            decoded_sentence = decode_sequence(input_seq, model, encoder_model, decoder_model)\n",
    "        _, prob = get_prob(input_seq, y_test[seq_index], model, encoder_model, decoder_model)\n",
    "        prob = [math.log(x) for x in prob]\n",
    "        productProb = [sum(x) for x in zip(productProb, prob)]\n",
    "        input_sen = decoder(input_seq[0])\n",
    "#         inputAll = inputAll + input_sen\n",
    "#         predAll = predAll + decoded_sentence\n",
    "#         outputAll = outputAll + decoder(y_test[seq_index])\n",
    "#         print(input_sen, ' -> ',\n",
    "#               decoded_sentence, 'True:', decoder(y_test[seq_index]), \n",
    "#               printHitMiss(decoded_sentence, decoder(y_test[seq_index]))\n",
    "#               #diffList(input_sen, decoded_sentence)\n",
    "#              )\n",
    "#         print(input_sen, ' -> ',\n",
    "#               decoder(y_test[seq_index]), 'True:', decoder(y_test[seq_index]), \n",
    "#               prob,\n",
    "#               printHitMiss(decoded_sentence, decoder(y_test[seq_index]))\n",
    "#               #diffList(input_sen, decoded_sentence)\n",
    "#              )\n",
    "        x_true.append(input_sen)\n",
    "        y_hat.append(decoded_sentence)\n",
    "        y_true.append(decoder(y_test[seq_index]))\n",
    "    #generator_output.append(input_sen+decoded_seq)\n",
    "    print(productProb)\n",
    "    productProb = [x/test_size for x in productProb]\n",
    "    print(\"Sum of log probabilities : {}\".format(productProb))\n",
    "    print(\"Percentage of target and prediction being identical: {}\".format(accuracy(y_hat, y_true)))\n",
    "    print(\"Percentage of training and prediction being identical: {}\".format(accuracy(y_hat, x_true)))\n",
    "    print(\"Accuracy given mutation happened : {}\".format(accuracy2(x_true, y_hat, y_true)))\n",
    "    #np.save('data/hg38_output.npy', generator_output)\n",
    "    \n",
    "    return x_true, y_hat, y_true\n",
    "\n",
    "def grid_predict(train_size, half, epoch, X_test, y_test):\n",
    "    model1 = tf.keras.models.load_model(\"models/insert1_{}_{}_{}_{}_{}.h5\".format(ancName, desName,train_size,half,epoch))\n",
    "\n",
    "    encoder_model1 = tf.keras.models.load_model(\"models/E_insert1_{}_{}_{}_{}_{}.h5\".format(ancName, desName,train_size,half, epoch))\n",
    "\n",
    "    decoder_model1 =tf.keras.models.load_model(\"models/D_insert1_{}_{}_{}_{}_{}.h5\".format(ancName, desName,train_size,half, epoch))\n",
    "\n",
    "    inputAll, predAll, outputAll = predict2(X_test, y_test, model1, encoder_model1, decoder_model1, gru=False)\n",
    "    \n",
    "    return inputAll, predAll, outputAll\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "def concat(input1, input2):\n",
    "    result = []\n",
    "    for x, y in zip(input1, input2):\n",
    "        result.append(np.hstack((x, y)))\n",
    "    \n",
    "    return np.array(result)\n",
    "\n",
    "# def get_data(trainInd, valInd, testInd):\n",
    "#     X_train=np.load('prepData/X_train_gap_hg38_v3_chr2_size10.npy')[:trainInd]\n",
    "#     X_val=np.load('prepData/X_val_gap_hg38_v3_chr2_size10.npy')[:valInd]\n",
    "#     X_test=np.load('prepData/X_test_gap_hg38_v3_chr2_size10.npy')[:testInd]\n",
    "#     y_train=np.load('prepData/y_train_gap_hg38_v3_chr2_size10.npy')[:trainInd]\n",
    "#     y_val=np.load('prepData/y_val_gap_hg38_v3_chr2_size10.npy')[:valInd]\n",
    "#     y_test=np.load('prepData/y_test_gap_hg38_v3_chr2_size10.npy')[:testInd]\n",
    "\n",
    "#     y_train1 = np.load('prepData/y_train1_gap_hg38_v3_chr2_size10.npy')[:trainInd]\n",
    "#     y_val1 = np.load('prepData/y_val1_gap_hg38_v3_chr2_size10.npy')[:valInd]\n",
    "#     y_test1 = np.load('prepData/y_test1_gap_hg38_v3_chr2_size10.npy')[:testInd]\n",
    "\n",
    "#     y_train1 = concat(X_train, y_train1)\n",
    "#     y_val1 = concat(X_val, y_val1)\n",
    "#     y_test1 = concat(X_test, y_test1)\n",
    "#     return X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "# hidden = [16, 32, 64,128,256,512]\n",
    "# epoch = [10, 10, 2, 2, 2, 1]\n",
    "hidden = [512]\n",
    "epoch = [10]\n",
    "#X_test, y_test = get_data(train_size, val_size, test_size)\n",
    "for h, e in zip(hidden, epoch):\n",
    "    print(\"Anc : {}, Des : {}, Train size = {}, hidden_size = {}, epoch = {}\".format(ancName, desName, train_size, h, e))\n",
    "    inputAll, predAll, outputAll = grid_predict(train_size, h, e, X_test, y_test)\n",
    "    print(\"The end of Anc : {}, Des : {}, Train size = {}, hidden_size = {}, epoch = {}\".format(ancName, desName,train_size, h, e))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# mapDict = {'A': 'A', 'C': 'C', 'G': 'G', 'T': 'T', '-': '-', 'AA': 'O', 'AC': 'h', '0': '0',\n",
    "#        'AT': 'b', 'AG': 'V', 'CA': 'r', 'CC': 'p', 'CT': 'o', 'CG': 'i', 'TA': 'g', \n",
    "#        'TC': 'I', 'TT': 'f', 'TG': 'L', 'GA': 'B', 'GC': 'c', 'GT': 'X', 'GG': 'P'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def contextMut(size, ancNuc, desNuc, anc, des):\n",
    "    cont = list(itertools.product('ACGT-', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont:\n",
    "        for j in cont:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(seq_length-size*2):\n",
    "            if a[i+size] == ancNuc :\n",
    "                count_dict[(a[i:i+size*2+1])] += 1\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(seq_length-size*2):\n",
    "            if a[i+size] == ancNuc and b[i+size] == desNuc:\n",
    "                context_dict[(a[i:i+size*2+1])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    return sorted_context\n",
    "\n",
    "# pred_contextAG = contextMut(contextLen, 'A', 'G', inputAll, predAll)\n",
    "# true_contextAG = contextMut(contextLen, 'A', 'G', inputAll, outputAll)\n",
    "# pred_contextCT = contextMut(contextLen, 'C', 'T', inputAll, predAll)\n",
    "# true_contextCT = contextMut(contextLen, 'C', 'T', inputAll, outputAll)\n",
    "# print(pred_context)\n",
    "# print(true_context)\n",
    "    \n",
    "# for i in range(100):\n",
    "#     print(pred_context[i], true_context[i])\n",
    "\n",
    "def plotPointMut(n_groups, predSeq, trueSeq, ancNuc, desNuc):\n",
    "    pred = [b for a,b in predSeq][:n_groups]\n",
    "    true = [b for a,b in trueSeq][:n_groups]\n",
    "\n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.05\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, pred, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='b',\n",
    "    label='pred')\n",
    "\n",
    "    rects2 = plt.bar(index + bar_width, true, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='g',\n",
    "    label='true')\n",
    "\n",
    "    plt.xlabel('context')\n",
    "    plt.ylabel('number')\n",
    "    plt.title('{} to {} point mutation'.format(ancNuc, desNuc))\n",
    "    plt.xticks(index + bar_width, [a for (a,b) in trueSeq][:n_groups])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "contextLen = 2\n",
    "numBin = 40\n",
    "np.save('inputAll_{}_{}'.format(ancName, desName), inputAll)\n",
    "np.save('predAll_{}_{}'.format(ancName, desName), predAll)\n",
    "np.save('outputAll_{}_{}'.format(ancName, desName), outputAll)\n",
    "\n",
    "pred_contextAG = contextMut(contextLen, 'A', 'G', inputAll, predAll)\n",
    "true_contextAG = contextMut(contextLen, 'A', 'G', inputAll, outputAll)\n",
    "pred_contextAT = contextMut(contextLen, 'A', 'T', inputAll, predAll)\n",
    "true_contextAT = contextMut(contextLen, 'A', 'T', inputAll, outputAll)\n",
    "pred_contextAC = contextMut(contextLen, 'A', 'C', inputAll, predAll)\n",
    "true_contextAC = contextMut(contextLen, 'A', 'C', inputAll, outputAll)\n",
    "pred_contextCT = contextMut(contextLen, 'C', 'T', inputAll, predAll)\n",
    "true_contextCT = contextMut(contextLen, 'C', 'T', inputAll, outputAll)\n",
    "pred_contextCG = contextMut(contextLen, 'C', 'G', inputAll, predAll)\n",
    "true_contextCG = contextMut(contextLen, 'C', 'G', inputAll, outputAll)\n",
    "pred_contextCA = contextMut(contextLen, 'C', 'A', inputAll, predAll)\n",
    "true_contextCA = contextMut(contextLen, 'C', 'A', inputAll, outputAll)\n",
    "pred_contextGA = contextMut(contextLen, 'G', 'A', inputAll, predAll)\n",
    "true_contextGA = contextMut(contextLen, 'G', 'A', inputAll, outputAll)\n",
    "pred_contextGT = contextMut(contextLen, 'G', 'T', inputAll, predAll)\n",
    "true_contextGT = contextMut(contextLen, 'G', 'T', inputAll, outputAll)\n",
    "pred_contextGC = contextMut(contextLen, 'G', 'C', inputAll, predAll)\n",
    "true_contextGC = contextMut(contextLen, 'G', 'C', inputAll, outputAll)\n",
    "pred_contextTA = contextMut(contextLen, 'T', 'A', inputAll, predAll)\n",
    "true_contextTA = contextMut(contextLen, 'T', 'A', inputAll, outputAll)\n",
    "pred_contextTC = contextMut(contextLen, 'T', 'C', inputAll, predAll)\n",
    "true_contextTC = contextMut(contextLen, 'T', 'C', inputAll, outputAll)\n",
    "pred_contextTG = contextMut(contextLen, 'T', 'G', inputAll, predAll)\n",
    "true_contextTG = contextMut(contextLen, 'T', 'G', inputAll, outputAll)\n",
    "true_contextAgap = contextMut(contextLen, 'A', '-', inputAll, outputAll)\n",
    "pred_contextAgap = contextMut(contextLen, 'A', '-', inputAll, predAll)\n",
    "true_contextCgap = contextMut(contextLen, 'C', '-', inputAll, outputAll)\n",
    "pred_contextCgap = contextMut(contextLen, 'C', '-', inputAll, predAll)\n",
    "true_contextGgap = contextMut(contextLen, 'G', '-', inputAll, outputAll)\n",
    "pred_contextGgap = contextMut(contextLen, 'G', '-', inputAll, predAll)\n",
    "true_contextTgap = contextMut(contextLen, 'T', '-', inputAll, outputAll)\n",
    "pred_contextTgap = contextMut(contextLen, 'T', '-', inputAll, predAll)\n",
    "# print(pred_context)\n",
    "# print(true_context)\n",
    "    \n",
    "plotPointMut(numBin, pred_contextAG, true_contextAG, 'A','G')\n",
    "plotPointMut(numBin, pred_contextAT, true_contextAT, 'A','T')\n",
    "plotPointMut(numBin, pred_contextAC, true_contextAC, 'A','C')\n",
    "plotPointMut(numBin, pred_contextCT, true_contextCT, 'C','T')\n",
    "plotPointMut(numBin, pred_contextCA, true_contextCA, 'C','A')\n",
    "plotPointMut(numBin, pred_contextCG, true_contextCG, 'C','G')\n",
    "plotPointMut(numBin, pred_contextGA, true_contextGA, 'G','A')\n",
    "plotPointMut(numBin, pred_contextGT, true_contextGT, 'G','T')\n",
    "plotPointMut(numBin, pred_contextGC, true_contextGC, 'G','C')\n",
    "plotPointMut(numBin, pred_contextTC, true_contextTC, 'T','C')\n",
    "plotPointMut(numBin, pred_contextTA, true_contextTA, 'T','A')\n",
    "plotPointMut(numBin, pred_contextTG, true_contextTG, 'T','G')\n",
    "plotPointMut(numBin, pred_contextAgap, true_contextAgap, 'A','-')\n",
    "plotPointMut(numBin, pred_contextCgap, true_contextCgap, 'C','-')\n",
    "plotPointMut(numBin, pred_contextGgap, true_contextGgap, 'G','-')\n",
    "plotPointMut(numBin, pred_contextTgap, true_contextTgap, 'T','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqCases(mutList):\n",
    "    sum = 0\n",
    "    for item in mutList:\n",
    "        sum += item[1]\n",
    "    print(sum)\n",
    "\n",
    "freqCases(pred_contextAG)\n",
    "freqCases(pred_contextAgap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScatter(n_groups, predSeq, trueSeq, ancNuc, desNuc):\n",
    "    pred = [b for a,b in predSeq][:n_groups]\n",
    "    true = [b for a,b in trueSeq][:n_groups]\n",
    "    plt.scatter(pred, true, color = 'm')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.axis('scaled')\n",
    "    plt.axis('square')\n",
    "    plt.title('{} to {} point mutation'.format(ancNuc, desNuc))\n",
    "    plt.savefig('figures/scatter_{}_{}_{}_{}_{}->{}.png'.format(ancName, desName, train_size, seq_length, ancNuc, desNuc))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "plotScatter(numBin, pred_contextAG, true_contextAG, 'A','G')\n",
    "plotScatter(numBin, pred_contextAT, true_contextAT, 'A','T')\n",
    "plotScatter(numBin, pred_contextAC, true_contextAC, 'A','C')\n",
    "plotScatter(numBin, pred_contextCT, true_contextCT, 'C','T')\n",
    "plotScatter(numBin, pred_contextCA, true_contextCA, 'C','A')\n",
    "plotScatter(numBin, pred_contextCG, true_contextCG, 'C','G')\n",
    "plotScatter(numBin, pred_contextGA, true_contextGA, 'G','A')\n",
    "plotScatter(numBin, pred_contextGT, true_contextGT, 'G','T')\n",
    "plotScatter(numBin, pred_contextGC, true_contextGC, 'G','C')\n",
    "plotScatter(numBin, pred_contextTC, true_contextTC, 'T','C')\n",
    "plotScatter(numBin, pred_contextTA, true_contextTA, 'T','A')\n",
    "plotScatter(numBin, pred_contextTG, true_contextTG, 'T','G')\n",
    "plotScatter(numBin, pred_contextAgap, true_contextAgap, 'A','-')\n",
    "plotScatter(numBin, pred_contextCgap, true_contextCgap, 'C','-')\n",
    "plotScatter(numBin, pred_contextGgap, true_contextGgap, 'G','-')\n",
    "plotScatter(numBin, pred_contextTgap, true_contextTgap, 'T','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder.transform(np.ones(1).reshape(-1,1))\n",
    "for i in range (100):\n",
    "    print(decoder(X_train[i]), decoder(y_train[i]), decoder(y_train1[i]))\n",
    "    \n",
    "print(y_train[1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
