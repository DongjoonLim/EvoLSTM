{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 30 01:30:22 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 30%   23C    P8     5W / 250W |  10671MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 30%   30C    P8    22W / 250W |  10671MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8     1W / 250W |  10671MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 31%   43C    P2    68W / 250W |  10671MiB / 11019MiB |     11%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  On   | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 30%   28C    P8     7W / 250W |   9139MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  On   | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 30%   36C    P2    52W / 250W |  10671MiB / 11019MiB |     29%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  On   | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 30%   28C    P8    14W / 250W |   5100MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  On   | 00000000:3F:00.0 Off |                  N/A |\n",
      "| 31%   45C    P2    58W / 250W |  10671MiB / 11019MiB |     31%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   8  GeForce RTX 208...  On   | 00000000:40:00.0 Off |                  N/A |\n",
      "| 30%   46C    P2    66W / 250W |  10671MiB / 11019MiB |     31%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   9  GeForce RTX 208...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 31%   44C    P2    66W / 250W |  10671MiB / 11019MiB |     31%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     31977      C   ...m63/miniconda3/envs/research/bin/python 10659MiB |\n",
      "|    1     31894      C   ...m63/miniconda3/envs/research/bin/python 10659MiB |\n",
      "|    2     32066      C   ...m63/miniconda3/envs/research/bin/python 10659MiB |\n",
      "|    3     33983      C   python3                                    10659MiB |\n",
      "|    4     14557      C   ...5/anaconda3/envs/single-cell/bin/python  1399MiB |\n",
      "|    4     15895      C   ...5/anaconda3/envs/single-cell/bin/python  1129MiB |\n",
      "|    4     18188      C   ...5/anaconda3/envs/single-cell/bin/python  1385MiB |\n",
      "|    4     23293      C   ...5/anaconda3/envs/single-cell/bin/python  1741MiB |\n",
      "|    4     30865      C   ...5/anaconda3/envs/single-cell/bin/python  1057MiB |\n",
      "|    4     31362      C   ...5/anaconda3/envs/single-cell/bin/python  1379MiB |\n",
      "|    4     39952      C   ...5/anaconda3/envs/single-cell/bin/python  1037MiB |\n",
      "|    5     32641      C   python3                                    10659MiB |\n",
      "|    6      9128      C   ...a3/envs/tensorflow-gpu-rdkit/bin/python  3959MiB |\n",
      "|    6     27834      C   ...5/anaconda3/envs/single-cell/bin/python  1129MiB |\n",
      "|    7     30241      C   python3                                    10659MiB |\n",
      "|    8     30772      C   python3                                    10659MiB |\n",
      "|    9     31425      C   python3                                    10659MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "86\n",
      "['!' '\"' '$' '%' '&' '(' ')' '*' '+' '-' '.' '/' '0' '1' '2' '3' '4' '5'\n",
      " '6' '7' '8' '9' ':' ';' '<' '=' '>' '?' '@' 'A' 'B' 'C' 'D' 'E' 'F' 'G'\n",
      " 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z'\n",
      " '[' '\\\\' ']' '^' '_' '`' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm'\n",
      " 'n' 'o' 'p' 'q' 's' 't' 'u' 'w' 'x' 'z' '{' '|' '}' '~']\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "from scipy import stats\n",
    "# import tensorflow as tf\n",
    "import math\n",
    "import itertools\n",
    "import operator\n",
    "# from tensorflow.python.keras import backend as k\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import numpy as np\n",
    "# from tensorflow.keras import layers\n",
    "import os\n",
    "from scipy.stats.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import choice\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from bio import AlignIO\n",
    "# from Bio.Align import MultipleSeqAlignment\n",
    "# from Bio.SeqRecord import SeqRecord\n",
    "# from Bio import SeqIO\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "import string\n",
    "from joblib import dump, load\n",
    "\n",
    "%precision 2\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "context_length = 15\n",
    "val_loss_hist = []\n",
    "\n",
    "# K.clear_session()\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "ancName = '_HPGPNRMPC'\n",
    "desName = 'hg38'\n",
    "\n",
    "anc = str(np.load('prepData/insert2Anc_{}_hg38_chr3.npy'.format(ancName)))[:10000000]\n",
    "des = str(np.load('prepData/insert2Des_{}_hg38_chr3.npy'.format(ancName)))[:10000000]\n",
    "anc = np.array(list(anc+'0'))\n",
    "des = np.array(list(des+'0'))\n",
    "\n",
    "# with open('label_encoder.pickle', 'rb') as f:\n",
    "#     label_encoder = pickle.load(f)\n",
    "# with open('onehot_encoder.pickle', 'rb') as f:\n",
    "#     onehot_encoder = pickle.load(f)\n",
    "\n",
    "label_encoder = load('label_encoder.joblib') \n",
    "onehot_encoder = load('onehot_encoder.joblib') \n",
    "\n",
    "integer_encoded_des = label_encoder.transform(des)\n",
    "integer_encoded_anc = label_encoder.transform(anc)\n",
    "integer_des = integer_encoded_des.reshape(len(integer_encoded_des), 1)\n",
    "encoded_des =onehot_encoder.transform(integer_des)\n",
    "integer_anc = integer_encoded_anc.reshape(len(integer_encoded_anc), 1)\n",
    "encoded_anc = onehot_encoder.transform(integer_anc)\n",
    "\n",
    "print(encoded_des)\n",
    "print(encoded_anc)\n",
    "\n",
    "print(len(encoded_des[0]))\n",
    "encode_dimension= len(encoded_des[0])\n",
    "\n",
    "print(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "print(onehot_encoder.transform(np.ones(1).reshape(-1,1)))\n",
    "key = list(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "\n",
    "nucleotide = label_encoder.inverse_transform(range(encode_dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 'A', 'C': 'C', 'G': 'G', 'T': 'T', '-': '-', '0': '0', '^': 'AAA', 'f': 'AAC', '4': 'AAT', 'B': 'AAG', 'w': 'ACA', 't': 'ACC', 'i': 'ACT', 'e': 'ACG', '.': 'ATA', 'c': 'ATC', '>': 'ATT', 'X': 'ATG', '5': 'AGA', '|': 'AGC', '[': 'AGT', 's': 'AGG', 'u': 'CAA', '(': 'CAC', '=': 'CAT', 'q': 'CAG', 'W': 'CCA', '_': 'CCC', '!': 'CCT', '{': 'CCG', '1': 'CTA', 'Q': 'CTC', 'U': 'CTT', 'b': 'CTG', 'M': 'CGA', ';': 'CGC', 'm': 'CGT', '~': 'CGG', 'a': 'TAA', ']': 'TAC', '&': 'TAT', ')': 'TAG', '7': 'TCA', '6': 'TCC', 'p': 'TCT', '%': 'TCG', 'n': 'TTA', 'P': 'TTC', 'F': 'TTT', 'h': 'TTG', '3': 'TGA', ':': 'TGC', 'z': 'TGT', '8': 'TGG', 'R': 'GAA', 'S': 'GAC', '/': 'GAT', 'j': 'GAG', 'o': 'GCA', 'd': 'GCC', '@': 'GCT', 'L': 'GCG', '}': 'GTA', 'H': 'GTC', 'Y': 'GTT', 'x': 'GTG', '\"': 'GGA', 'I': 'GGC', '\\\\': 'GGT', 'J': 'GGG', '9': 'AA', '`': 'AC', 'l': 'AT', '<': 'AG', 'N': 'CA', 'V': 'CC', 'D': 'CT', '+': 'CG', 'E': 'TA', 'Z': 'TC', '$': 'TT', '?': 'TG', '2': 'GA', 'K': 'GC', '*': 'GT', 'g': 'GG'}\n",
      "22587896 22587896 22587896\n",
      "GGCACTGTCT AGCACTGTCT GACACTCTCT\n",
      "42343685 42343685 42343685\n",
      "GTGGTGGTGT GTGGTGGTAT GTGGTGGTGA\n",
      "61140191 61140191 61140191\n",
      "CAAGAACACA CAAGAACACA CAAGAACACA\n",
      "79887837 79887837 79887837\n",
      "AAGCATTTGA AAGCATTTGA AAGCATTTGT\n",
      "104272401 104272401 104272401\n",
      "AAGATTTTGG AAGATATTGG AAGATTTTGA\n",
      "129025047 129025047 129025047\n",
      "TGTGGAAACA TGTGGAAACA TGTGGAAACT\n",
      "149860432 149860432 149860432\n",
      "TAGAGGCCAT TGGAGGCCAT TAGAGGCCAC\n"
     ]
    }
   ],
   "source": [
    "def load_seq(chromList):\n",
    "    inputAll = ''\n",
    "    predAll = ''\n",
    "    outputAll = ''\n",
    "    for chromosome in chromList:\n",
    "        try:\n",
    "            inputAll += str(np.load('prepData/insert2Anc_{}_hg38_chr{}.npy'.format(ancName,chromosome)))#[:10000000]\n",
    "            outputAll += str(np.load('prepData/insert2Des_{}_hg38_chr{}.npy'.format(ancName,chromosome)))#[:10000000]\n",
    "            predAll += str(np.load('prepData/simulated_{}_-1_chr{}.npy'.format(ancName, chromosome)))#[:10000000]\n",
    "        except FileNotFoundError:\n",
    "            print(chromosome)\n",
    "            continue\n",
    "        print(len(inputAll), len(outputAll), len(predAll))\n",
    "        print(inputAll[-10:], outputAll[-10:], predAll[-10:])\n",
    "    return [inputAll], [outputAll], [predAll]\n",
    "\n",
    "# def load_seq(chromList):\n",
    "#     inputAll = ''\n",
    "#     predAll = ''\n",
    "#     outputAll = ''\n",
    "#     for chromosome in chromList:\n",
    "#         inputAll += str(np.load('prepData/insert2Anc_{}_hg38_chr{}.npy'.format(ancName,chromosome)))[:10000000]\n",
    "#         outputAll += str(np.load('prepData/insert2Des_{}_hg38_chr{}.npy'.format(ancName,chromosome)))[:10000000]\n",
    "#         predAll += str(np.load('simulated_{}_10000000_chr{}.npy'.format(ancName, chromosome)))[:10000000]\n",
    "#     return [inputAll], [outputAll], [predAll]\n",
    "    \n",
    "mut_dict = np.load('mut_dict_insert2.npy',allow_pickle=True).item()\n",
    "inv_dict = {v: k for k, v in mut_dict.items()}\n",
    "print(inv_dict)\n",
    "\n",
    "inputAll, outputAll, predAll = load_seq([12,16,17,19,20,21,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# decoded_seq = str(np.load('simulated_{}_10000000_chr{}.npy'.format(ancName, chromosome)))\n",
    "# inputAll =[''.join(anc)[:-1]]\n",
    "# predAll = [decoded_seq[:-1]]\n",
    "# outputAll = [''.join(des)[:-1]\n",
    "k = 1\n",
    "lstm_inputAll = [''.join(anc)[:2000000]]\n",
    "lstm_predAll = [str(np.load('simulated_{}_lstm.npy'.format(ancName)))]\n",
    "lstm_outputAll = [''.join(des)[:2000000]]\n",
    "contextLen = 1\n",
    "numBin = 10\n",
    "def contextMut(size, ancNuc, desNuc, anc, des, pred, evol, lstm = False, table='', tableCon = 0):\n",
    "    cont = list(itertools.product('ACGT', repeat=size))\n",
    "    cont1 = list(itertools.product('ACGT', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont1:\n",
    "        for j in cont1:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            if a[i+size:i+size+len(ancNuc)] == ancNuc :\n",
    "                count_dict[(a[i:i+size*2+len(ancNuc)])] += 1\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            if a[i+size:i+size+len(ancNuc)] == ancNuc and b[i+size+int(len(ancNuc)/2)] == desNuc:\n",
    "                context_dict[(a[i:i+size*2+len(ancNuc)])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    sorted_context = dict(sorted_context)\n",
    "    if lstm ==False:\n",
    "        if pred == True and evol ==False:\n",
    "            np.save('data/pred{}_context{}->{}_{}_{}_{}.npy'.format(table,ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "        elif pred == True and evol == True:\n",
    "            np.save('data/pred{}_evol_context{}->{}_{}_{}_{}.npy'.format(table,ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "        elif pred == False and evol ==False:\n",
    "            np.save('data/true_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "        elif pred == False and evol ==True:\n",
    "            np.save('data/true_evol_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "        return sorted_context\n",
    "    elif lstm ==True :\n",
    "        if pred == True:\n",
    "            np.save('data/pred_lstm_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "        elif pred ==False:\n",
    "            np.save('data/true_lstm_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "    return sorted_context\n",
    "            \n",
    "def contextMutInsert(size, ancNuc, desNuc, anc, des, pred, evol, lstm = False, table = '',tableCon = 0):\n",
    "    cont1 = list(itertools.product('ACGT', repeat=size-1))\n",
    "    cont = list(itertools.product('ACGT', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont:\n",
    "        for j in cont:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            count_dict[(a[i:i+size]+ancNuc+a[i+size+len(ancNuc):i+size*2+len(ancNuc)])] += 1\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            inserted_nuc = inv_dict[b[i+size+int(len(ancNuc)/2)-1]]\n",
    "            if len(inserted_nuc) >1 and inserted_nuc[1] == desNuc:\n",
    "                context_dict[(a[i:i+size]+ancNuc+a[i+size+len(ancNuc):i+size*2+len(ancNuc)])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    sorted_context = dict(sorted_context)\n",
    "    if lstm ==False:\n",
    "        if pred == True and evol ==False:\n",
    "            np.save('data/pred{}_context{}->{}_{}_{}_{}.npy'.format(table,ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "        elif pred == True and evol == True:\n",
    "            np.save('data/pred{}_evol_context{}->{}_{}_{}_{}.npy'.format(table,ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "        elif pred == False and evol ==False:\n",
    "            np.save('data/true_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "        elif pred == False and evol ==True:\n",
    "            np.save('data/true_evol_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "        return sorted_context\n",
    "    elif lstm ==True :\n",
    "        if pred == True:\n",
    "            np.save('data/pred_lstm_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "        elif pred ==False:\n",
    "            np.save('data/true_lstm_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), sorted_context)\n",
    "    return sorted_context\n",
    "            \n",
    "def decodeList(inputAll, predAll, outputAll):\n",
    "    inp =[]\n",
    "    inp2 = []\n",
    "    pre = []\n",
    "    out = []\n",
    "    for i, p, o in tqdm(zip(inputAll, predAll, outputAll)):\n",
    "        input, pred = decodeDictSeq(i, p, mut_dict)\n",
    "        input2, output = decodeDictSeq(i,o, mut_dict)\n",
    "        inp.append(input)\n",
    "        inp2.append(input2)\n",
    "        pre.append(pred)\n",
    "        out.append(output)\n",
    "    return inp, inp2, pre, out\n",
    "\n",
    "def valueFloat(data_list):\n",
    "    newDict = dict(zip(data_list.keys(), [float(value) for value in data_list.values()]))\n",
    "    return newDict\n",
    "def plotPointMut(n_groups,ancNuc, desNuc):\n",
    "    predSeq = np.load('data/pred_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), allow_pickle = True).item()\n",
    "\n",
    "    trueSeq = np.load('data/true_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), allow_pickle = True).item()\n",
    "\n",
    "#     evolSeq = np.load('data/true_evol_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), allow_pickle = True).item()\n",
    "    \n",
    "    lstmSeq = np.load('data/pred_lstm_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), allow_pickle = True).item()\n",
    "\n",
    "    true = list(trueSeq.values())[:n_groups]\n",
    "    true_context = list(trueSeq.keys())[:n_groups]\n",
    "    pred = []\n",
    "    evol = []\n",
    "    lstm = []\n",
    "    for i in true_context:\n",
    "        pred.append(predSeq[i])\n",
    "#         evol.append(evolSeq[i])\n",
    "        lstm.append(lstmSeq[i])\n",
    "\n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.05\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, pred, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='b',\n",
    "    label='seq2seq_pred')\n",
    "    \n",
    "    rects2 = plt.bar(index + bar_width, lstm, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='m',\n",
    "    label='lstm_pred')\n",
    "    \n",
    "    rects3 = plt.bar(index + bar_width*2, true, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='g',\n",
    "    label='true')\n",
    "    \n",
    "#     rects3 = plt.bar(index + bar_width*3, evol, bar_width,\n",
    "#     alpha=opacity,\n",
    "#     color='r',\n",
    "#     label='evol_pred')\n",
    "\n",
    "    plt.xlabel('context')\n",
    "    plt.ylabel('rate')\n",
    "    plt.title('{} to {} point mutation'.format(ancNuc, desNuc))\n",
    "    plt.xticks(index + bar_width, list(trueSeq.keys())[:n_groups])\n",
    "    plt.legend()\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plotScatter(n_groups, ancNuc, desNuc,k, tableCon):\n",
    "    predSeq = np.load('data/pred_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), allow_pickle = True).item()\n",
    "\n",
    "    tableSeq = np.load('data/predTable_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), allow_pickle = True).item()\n",
    "    \n",
    "    trueSeq = np.load('data/true_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), allow_pickle = True).item()\n",
    "\n",
    "#     evolSeq = np.load('data/true_evol_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), allow_pickle = True).item()\n",
    "    \n",
    "    lstmSeq = np.load('data/pred_lstm_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon, k*2+1), allow_pickle = True).item()\n",
    "\n",
    "    true = list(trueSeq.values())\n",
    "    true_context = list(trueSeq.keys())\n",
    "    pred = []\n",
    "    evol = []\n",
    "    lstm = []\n",
    "    table = []\n",
    "    for i in true_context:\n",
    "        pred.append(predSeq[i])\n",
    "#         evol.append(evolSeq[i])\n",
    "        lstm.append(lstmSeq[i])\n",
    "        table.append(tableSeq[i])\n",
    "        \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(15,5))\n",
    "    f.text(0.5, 0.0, 'Observed', ha='center', va='center', fontsize = 20)\n",
    "    f.text(0.05, 0.5, 'Predicted', ha='center', va='center', rotation='vertical', fontsize = 20)\n",
    "    \n",
    "    ax1.scatter(true, table, color = 'y', label = 'freqTable')\n",
    "\n",
    "#     ax1.axis('scaled')\n",
    "#     ax1.axis('square')\n",
    "    ax1.set_xlim([0, 1.2 * max(max(table), max(true))])\n",
    "    ax1.set_ylim([0, 1.2 * max(max(table), max(true))])\n",
    "    ax1.text(0.5,1, \"r = {}\".format(stats.pearsonr(table, true)[0]), size=15, ha=\"center\", \n",
    "                         transform=ax1.transAxes)\n",
    "    ax1.set_title('wx{}yz to wx{}yz point mutation'.format(ancNuc, desNuc), y=1.08, fontsize = 16)\n",
    "    for i, txt in enumerate(list(trueSeq.keys())):\n",
    "        if i%30 == 0:\n",
    "            ax1.annotate(txt, (true[i], table[i]))\n",
    "\n",
    "    ax1.legend()\n",
    "    \n",
    "    \n",
    "    ax2.scatter(true, lstm, color = 'c', label = 'lstm')\n",
    "    for i, txt in enumerate(list(lstmSeq.keys())):\n",
    "        if i%30 == 0:\n",
    "            ax2.annotate(txt, (true[i], lstm[i]))\n",
    "\n",
    "#     ax2.axis('scaled')\n",
    "#     ax2.axis('square')\n",
    "    ax2.set_xlim([0, 1.2 * max(max(table), max(lstm), max(true))])\n",
    "    ax2.set_ylim([0, 1.2* max(max(table), max(lstm), max(true))])\n",
    "    ax2.text(0.5,1, \"r = {}\".format(stats.pearsonr(lstm, true)[0]), size=15, ha=\"center\", \n",
    "                             transform=ax2.transAxes)\n",
    "    ax2.legend()\n",
    "    ax2.set_title('wx{}yz to wz{}yz point mutation'.format(ancNuc, desNuc), y=1.08, fontsize = 16)\n",
    "    \n",
    "    ax3.scatter(true, pred, color = 'm', label = 'EvoLSTM')\n",
    "\n",
    "#     ax3.axis('scaled')\n",
    "#     ax3.axis('square')\n",
    "    ax3.set_xlim([0, 1.2 * max(max(pred), max(true))])\n",
    "    ax3.set_ylim([0, 1.2 * max(max(pred), max(true))])\n",
    "    ax3.text(0.5,1, \"r = {}\".format(stats.pearsonr(pred, true)[0]), size=15, ha=\"center\", \n",
    "                         transform=ax3.transAxes)\n",
    "    ax3.set_title('xy{}zw to xy{}zw point mutation'.format(ancNuc, desNuc), y=1.08, fontsize = 16)\n",
    "    for i, txt in enumerate(list(trueSeq.keys())):\n",
    "        if i%30 == 0:\n",
    "            ax3.annotate(txt, (true[i], pred[i]))\n",
    "\n",
    "    ax3.legend()\n",
    "    \n",
    "    f.savefig('figures/scatter_{}_{}_{}->{}_{}.png'.format(ancName, desName,  ancNuc, desNuc,k, tableCon))\n",
    "    f.show()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return ('{} $rightarrow$ {} & {:.3f} & {:.3f} & {:.3f}'.format(ancNuc, desNuc,stats.pearsonr(pred, true)[0], stats.pearsonr(lstm, true)[0], stats.pearsonr(table, true)[0] ))\n",
    "#     print(stats.pearsonr(pred, true), stats.pearsonr(lstm, true))\n",
    "            \n",
    "\n",
    "# np.save('inputAll_{}_{}'.format(ancName, desName), inputAll)\n",
    "# np.save('predAll_{}_{}'.format(ancName, desName), predAll)\n",
    "# np.save('outputAll_{}_{}'.format(ancName, desName), outputAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputAll, inputAll2, predAll, outputAll= decodeList(inputAll, predAll, outputAll)\n",
    "# lstm_inputAll, lstm_inputAll2, lstm_predAll, lstm_outputAll = decodeList(lstm_inputAll, lstm_predAll, lstm_outputAll)\n",
    "k = 1\n",
    "def plotCombine(k, tableCon):\n",
    "    contextLen = k\n",
    "    predTable = [str(np.load('predTable_{}.npy'.format(tableCon)))]\n",
    "    ancCase = ['A','C','G','T']\n",
    "    desCase = ['A','C','G','T','-']\n",
    "    for i in tqdm_notebook(ancCase):\n",
    "        for j in desCase:\n",
    "            if i != j:\n",
    "                contextMut(contextLen, i, j, inputAll, predAll, pred = True, evol = False, tableCon= tableCon)\n",
    "                contextMut(contextLen, i, j, inputAll, predTable, pred = True, evol = False, table = 'Table', tableCon= tableCon)\n",
    "                contextMut(contextLen, i, j, inputAll, outputAll, pred = False, evol = False, tableCon= tableCon)\n",
    "                contextMut(contextLen, i, j, lstm_inputAll, lstm_predAll, pred = True, evol = False, lstm = True, tableCon= tableCon)\n",
    "    ancCase = ['-']\n",
    "    desCase = ['A','C','G','T']\n",
    "    for i in tqdm_notebook(ancCase):\n",
    "        for j in desCase:\n",
    "            contextMutInsert(contextLen, i, j, inputAll, predAll, pred = True, evol = False, tableCon= tableCon)\n",
    "            contextMutInsert(contextLen, i, j, inputAll, predTable, pred = True, evol = False, table = 'Table', tableCon= tableCon)\n",
    "            contextMutInsert(contextLen, i, j, inputAll, outputAll, pred = False, evol = False, tableCon= tableCon)\n",
    "            contextMutInsert(contextLen, i, j, lstm_inputAll, lstm_predAll, pred = True, evol = False, lstm = True, tableCon= tableCon)\n",
    "\n",
    "    ancCase = ['A','C','G','T','-']\n",
    "    desCase = ['A','C','G','T','-']\n",
    "\n",
    "\n",
    "    values = []\n",
    "    for i in tqdm_notebook(ancCase):\n",
    "        for j in desCase:\n",
    "            if i != j:\n",
    "                values.append(plotScatter(numBin,i, j, k, tableCon))\n",
    "    for item in values:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d40b663e64f4cd8b7fda564a2707eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotCombine(1, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotCombine(2, 5)\n",
    "# ancCase = ['C','A','C','T','-']\n",
    "# desCase = ['T','G','A','-','T']\n",
    "# # for i in ancCase:\n",
    "# #     for j in desCase:\n",
    "# #         if i != j:\n",
    "# #             plotPointMut(numBin,i, j)\n",
    "\n",
    "\n",
    "\n",
    "# for i, j in zip(ancCase, desCase):\n",
    "#         if i != j:\n",
    "#             plotScatter(numBin,i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotCombine(2, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def analyzeMut(ancNuc, desNuc):\n",
    "    predSeq = np.load('data/pred_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,15,k*2+1), allow_pickle = True).item()\n",
    "\n",
    "    tableSeq = np.load('data/predTable_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,15,k*2+1), allow_pickle = True).item()\n",
    "    \n",
    "    trueSeq = np.load('data/true_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,15,k*2+1), allow_pickle = True).item()\n",
    "\n",
    "#     evolSeq = np.load('data/true_evol_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), allow_pickle = True).item()\n",
    "    \n",
    "    lstmSeq = np.load('data/pred_lstm_context{}->{}_{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,15,k*2+1), allow_pickle = True).item()\n",
    "    \n",
    "    return predSeq, tableSeq , trueSeq, lstmSeq\n",
    "\n",
    "ancNuc = ['A', 'C', 'G', 'T', '-']\n",
    "desNuc = ['A', 'C', 'G', 'T', '-']    \n",
    "\n",
    "for i in ancNuc:\n",
    "    for j in desNuc:\n",
    "        if i != j :\n",
    "            print('=========================================================================================================')\n",
    "            pred, table, true, lstm = analyzeMut(i,j)\n",
    "            pred = collections.OrderedDict(sorted(pred.items()))\n",
    "            table = collections.OrderedDict(sorted(table.items()))\n",
    "            lstm = collections.OrderedDict(sorted(lstm.items()))\n",
    "            true = collections.OrderedDict(sorted(true.items()))\n",
    "            print('Context of {} -> {}'.format(i,j))\n",
    "            for a, b, c, d, e, f, g,h in zip(pred.keys(), pred.values(), table.keys(), table.values(), lstm.keys(), lstm.values(), true.keys(), true.values()):\n",
    "                print(\"\")\n",
    "                print('EvoLSTM :', a,'{:,.5f}'.format(b), '|' ,'Table :', c, '{:,.5f}'.format(d), '|', 'lstm :' ,e,'{:,.5f}'.format(f), '|', 'Observed :' ,g,'{:,.5f}'.format(h),  '\\\\', \"\\\\\" )\n",
    "            print('=========================================================================================================')\n",
    "            print()\n",
    "            print()\n",
    "    \n",
    "pred, table, true, lstm = analyzeMut('A','G')\n",
    "# for a, b, c, d, e, f in zip(pred.keys(), pred.values(), table.keys(), table.values(), true.keys(), true.values()):\n",
    "#     print(\"\")\n",
    "#     print( a,'{:,.5f}'.format(b), '|' , c, '{:,.5f}'.format(d), '|' ,e,'{:,.5f}'.format(f), '\\\\', \"\\\\\" )\n",
    "# for a, b, c, d, e, f in zip(pred.keys(), pred.values(), table.keys(), table.values(), true.keys(), true.values()):\n",
    "#     print('EvoLSTM: ', a,b, 'Table:', c, d, | 'Observed: ',e,f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(3, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(4, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextLength = 1\n",
    "numBin = 16\n",
    "def contextMut(size, ancNuc, desNuc, anc, des, pred, evol, lstm = False):\n",
    "    cont = list(itertools.product('ACGT', repeat=size))\n",
    "    cont1 = list(itertools.product('ACGT', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont1:\n",
    "        for j in cont1:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            if a[i+size:i+size+len(ancNuc)] == ancNuc :\n",
    "                count_dict[(a[i:i+size*2+len(ancNuc)])] += 1\n",
    "    for a,b in tqdm_notebook(zip(anc, des)):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            if a[i+size:i+size+len(ancNuc)] == ancNuc and b[i+size+int(len(ancNuc)/2)] == desNuc:\n",
    "                context_dict[(a[i:i+size*2+len(ancNuc)])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    sorted_context = dict(sorted_context)\n",
    "    if lstm ==False:\n",
    "        if pred == True and evol ==False:\n",
    "            np.save('data/pred_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == True and evol == True:\n",
    "            np.save('data/pred_evol_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == False and evol ==False:\n",
    "            np.save('data/true_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == False and evol ==True:\n",
    "            np.save('data/true_evol_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        return sorted_context\n",
    "    elif lstm ==True :\n",
    "        if pred == True:\n",
    "            np.save('data/pred_lstm_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred ==False:\n",
    "            np.save('data/true_lstm_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "    return sorted_context\n",
    "            \n",
    "def contextMutInsert(size, ancNuc, desNuc, anc, des, pred, evol, lstm = False):\n",
    "    cont1 = list(itertools.product('ACGT', repeat=size-1))\n",
    "    cont = list(itertools.product('ACGT', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont:\n",
    "        for j in cont:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            count_dict[(a[i:i+size]+ancNuc+a[i+size+len(ancNuc):i+size*2+len(ancNuc)])] += 1\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            inserted_nuc = inv_dict[b[i+size+int(len(ancNuc)/2)-1]]\n",
    "            if len(inserted_nuc) >1 and inserted_nuc[1] == desNuc:\n",
    "                context_dict[(a[i:i+size]+ancNuc+a[i+size+len(ancNuc):i+size*2+len(ancNuc)])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    sorted_context = dict(sorted_context)\n",
    "    if lstm ==False:\n",
    "        if pred == True and evol ==False:\n",
    "            np.save('data/pred_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == True and evol == True:\n",
    "            np.save('data/pred_evol_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == False and evol ==False:\n",
    "            np.save('data/true_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == False and evol ==True:\n",
    "            np.save('data/true_evol_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        return sorted_context\n",
    "    elif lstm ==True :\n",
    "        if pred == True:\n",
    "            np.save('data/pred_lstm_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred ==False:\n",
    "            np.save('data/true_lstm_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "    return sorted_context\n",
    "            \n",
    "def calculateR(contextLen, ancCase, desCase):\n",
    "    sorted_context = contextMut(contextLen, ancCase, desCase, inputAll, predAll, pred = True, evol = False)\n",
    "    contextMut(contextLen, ancCase, desCase, inputAll, outputAll, pred = False, evol = False)\n",
    "    contextMut(contextLen, ancCase, desCase, lstm_inputAll, lstm_predAll, pred = True, evol = False, lstm = True)\n",
    "\n",
    "    sorted_word = list(sorted_context.keys())\n",
    "    top = sorted_word[0]\n",
    "    mid = sorted_word[int(len(sorted_word)/2)]\n",
    "    bot = sorted_word[-1]\n",
    "    return top, mid, bot\n",
    "\n",
    "def calculateRInsert(contextLen, ancCase, desCase):\n",
    "    sorted_context = contextMutInsert(contextLen, ancCase, desCase, inputAll, predAll, pred = True, evol = False)\n",
    "    contextMutInsert(contextLen, ancCase, desCase, inputAll, outputAll, pred = False, evol = False)\n",
    "    contextMutInsert(contextLen, ancCase, desCase, lstm_inputAll, lstm_predAll, pred = True, evol = False, lstm = True)\n",
    "\n",
    "    sorted_word = list(sorted_context.keys())\n",
    "    top = sorted_word[0]\n",
    "    mid = sorted_word[int(len(sorted_word)/2)]\n",
    "    bot = sorted_word[-1]\n",
    "    return top, mid, bot\n",
    "    \n",
    "def plotContextChange(contLen, ancCase, desCase, insert = False):\n",
    "    contextLen = contLen\n",
    "    if insert == True:\n",
    "        top, mid, bot = calculateRInsert(contextLen, ancCase, desCase)\n",
    "        \n",
    "        tt, tm, tb = calculateRInsert(contextLen, top, desCase)\n",
    "        mt, mm, mb = calculateRInsert(contextLen, mid, desCase)\n",
    "        bt, bm, bb = calculateRInsert(contextLen, bot, desCase)\n",
    "\n",
    "        ttt, ttm, ttb = calculateRInsert(contextLen, tt, desCase)\n",
    "        mmt, mmm, mmb = calculateRInsert(contextLen, mm, desCase)\n",
    "        bbt, bbm, bbb = calculateRInsert(contextLen, bb, desCase)\n",
    "    else :\n",
    "        top, mid, bot = calculateR(contextLen, ancCase, desCase)\n",
    "        tt, tm, tb = calculateR(contextLen, top, desCase)\n",
    "        mt, mm, mb = calculateR(contextLen, mid, desCase)\n",
    "        bt, bm, bb = calculateR(contextLen, bot, desCase)\n",
    "\n",
    "        ttt, ttm, ttb = calculateR(contextLen, tt, desCase)\n",
    "        mmt, mmm, mmb = calculateR(contextLen, mm, desCase)\n",
    "        bbt, bbm, bbb = calculateR(contextLen, bb, desCase)\n",
    "    \n",
    "    \n",
    "    topList = [ancCase, top, tt]\n",
    "    midList = [ancCase, mid, mm]\n",
    "    botList = [ancCase, bot, bb]\n",
    "    ancWords = [topList, midList, botList]\n",
    "    \n",
    "\n",
    "    print(topList)\n",
    "    print(midList)\n",
    "    print(botList)\n",
    "    print(ancWords)\n",
    "#     topList =['A', 'CAT', 'CCATG']\n",
    "#     midList =['A', 'AAC', 'AAACT']\n",
    "#     botList =['A', 'GAA', 'TGAAA']\n",
    "#     ancWords =[['A', 'CAT', 'CCATG'], ['A', 'AAC', 'AAACT'], ['A', 'GAA', 'TGAAA']]\n",
    "    \n",
    "    f, axs = plt.subplots(3, 3, sharex=False, sharey=False, figsize=(20,20))\n",
    "    axs = axs.flatten()\n",
    "    f.text(0.5, 0.08, 'Observed', ha='center', va='center', fontsize=40)\n",
    "    f.text(0.05, 0.5, 'Predicted', ha='center', va='center', rotation='vertical', fontsize=40)\n",
    "    f.suptitle('Effect of adding flanking base contexts to {}->{} mutation'.format(ancCase, desCase), fontsize =30)\n",
    "\n",
    "    index = 0\n",
    "    for words in tqdm(ancWords):\n",
    "        for j in desCase:\n",
    "            for n, i in enumerate(words):\n",
    "                if i != j:\n",
    "                    predSeq = np.load('data/pred_context{}->{}_{}.npy'.format(i,j,ancName), allow_pickle = True).item()\n",
    "                    trueSeq = np.load('data/true_context{}->{}_{}.npy'.format(i,j,ancName), allow_pickle = True).item()\n",
    "                    true = list(trueSeq.values())\n",
    "                    true_context = list(trueSeq.keys())\n",
    "                    pred = []\n",
    "                    for x in true_context:\n",
    "                        pred.append(predSeq[x])\n",
    "                    axs[index].scatter(true, pred, color = 'm')\n",
    "#                     axs[index].axis('scaled')\n",
    "#                     axs[index].axis('square')\n",
    "                    axs[index].set_xlim([0, 1.1 * max(max(pred), max(true))])\n",
    "                    axs[index].set_ylim([0, 1.1 * max(max(pred), max(true))])\n",
    "                    axs[index].text(0.5,1.0, \"r = {}\".format(stats.pearsonr(pred, true)[0]), size=20, ha=\"center\", \n",
    "                             transform=axs[index].transAxes)\n",
    "                    axs[index].set_title('x{}y to {} point mutation'.format(i, j), fontsize=25, y=1.08)\n",
    "                    for i, txt in enumerate(list(predSeq.keys())):\n",
    "                        if i %3 ==0 or i%(int(len(true)/2))==0 or i%(int(len(true)-1))==0:\n",
    "                            axs[index].annotate(txt, (true[i], pred[i]))\n",
    "\n",
    "                    index += 1\n",
    "                    f.savefig('figures/scatter_conChange_{}_{}_{}->{}.png'.format(ancName, desName,  ancCase, desCase))\n",
    "#                     print('pearson corr: ', stats.pearsonr(pred, true)[0])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "#                     plotPointMut(numBin,i, j)\n",
    "#                     plotScatter(numBin,i, j)\n",
    "#     analyzeMut(ancCase[0],desCase[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotContextChange(1, 'A', 'G', insert = False)\n",
    "plotContextChange(1, 'C', 'T', insert = False)\n",
    "plotContextChange(1, 'A', '-', insert = False)\n",
    "plotContextChange(1, '-', 'T', insert = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzeMut('TAG','G')\n",
    "contextMut(contextLen, 'TAG', 'G', inputAll, predAll, pred = True, evol = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
