{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 28 20:35:36 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8     5W / 250W |     12MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 30%   35C    P8    22W / 250W |     12MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 30%   30C    P8     1W / 250W |     12MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 31%   44C    P2    71W / 250W |  10671MiB / 11019MiB |     32%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  On   | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 30%   29C    P8     7W / 250W |   9017MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  On   | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 30%   36C    P2    52W / 250W |  10671MiB / 11019MiB |     34%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  On   | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 30%   27C    P8    15W / 250W |   5100MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  On   | 00000000:3F:00.0 Off |                  N/A |\n",
      "| 31%   44C    P2    57W / 250W |  10671MiB / 11019MiB |     11%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   8  GeForce RTX 208...  On   | 00000000:40:00.0 Off |                  N/A |\n",
      "| 30%   46C    P2    67W / 250W |  10671MiB / 11019MiB |     30%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   9  GeForce RTX 208...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 31%   45C    P2    66W / 250W |  10671MiB / 11019MiB |     30%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    3     28052      C   python3                                    10659MiB |\n",
      "|    4     14557      C   ...5/anaconda3/envs/single-cell/bin/python  1399MiB |\n",
      "|    4     15895      C   ...5/anaconda3/envs/single-cell/bin/python  1129MiB |\n",
      "|    4     18188      C   ...5/anaconda3/envs/single-cell/bin/python  1385MiB |\n",
      "|    4     23293      C   ...5/anaconda3/envs/single-cell/bin/python  1619MiB |\n",
      "|    4     30865      C   ...5/anaconda3/envs/single-cell/bin/python  1057MiB |\n",
      "|    4     31362      C   ...5/anaconda3/envs/single-cell/bin/python  1379MiB |\n",
      "|    4     39952      C   ...5/anaconda3/envs/single-cell/bin/python  1037MiB |\n",
      "|    5     26077      C   python3                                    10659MiB |\n",
      "|    6      9128      C   ...a3/envs/tensorflow-gpu-rdkit/bin/python  3959MiB |\n",
      "|    6     27834      C   ...5/anaconda3/envs/single-cell/bin/python  1129MiB |\n",
      "|    7     19157      C   python3                                    10659MiB |\n",
      "|    8     14389      C   python3                                    10659MiB |\n",
      "|    9     12384      C   python3                                    10659MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import itertools\n",
    "import operator\n",
    "from tensorflow.python.keras import backend as k\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from scipy.stats.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import choice\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from bio import AlignIO\n",
    "# from Bio.Align import MultipleSeqAlignment\n",
    "# from Bio.SeqRecord import SeqRecord\n",
    "# from Bio import SeqIO\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras_preprocessing import sequence\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "import string\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "86\n",
      "['!' '\"' '$' '%' '&' '(' ')' '*' '+' '-' '.' '/' '0' '1' '2' '3' '4' '5'\n",
      " '6' '7' '8' '9' ':' ';' '<' '=' '>' '?' '@' 'A' 'B' 'C' 'D' 'E' 'F' 'G'\n",
      " 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z'\n",
      " '[' '\\\\' ']' '^' '_' '`' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm'\n",
      " 'n' 'o' 'p' 'q' 's' 't' 'u' 'w' 'x' 'z' '{' '|' '}' '~']\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "7871309\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%precision 2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "context_length = 15\n",
    "val_loss_hist = []\n",
    "\n",
    "# K.clear_session()\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "ancName = '_HPGPNRMPC'\n",
    "desName = 'hg38'\n",
    "\n",
    "\n",
    "anc = str(np.load('prepData/insert2Anc_{}_{}_gene+_chr2.npy'.format(ancName, desName)))\n",
    "des = str(np.load('prepData/insert2Des_{}_{}_gene+_chr2.npy'.format(ancName, desName)))\n",
    "anc = np.array(list(anc+'0'))\n",
    "des = np.array(list(des+'0'))\n",
    "\n",
    "# with open('label_encoder.pickle', 'rb') as f:\n",
    "#     label_encoder = pickle.load(f)\n",
    "# with open('onehot_encoder.pickle', 'rb') as f:\n",
    "#     onehot_encoder = pickle.load(f)\n",
    "\n",
    "label_encoder = load('label_encoder.joblib') \n",
    "onehot_encoder = load('onehot_encoder.joblib') \n",
    "\n",
    "integer_encoded_des = label_encoder.transform(des)\n",
    "integer_encoded_anc = label_encoder.transform(anc)\n",
    "integer_des = integer_encoded_des.reshape(len(integer_encoded_des), 1)\n",
    "encoded_des =onehot_encoder.transform(integer_des)\n",
    "integer_anc = integer_encoded_anc.reshape(len(integer_encoded_anc), 1)\n",
    "encoded_anc = onehot_encoder.transform(integer_anc)\n",
    "\n",
    "print(encoded_des)\n",
    "print(encoded_anc)\n",
    "\n",
    "print(len(encoded_des[0]))\n",
    "encode_dimension= len(encoded_des[0])\n",
    "\n",
    "print(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "print(onehot_encoder.transform(np.ones(1).reshape(-1,1)))\n",
    "key = list(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "\n",
    "nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "print(len(anc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7871308/7871308 [11:53:46<00:00, 183.79it/s]  IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(input_seq, model, encoder_model, decoder_model):\n",
    "    length = len(input_seq)\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    index = 0\n",
    "    initial_context = np.expand_dims(input_seq[0: context_length], axis=0)\n",
    "    states_value = encoder_model.predict(initial_context)\n",
    "    target_seq = np.zeros((1, 1, encode_dimension*2))\n",
    "    target_seq[0][0]= np.hstack((input_seq[0], onehot_encoder.transform(np.ones(1).reshape(-1,1))[0]))\n",
    "    decoded_seq = ''\n",
    "    for i in tqdm(range(1, length)):\n",
    "        if i%context_length == 0 :\n",
    "            context = np.expand_dims(input_seq[i: i+context_length], axis=0)\n",
    "            states_value = encoder_model.predict(context)\n",
    "            \n",
    "#         stop_condition = False\n",
    "        \n",
    "#         while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        sampled_token_index = np.random.choice(encode_dimension, 1, p=output_tokens[0, -1, :])[0]\n",
    "        sampled_nucleotide = nucleotide[sampled_token_index]\n",
    "\n",
    "        if (sampled_nucleotide == '') or (not sampled_nucleotide.isprintable()) or (sampled_nucleotide.isspace()):\n",
    "            decoded_seq += '0'\n",
    "        else :\n",
    "            decoded_seq += sampled_nucleotide\n",
    "#         if (len(decoded_seq) == context_length):\n",
    "#             break\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, encode_dimension*2))\n",
    "        temp = np.zeros((encode_dimension))\n",
    "        temp[sampled_token_index] = 1\n",
    "        target_seq[0][0]= np.hstack((input_seq[i], temp))\n",
    "        \n",
    "        if i == length -1:\n",
    "            output_tokens, h, c = decoder_model.predict(\n",
    "                [target_seq] + states_value)\n",
    "            sampled_token_index = np.random.choice(encode_dimension, 1, p=output_tokens[0, -1, :])[0]\n",
    "            sampled_nucleotide = nucleotide[sampled_token_index]\n",
    "\n",
    "            decoded_seq += sampled_nucleotide\n",
    "            \n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_seq\n",
    "\n",
    "\n",
    "model = load_model(\"models/insert2__HPGPNRMPC_hg38__HPGPNRMPC_hg38_+_10.h5\")\n",
    "encoder_model = load_model(\"models/E_insert2__HPGPNRMPC_hg38__HPGPNRMPC_hg38_+_10.h5\")\n",
    "decoder_model = load_model(\"models/D_insert2__HPGPNRMPC_hg38__HPGPNRMPC_hg38_+_10.h5\")\n",
    "decoded_seq = decode_sequence(encoded_anc, model, encoder_model, decoder_model)\n",
    "print(decoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prepData/decoded_+', decoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 'A', 'C': 'C', 'G': 'G', 'T': 'T', '-': '-', '0': '0', '^': 'AAA', 'f': 'AAC', '4': 'AAT', 'B': 'AAG', 'w': 'ACA', 't': 'ACC', 'i': 'ACT', 'e': 'ACG', '.': 'ATA', 'c': 'ATC', '>': 'ATT', 'X': 'ATG', '5': 'AGA', '|': 'AGC', '[': 'AGT', 's': 'AGG', 'u': 'CAA', '(': 'CAC', '=': 'CAT', 'q': 'CAG', 'W': 'CCA', '_': 'CCC', '!': 'CCT', '{': 'CCG', '1': 'CTA', 'Q': 'CTC', 'U': 'CTT', 'b': 'CTG', 'M': 'CGA', ';': 'CGC', 'm': 'CGT', '~': 'CGG', 'a': 'TAA', ']': 'TAC', '&': 'TAT', ')': 'TAG', '7': 'TCA', '6': 'TCC', 'p': 'TCT', '%': 'TCG', 'n': 'TTA', 'P': 'TTC', 'F': 'TTT', 'h': 'TTG', '3': 'TGA', ':': 'TGC', 'z': 'TGT', '8': 'TGG', 'R': 'GAA', 'S': 'GAC', '/': 'GAT', 'j': 'GAG', 'o': 'GCA', 'd': 'GCC', '@': 'GCT', 'L': 'GCG', '}': 'GTA', 'H': 'GTC', 'Y': 'GTT', 'x': 'GTG', '\"': 'GGA', 'I': 'GGC', '\\\\': 'GGT', 'J': 'GGG', '9': 'AA', '`': 'AC', 'l': 'AT', '<': 'AG', 'N': 'CA', 'V': 'CC', 'D': 'CT', '+': 'CG', 'E': 'TA', 'Z': 'TC', '$': 'TT', '?': 'TG', '2': 'GA', 'K': 'GC', '*': 'GT', 'g': 'GG'}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4fb05f3b7b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0minputAll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputAll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredAll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-4fb05f3b7b2d>\u001b[0m in \u001b[0;36mload_seq\u001b[0;34m(chromList)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchromosome\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchromList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0minputAll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prepData/insert2Anc_{}_{}_gene+_chr{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[:10000000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0moutputAll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prepData/insert2Anc_{}_{}_gene+_chr{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[:10000000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpredAll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prepData/simulated_{}_-1_chr{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchromosome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[:10000000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "def load_seq(chromList):\n",
    "    inputAll = ''\n",
    "    predAll = ''\n",
    "    outputAll = ''\n",
    "    for chromosome in chromList:\n",
    "        try:\n",
    "            inputAll += str(np.load('prepData/insert2Anc_{}_{}_gene+_chr{}.npy'.format(ancName,chromosome)))#[:10000000]\n",
    "            outputAll += str(np.load('prepData/insert2Anc_{}_{}_gene+_chr{}.npy'.format(ancName,chromosome)))#[:10000000]\n",
    "            predAll += str(np.load('prepData/simulated_{}_-1_chr{}.npy'.format(ancName, chromosome)))#[:10000000]\n",
    "        except FileNotFoundError:\n",
    "            print(chromosome)\n",
    "            continue\n",
    "        print(len(inputAll), len(outputAll), len(predAll))\n",
    "        print(inputAll[-10:], outputAll[-10:], predAll[-10:])\n",
    "    return [inputAll], [outputAll], [predAll]\n",
    "\n",
    "# def load_seq(chromList):\n",
    "#     inputAll = ''\n",
    "#     predAll = ''\n",
    "#     outputAll = ''\n",
    "#     for chromosome in chromList:\n",
    "#         inputAll += str(np.load('prepData/insert2Anc_{}_hg38_chr{}.npy'.format(ancName,chromosome)))[:10000000]\n",
    "#         outputAll += str(np.load('prepData/insert2Des_{}_hg38_chr{}.npy'.format(ancName,chromosome)))[:10000000]\n",
    "#         predAll += str(np.load('simulated_{}_10000000_chr{}.npy'.format(ancName, chromosome)))[:10000000]\n",
    "#     return [inputAll], [outputAll], [predAll]\n",
    "    \n",
    "mut_dict = np.load('mut_dict_insert2.npy',allow_pickle=True).item()\n",
    "inv_dict = {v: k for k, v in mut_dict.items()}\n",
    "print(inv_dict)\n",
    "\n",
    "inputAll, outputAll, predAll = load_seq([12,16,17,19,20,21,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# decoded_seq = str(np.load('simulated_{}_10000000_chr{}.npy'.format(ancName, chromosome)))\n",
    "# inputAll =[''.join(anc)[:-1]]\n",
    "# predAll = [decoded_seq[:-1]]\n",
    "# outputAll = [''.join(des)[:-1]\n",
    "\n",
    "lstm_inputAll = [''.join(anc)[:2000000]]\n",
    "lstm_predAll = [str(np.load('simulated_{}_lstm.npy'.format(ancName)))]\n",
    "lstm_outputAll = [''.join(des)[:2000000]]\n",
    "contextLen = 2\n",
    "numBin = 10\n",
    "def contextMut(size, ancNuc, desNuc, anc, des, pred, evol, lstm = False, table='', tableCon = 0):\n",
    "    cont = list(itertools.product('ACGT', repeat=size))\n",
    "    cont1 = list(itertools.product('ACGT', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont1:\n",
    "        for j in cont1:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            if a[i+size:i+size+len(ancNuc)] == ancNuc :\n",
    "                count_dict[(a[i:i+size*2+len(ancNuc)])] += 1\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            if a[i+size:i+size+len(ancNuc)] == ancNuc and b[i+size+int(len(ancNuc)/2)] == desNuc:\n",
    "                context_dict[(a[i:i+size*2+len(ancNuc)])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    sorted_context = dict(sorted_context)\n",
    "    if lstm ==False:\n",
    "        if pred == True and evol ==False:\n",
    "            np.save('data/pred{}_context{}->{}_{}_{}.npy'.format(table,ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "        elif pred == True and evol == True:\n",
    "            np.save('data/pred{}_evol_context{}->{}_{}_{}.npy'.format(table,ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "        elif pred == False and evol ==False:\n",
    "            np.save('data/true_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "        elif pred == False and evol ==True:\n",
    "            np.save('data/true_evol_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "        return sorted_context\n",
    "    elif lstm ==True :\n",
    "        if pred == True:\n",
    "            np.save('data/pred_lstm_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "        elif pred ==False:\n",
    "            np.save('data/true_lstm_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "    return sorted_context\n",
    "            \n",
    "def contextMutInsert(size, ancNuc, desNuc, anc, des, pred, evol, lstm = False, table = '',tableCon = 0):\n",
    "    cont1 = list(itertools.product('ACGT', repeat=size-1))\n",
    "    cont = list(itertools.product('ACGT', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont:\n",
    "        for j in cont:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            count_dict[(a[i:i+size]+ancNuc+a[i+size+len(ancNuc):i+size*2+len(ancNuc)])] += 1\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            inserted_nuc = inv_dict[b[i+size+int(len(ancNuc)/2)-1]]\n",
    "            if len(inserted_nuc) >1 and inserted_nuc[1] == desNuc:\n",
    "                context_dict[(a[i:i+size]+ancNuc+a[i+size+len(ancNuc):i+size*2+len(ancNuc)])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    sorted_context = dict(sorted_context)\n",
    "    if lstm ==False:\n",
    "        if pred == True and evol ==False:\n",
    "            np.save('data/pred{}_context{}->{}_{}_{}.npy'.format(table,ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "        elif pred == True and evol == True:\n",
    "            np.save('data/pred{}_evol_context{}->{}_{}_{}.npy'.format(table,ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "        elif pred == False and evol ==False:\n",
    "            np.save('data/true_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "        elif pred == False and evol ==True:\n",
    "            np.save('data/true_evol_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "        return sorted_context\n",
    "    elif lstm ==True :\n",
    "        if pred == True:\n",
    "            np.save('data/pred_lstm_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "        elif pred ==False:\n",
    "            np.save('data/true_lstm_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), sorted_context)\n",
    "    return sorted_context\n",
    "            \n",
    "def decodeList(inputAll, predAll, outputAll):\n",
    "    inp =[]\n",
    "    inp2 = []\n",
    "    pre = []\n",
    "    out = []\n",
    "    for i, p, o in tqdm(zip(inputAll, predAll, outputAll)):\n",
    "        input, pred = decodeDictSeq(i, p, mut_dict)\n",
    "        input2, output = decodeDictSeq(i,o, mut_dict)\n",
    "        inp.append(input)\n",
    "        inp2.append(input2)\n",
    "        pre.append(pred)\n",
    "        out.append(output)\n",
    "    return inp, inp2, pre, out\n",
    "\n",
    "def valueFloat(data_list):\n",
    "    newDict = dict(zip(data_list.keys(), [float(value) for value in data_list.values()]))\n",
    "    return newDict\n",
    "def plotPointMut(n_groups,ancNuc, desNuc):\n",
    "    predSeq = np.load('data/pred_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), allow_pickle = True).item()\n",
    "\n",
    "    trueSeq = np.load('data/true_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), allow_pickle = True).item()\n",
    "\n",
    "#     evolSeq = np.load('data/true_evol_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), allow_pickle = True).item()\n",
    "    \n",
    "    lstmSeq = np.load('data/pred_lstm_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), allow_pickle = True).item()\n",
    "\n",
    "    true = list(trueSeq.values())[:n_groups]\n",
    "    true_context = list(trueSeq.keys())[:n_groups]\n",
    "    pred = []\n",
    "    evol = []\n",
    "    lstm = []\n",
    "    for i in true_context:\n",
    "        pred.append(predSeq[i])\n",
    "#         evol.append(evolSeq[i])\n",
    "        lstm.append(lstmSeq[i])\n",
    "\n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.05\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, pred, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='b',\n",
    "    label='seq2seq_pred')\n",
    "    \n",
    "    rects2 = plt.bar(index + bar_width, lstm, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='m',\n",
    "    label='lstm_pred')\n",
    "    \n",
    "    rects3 = plt.bar(index + bar_width*2, true, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='g',\n",
    "    label='true')\n",
    "    \n",
    "#     rects3 = plt.bar(index + bar_width*3, evol, bar_width,\n",
    "#     alpha=opacity,\n",
    "#     color='r',\n",
    "#     label='evol_pred')\n",
    "\n",
    "    plt.xlabel('context')\n",
    "    plt.ylabel('rate')\n",
    "    plt.title('{} to {} point mutation'.format(ancNuc, desNuc))\n",
    "    plt.xticks(index + bar_width, list(trueSeq.keys())[:n_groups])\n",
    "    plt.legend()\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plotScatter(n_groups, ancNuc, desNuc,k, tableCon):\n",
    "    predSeq = np.load('data/pred_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), allow_pickle = True).item()\n",
    "\n",
    "    tableSeq = np.load('data/predTable_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), allow_pickle = True).item()\n",
    "    \n",
    "    trueSeq = np.load('data/true_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), allow_pickle = True).item()\n",
    "\n",
    "#     evolSeq = np.load('data/true_evol_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), allow_pickle = True).item()\n",
    "    \n",
    "    lstmSeq = np.load('data/pred_lstm_context{}->{}_{}_{}.npy'.format(ancNuc,desNuc,ancName,tableCon), allow_pickle = True).item()\n",
    "\n",
    "    true = list(trueSeq.values())\n",
    "    true_context = list(trueSeq.keys())\n",
    "    pred = []\n",
    "    evol = []\n",
    "    lstm = []\n",
    "    table = []\n",
    "    for i in true_context:\n",
    "        pred.append(predSeq[i])\n",
    "#         evol.append(evolSeq[i])\n",
    "        lstm.append(lstmSeq[i])\n",
    "        table.append(tableSeq[i])\n",
    "        \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(15,5))\n",
    "    f.text(0.5, 0.0, 'Observed', ha='center', va='center', fontsize = 16)\n",
    "    f.text(0.05, 0.5, 'Predicted', ha='center', va='center', rotation='vertical', fontsize = 16)\n",
    "    \n",
    "    ax1.scatter(true, table, color = 'y', label = 'freqTable')\n",
    "\n",
    "#     ax1.axis('scaled')\n",
    "#     ax1.axis('square')\n",
    "    ax1.set_xlim([0, 1.2 * max(max(table), max(true))])\n",
    "    ax1.set_ylim([0, 1.2 * max(max(table), max(true))])\n",
    "    ax1.text(0.5,-0.1, \"r = {}\".format(stats.pearsonr(table, true)[0]), size=12, ha=\"center\", \n",
    "                         transform=ax1.transAxes)\n",
    "    ax1.set_title('xy{}zw to xy{}zw point mutation'.format(ancNuc, desNuc))\n",
    "    for i, txt in enumerate(list(trueSeq.keys())):\n",
    "        if i%30 == 0:\n",
    "            ax1.annotate(txt, (true[i], table[i]))\n",
    "\n",
    "    ax1.legend()\n",
    "    \n",
    "    \n",
    "    ax2.scatter(true, lstm, color = 'k', label = 'lstm')\n",
    "    for i, txt in enumerate(list(lstmSeq.keys())):\n",
    "        if i%30 == 0:\n",
    "            ax2.annotate(txt, (true[i], lstm[i]))\n",
    "\n",
    "#     ax2.axis('scaled')\n",
    "#     ax2.axis('square')\n",
    "    ax2.set_xlim([0, 1.2 * max(max(lstm), max(true))])\n",
    "    ax2.set_ylim([0, 1.2* max(max(lstm), max(true))])\n",
    "    ax2.text(0.5,-0.1, \"r = {}\".format(stats.pearsonr(lstm, true)[0]), size=12, ha=\"center\", \n",
    "                             transform=ax2.transAxes)\n",
    "    ax2.legend()\n",
    "    ax2.set_title('xy{}zw to xy{}zw point mutation'.format(ancNuc, desNuc))\n",
    "    \n",
    "    ax3.scatter(true, pred, color = 'm', label = 'DeepEvoLstm')\n",
    "\n",
    "#     ax3.axis('scaled')\n",
    "#     ax3.axis('square')\n",
    "    ax3.set_xlim([0, 1.2 * max(max(pred), max(true))])\n",
    "    ax3.set_ylim([0, 1.2 * max(max(pred), max(true))])\n",
    "    ax3.text(0.5,-0.1, \"r = {}\".format(stats.pearsonr(pred, true)[0]), size=12, ha=\"center\", \n",
    "                         transform=ax3.transAxes)\n",
    "    ax3.set_title('xy{}zw to xy{}zw point mutation'.format(ancNuc, desNuc))\n",
    "    for i, txt in enumerate(list(trueSeq.keys())):\n",
    "        if i%30 == 0:\n",
    "            ax3.annotate(txt, (true[i], pred[i]))\n",
    "\n",
    "    ax3.legend()\n",
    "    \n",
    "    f.savefig('figures/scatter_{}_{}_{}->{}_{}.png'.format(ancName, desName,  ancNuc, desNuc,k, tableCon))\n",
    "    f.show()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return ('{} $rightarrow$ {} & {:.3f} & {:.3f} & {:.3f}'.format(ancNuc, desNuc,stats.pearsonr(pred, true)[0], stats.pearsonr(lstm, true)[0], stats.pearsonr(table, true)[0] ))\n",
    "#     print(stats.pearsonr(pred, true), stats.pearsonr(lstm, true))\n",
    "            \n",
    "\n",
    "# np.save('inputAll_{}_{}'.format(ancName, desName), inputAll)\n",
    "# np.save('predAll_{}_{}'.format(ancName, desName), predAll)\n",
    "# np.save('outputAll_{}_{}'.format(ancName, desName), outputAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputAll, inputAll2, predAll, outputAll= decodeList(inputAll, predAll, outputAll)\n",
    "# lstm_inputAll, lstm_inputAll2, lstm_predAll, lstm_outputAll = decodeList(lstm_inputAll, lstm_predAll, lstm_outputAll)\n",
    "def plotCombine(k, tableCon):\n",
    "#     contextLen = k\n",
    "#     predTable = [str(np.load('predTable_{}.npy'.format(tableCon)))]\n",
    "#     ancCase = ['A','C','G','T']\n",
    "#     desCase = ['A','C','G','T','-']\n",
    "#     for i in tqdm_notebook(ancCase):\n",
    "#         for j in desCase:\n",
    "#             contextMut(contextLen, i, j, inputAll, predAll, pred = True, evol = False, tableCon= tableCon)\n",
    "#             contextMut(contextLen, i, j, inputAll, predTable, pred = True, evol = False, table = 'Table', tableCon= tableCon)\n",
    "#             contextMut(contextLen, i, j, inputAll, outputAll, pred = False, evol = False, tableCon= tableCon)\n",
    "#             contextMut(contextLen, i, j, lstm_inputAll, lstm_predAll, pred = True, evol = False, lstm = True, tableCon= tableCon)\n",
    "#     ancCase = ['-']\n",
    "#     desCase = ['A','C','G','T']\n",
    "#     for i in tqdm_notebook(ancCase):\n",
    "#         for j in desCase:\n",
    "#             contextMutInsert(contextLen, i, j, inputAll, predAll, pred = True, evol = False, tableCon= tableCon)\n",
    "#             contextMutInsert(contextLen, i, j, inputAll, predTable, pred = True, evol = False, table = 'Table', tableCon= tableCon)\n",
    "#             contextMutInsert(contextLen, i, j, inputAll, outputAll, pred = False, evol = False, tableCon= tableCon)\n",
    "#             contextMutInsert(contextLen, i, j, lstm_inputAll, lstm_predAll, pred = True, evol = False, lstm = True, tableCon= tableCon)\n",
    "\n",
    "#     ancCase = ['A','C','G','T','-']\n",
    "#     desCase = ['A','C','G','T','-']\n",
    "\n",
    "\n",
    "    values = []\n",
    "    for i in tqdm_notebook(ancCase):\n",
    "        for j in desCase:\n",
    "            if i != j:\n",
    "                values.append(plotScatter(numBin,i, j, k, tableCon))\n",
    "    for item in values:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotCombine(2, 5)\n",
    "# ancCase = ['C','A','C','T','-']\n",
    "# desCase = ['T','G','A','-','T']\n",
    "# # for i in ancCase:\n",
    "# #     for j in desCase:\n",
    "# #         if i != j:\n",
    "# #             plotPointMut(numBin,i, j)\n",
    "\n",
    "\n",
    "\n",
    "# for i, j in zip(ancCase, desCase):\n",
    "#         if i != j:\n",
    "#             plotScatter(numBin,i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotCombine(2, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(3, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(4, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombine(5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeMut(ancNuc, desNuc):\n",
    "    predSeq = np.load('data/pred_context{}{}_{}.npy'.format(ancNuc,desNuc, ancName), allow_pickle = True).item()\n",
    "    trueSeq = np.load('data/true_context{}{}_{}.npy'.format(ancNuc,desNuc, ancName), allow_pickle = True).item()\n",
    "#     evolSeq = np.load('data/true_evol_context{}{}_{}.npy'.format(ancNuc,desNuc, ancName), allow_pickle = True).item()\n",
    "    lstmSeq = np.load('data/pred_lstm_context{}{}_{}.npy'.format(ancNuc,desNuc, ancName), allow_pickle = True).item()\n",
    "\n",
    "#     print(list(predSeq.keys())[:256])\n",
    "#     print(list(trueSeq.keys())[:256])\n",
    "    print(predSeq)\n",
    "#     print(trueSeq)\n",
    "    \n",
    "analyzeMut('A','G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextLength = 1\n",
    "numBin = 16\n",
    "def contextMut(size, ancNuc, desNuc, anc, des, pred, evol, lstm = False):\n",
    "    cont = list(itertools.product('ACGT', repeat=size))\n",
    "    cont1 = list(itertools.product('ACGT', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont1:\n",
    "        for j in cont1:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            if a[i+size:i+size+len(ancNuc)] == ancNuc :\n",
    "                count_dict[(a[i:i+size*2+len(ancNuc)])] += 1\n",
    "    for a,b in tqdm_notebook(zip(anc, des)):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            if a[i+size:i+size+len(ancNuc)] == ancNuc and b[i+size+int(len(ancNuc)/2)] == desNuc:\n",
    "                context_dict[(a[i:i+size*2+len(ancNuc)])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    sorted_context = dict(sorted_context)\n",
    "    if lstm ==False:\n",
    "        if pred == True and evol ==False:\n",
    "            np.save('data/pred_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == True and evol == True:\n",
    "            np.save('data/pred_evol_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == False and evol ==False:\n",
    "            np.save('data/true_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == False and evol ==True:\n",
    "            np.save('data/true_evol_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        return sorted_context\n",
    "    elif lstm ==True :\n",
    "        if pred == True:\n",
    "            np.save('data/pred_lstm_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred ==False:\n",
    "            np.save('data/true_lstm_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "    return sorted_context\n",
    "            \n",
    "def contextMutInsert(size, ancNuc, desNuc, anc, des, pred, evol, lstm = False):\n",
    "    cont1 = list(itertools.product('ACGT', repeat=size-1))\n",
    "    cont = list(itertools.product('ACGT', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont:\n",
    "        for j in cont:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            count_dict[(a[i:i+size]+ancNuc+a[i+size+len(ancNuc):i+size*2+len(ancNuc)])] += 1\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(len(a)-size*2-len(ancNuc)):\n",
    "            inserted_nuc = inv_dict[b[i+size+int(len(ancNuc)/2)-1]]\n",
    "            if len(inserted_nuc) >1 and inserted_nuc[1] == desNuc:\n",
    "                context_dict[(a[i:i+size]+ancNuc+a[i+size+len(ancNuc):i+size*2+len(ancNuc)])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    sorted_context = dict(sorted_context)\n",
    "    if lstm ==False:\n",
    "        if pred == True and evol ==False:\n",
    "            np.save('data/pred_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == True and evol == True:\n",
    "            np.save('data/pred_evol_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == False and evol ==False:\n",
    "            np.save('data/true_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred == False and evol ==True:\n",
    "            np.save('data/true_evol_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        return sorted_context\n",
    "    elif lstm ==True :\n",
    "        if pred == True:\n",
    "            np.save('data/pred_lstm_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "        elif pred ==False:\n",
    "            np.save('data/true_lstm_context{}->{}_{}.npy'.format(ancNuc,desNuc,ancName), sorted_context)\n",
    "    return sorted_context\n",
    "            \n",
    "def calculateR(contextLen, ancCase, desCase):\n",
    "    sorted_context = contextMut(contextLen, ancCase, desCase, inputAll, predAll, pred = True, evol = False)\n",
    "    contextMut(contextLen, ancCase, desCase, inputAll, outputAll, pred = False, evol = False)\n",
    "    contextMut(contextLen, ancCase, desCase, lstm_inputAll, lstm_predAll, pred = True, evol = False, lstm = True)\n",
    "\n",
    "    sorted_word = list(sorted_context.keys())\n",
    "    top = sorted_word[0]\n",
    "    mid = sorted_word[int(len(sorted_word)/2)]\n",
    "    bot = sorted_word[-1]\n",
    "    return top, mid, bot\n",
    "\n",
    "def calculateRInsert(contextLen, ancCase, desCase):\n",
    "    sorted_context = contextMutInsert(contextLen, ancCase, desCase, inputAll, predAll, pred = True, evol = False)\n",
    "    contextMutInsert(contextLen, ancCase, desCase, inputAll, outputAll, pred = False, evol = False)\n",
    "    contextMutInsert(contextLen, ancCase, desCase, lstm_inputAll, lstm_predAll, pred = True, evol = False, lstm = True)\n",
    "\n",
    "    sorted_word = list(sorted_context.keys())\n",
    "    top = sorted_word[0]\n",
    "    mid = sorted_word[int(len(sorted_word)/2)]\n",
    "    bot = sorted_word[-1]\n",
    "    return top, mid, bot\n",
    "    \n",
    "def plotContextChange(contLen, ancCase, desCase, insert = False):\n",
    "    contextLen = contLen\n",
    "    if insert == True:\n",
    "        top, mid, bot = calculateRInsert(contextLen, ancCase, desCase)\n",
    "        \n",
    "        tt, tm, tb = calculateRInsert(contextLen, top, desCase)\n",
    "        mt, mm, mb = calculateRInsert(contextLen, mid, desCase)\n",
    "        bt, bm, bb = calculateRInsert(contextLen, bot, desCase)\n",
    "\n",
    "        ttt, ttm, ttb = calculateRInsert(contextLen, tt, desCase)\n",
    "        mmt, mmm, mmb = calculateRInsert(contextLen, mm, desCase)\n",
    "        bbt, bbm, bbb = calculateRInsert(contextLen, bb, desCase)\n",
    "    else :\n",
    "        top, mid, bot = calculateR(contextLen, ancCase, desCase)\n",
    "        tt, tm, tb = calculateR(contextLen, top, desCase)\n",
    "        mt, mm, mb = calculateR(contextLen, mid, desCase)\n",
    "        bt, bm, bb = calculateR(contextLen, bot, desCase)\n",
    "\n",
    "        ttt, ttm, ttb = calculateR(contextLen, tt, desCase)\n",
    "        mmt, mmm, mmb = calculateR(contextLen, mm, desCase)\n",
    "        bbt, bbm, bbb = calculateR(contextLen, bb, desCase)\n",
    "    \n",
    "    \n",
    "    topList = [ancCase, top, tt]\n",
    "    midList = [ancCase, mid, mm]\n",
    "    botList = [ancCase, bot, bb]\n",
    "    ancWords = [topList, midList, botList]\n",
    "    \n",
    "\n",
    "    print(topList)\n",
    "    print(midList)\n",
    "    print(botList)\n",
    "    print(ancWords)\n",
    "#     topList =['A', 'CAT', 'CCATG']\n",
    "#     midList =['A', 'AAC', 'AAACT']\n",
    "#     botList =['A', 'GAA', 'TGAAA']\n",
    "#     ancWords =[['A', 'CAT', 'CCATG'], ['A', 'AAC', 'AAACT'], ['A', 'GAA', 'TGAAA']]\n",
    "    \n",
    "    f, axs = plt.subplots(3, 3, sharex=False, sharey=False, figsize=(20,20))\n",
    "    axs = axs.flatten()\n",
    "    f.text(0.5, 0.08, 'Observed', ha='center', va='center', fontsize=40)\n",
    "    f.text(0.05, 0.5, 'Predicted', ha='center', va='center', rotation='vertical', fontsize=40)\n",
    "    f.suptitle('Effect of adding flanking base contexts to {}->{} mutation'.format(ancCase, desCase), fontsize =30)\n",
    "\n",
    "    index = 0\n",
    "    for words in tqdm(ancWords):\n",
    "        for j in desCase:\n",
    "            for n, i in enumerate(words):\n",
    "                if i != j:\n",
    "                    predSeq = np.load('data/pred_context{}->{}_{}.npy'.format(i,j,ancName), allow_pickle = True).item()\n",
    "                    trueSeq = np.load('data/true_context{}->{}_{}.npy'.format(i,j,ancName), allow_pickle = True).item()\n",
    "                    true = list(trueSeq.values())\n",
    "                    true_context = list(trueSeq.keys())\n",
    "                    pred = []\n",
    "                    for x in true_context:\n",
    "                        pred.append(predSeq[x])\n",
    "                    axs[index].scatter(true, pred, color = 'm')\n",
    "#                     axs[index].axis('scaled')\n",
    "#                     axs[index].axis('square')\n",
    "                    axs[index].set_xlim([0, 1.1 * max(max(pred), max(true))])\n",
    "                    axs[index].set_ylim([0, 1.1 * max(max(pred), max(true))])\n",
    "                    axs[index].text(0.5,-0.1, \"r = {}\".format(stats.pearsonr(pred, true)[0]), size=20, ha=\"center\", \n",
    "                             transform=axs[index].transAxes)\n",
    "                    axs[index].set_title('x{}y to {} point mutation'.format(i, j), fontsize=25)\n",
    "                    for i, txt in enumerate(list(predSeq.keys())):\n",
    "                        if i %3 ==0 or i%(int(len(true)/2))==0 or i%(int(len(true)-1))==0:\n",
    "                            axs[index].annotate(txt, (true[i], pred[i]))\n",
    "\n",
    "                    index += 1\n",
    "                    f.savefig('figures/scatter_conChange_{}_{}_{}->{}.png'.format(ancName, desName,  ancCase, desCase))\n",
    "#                     print('pearson corr: ', stats.pearsonr(pred, true)[0])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "#                     plotPointMut(numBin,i, j)\n",
    "#                     plotScatter(numBin,i, j)\n",
    "#     analyzeMut(ancCase[0],desCase[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotContextChange(1, 'A', 'G', insert = False)\n",
    "plotContextChange(1, 'C', 'T', insert = False)\n",
    "plotContextChange(1, 'A', '-', insert = False)\n",
    "plotContextChange(1, '-', 'T', insert = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzeMut('TAG','G')\n",
    "contextMut(contextLen, 'TAG', 'G', inputAll, predAll, pred = True, evol = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
