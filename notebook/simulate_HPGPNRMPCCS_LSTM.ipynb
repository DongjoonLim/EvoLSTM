{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  9 22:16:02 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 30%   36C    P2    61W / 250W |  10642MiB / 10989MiB |      6%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 30%   36C    P8    22W / 250W |  10642MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 30%   27C    P8     1W / 250W |   1164MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 31%   45C    P2    71W / 250W |  10642MiB / 10989MiB |      5%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  On   | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 31%   45C    P2    64W / 250W |  10642MiB / 10989MiB |      5%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  On   | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 30%   36C    P2    52W / 250W |  10642MiB / 10989MiB |      5%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  On   | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 29%   26C    P8    13W / 250W |  10642MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  On   | 00000000:3F:00.0 Off |                  N/A |\n",
      "| 30%   26C    P8     3W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   8  GeForce RTX 208...  On   | 00000000:40:00.0 Off |                  N/A |\n",
      "| 29%   25C    P8    18W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   9  GeForce RTX 208...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8    12W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      4182      C   ...m63/miniconda3/envs/research/bin/python 10631MiB |\n",
      "|    1      6482      C   ...m63/miniconda3/envs/research/bin/python 10631MiB |\n",
      "|    2     35531      C   ...5/anaconda3/envs/single-cell/bin/python  1153MiB |\n",
      "|    3     15577      C   python3                                    10631MiB |\n",
      "|    4     17800      C   python3                                    10631MiB |\n",
      "|    5     20408      C   python3                                    10631MiB |\n",
      "|    6      6479      C   ...m63/miniconda3/envs/research/bin/python 10631MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "86\n",
      "['!' '\"' '$' '%' '&' '(' ')' '*' '+' '-' '.' '/' '0' '1' '2' '3' '4' '5'\n",
      " '6' '7' '8' '9' ':' ';' '<' '=' '>' '?' '@' 'A' 'B' 'C' 'D' 'E' 'F' 'G'\n",
      " 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z'\n",
      " '[' '\\\\' ']' '^' '_' '`' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm'\n",
      " 'n' 'o' 'p' 'q' 's' 't' 'u' 'w' 'x' 'z' '{' '|' '}' '~']\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import itertools\n",
    "import operator\n",
    "from tensorflow.python.keras import backend as k\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from scipy.stats.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import choice\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from bio import AlignIO\n",
    "# from Bio.Align import MultipleSeqAlignment\n",
    "# from Bio.SeqRecord import SeqRecord\n",
    "# from Bio import SeqIO\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras_preprocessing import sequence\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "import string\n",
    "from joblib import dump, load\n",
    "\n",
    "%precision 2\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "context_length = 15\n",
    "val_loss_hist = []\n",
    "\n",
    "# K.clear_session()\n",
    "# keras.backend.clear_session()\n",
    "\n",
    "ancName = '_HPGPNRMPCCS'\n",
    "desName = 'hg38'\n",
    "\n",
    "anc = str(np.load('prepData/insert2Anc__HPGPNRMPCCS_hg38_chr3.npy'))[:2000000]\n",
    "des = str(np.load('prepData/insert2Des__HPGPNRMPCCS_hg38_chr3.npy'))[:2000000]\n",
    "anc = np.array(list(anc+'0'))\n",
    "des = np.array(list(des+'0'))\n",
    "\n",
    "# with open('label_encoder.pickle', 'rb') as f:\n",
    "#     label_encoder = pickle.load(f)\n",
    "# with open('onehot_encoder.pickle', 'rb') as f:\n",
    "#     onehot_encoder = pickle.load(f)\n",
    "\n",
    "label_encoder = load('label_encoder.joblib') \n",
    "onehot_encoder = load('onehot_encoder.joblib') \n",
    "\n",
    "integer_encoded_des = label_encoder.transform(des)\n",
    "integer_encoded_anc = label_encoder.transform(anc)\n",
    "integer_des = integer_encoded_des.reshape(len(integer_encoded_des), 1)\n",
    "encoded_des =onehot_encoder.transform(integer_des)\n",
    "integer_anc = integer_encoded_anc.reshape(len(integer_encoded_anc), 1)\n",
    "encoded_anc = onehot_encoder.transform(integer_anc)\n",
    "\n",
    "print(encoded_des)\n",
    "print(encoded_anc)\n",
    "\n",
    "print(len(encoded_des[0]))\n",
    "encode_dimension= len(encoded_des[0])\n",
    "\n",
    "print(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "print(onehot_encoder.transform(np.ones(1).reshape(-1,1)))\n",
    "key = list(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "\n",
    "nucleotide = label_encoder.inverse_transform(range(encode_dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '$', '%', '&', '(', ')', '*', '+', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'AC', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'CA', 'AA', 'R', 'S', 'T', 'U', 'TG', 'TA', 'X', 'AG', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'GT', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'TT', 'CG', 'n', 'o', 'CT', 'q', 's', 't', 'AT', 'GA', 'GC', 'z', '{', '|', '}', '~']\n",
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000001/2000001 [04:44<00:00, 7037.41it/s]\n"
     ]
    }
   ],
   "source": [
    "%precision 2\n",
    "\n",
    "\n",
    "key = list(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "\n",
    "mapDict = np.load('mut_dict.npy', allow_pickle = True).item()\n",
    "\n",
    "rev_dict = {v: k for k, v in mapDict.items()}\n",
    "#print(rev_dict.keys())\n",
    "rev_key = []\n",
    "for item in key:\n",
    "    #print(item)\n",
    "    if item in list(rev_dict.keys()):\n",
    "        rev_key.append(rev_dict[item])\n",
    "        #print('hi')\n",
    "    else :\n",
    "        rev_key.append(item)\n",
    "print(rev_key)\n",
    "\n",
    "nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "\n",
    "def printHitMiss(a,b):\n",
    "    if a==b:\n",
    "        return 'Hit'\n",
    "    else:\n",
    "        return 'Miss'\n",
    "    \n",
    "def accuracy(a, b):\n",
    "    count = 0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == b[i]:\n",
    "            count = count+1\n",
    "    return count/len(a)\n",
    "\n",
    "def accuracy2(a, b, c):\n",
    "    count = 0\n",
    "    count2 =0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != c[i]:\n",
    "            count2 = count2 +1\n",
    "        if a[i] != c[i] and b[i]==c[i]:\n",
    "            count = count+1\n",
    "    return count/count2\n",
    "\n",
    "def isMutation(a, b):\n",
    "    if a!= b:\n",
    "        print(\"mutation\")\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq, model):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    input_seq = np.expand_dims(input_seq, axis=0)\n",
    "    index = 0\n",
    "    stop_condition = False\n",
    "    decoded_seq = ''\n",
    "    predicted = model.predict(input_seq)\n",
    "    for i in tqdm(range(len(predicted[0]))):\n",
    "#         print([input_seq[index-1]])\n",
    "        output_tokens = predicted[0][i]\n",
    "#        sampled_token_index = np.random.choice(encode_dimension, 1, p=output_tokens)[0]\n",
    "        sampled_nucleotide = nucleotide[np.random.choice(encode_dimension, 1, p=output_tokens)[0]]\n",
    "        \n",
    "        decoded_seq += sampled_nucleotide\n",
    "\n",
    "\n",
    "    return decoded_seq\n",
    "\n",
    "def get_prob(input_seq, target, model):\n",
    "    # Encode the input as state vectors.\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    index = 0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_seq = ''\n",
    "    probability = []\n",
    "    predicted = model.predict(input_seq)\n",
    "    \n",
    "    while not stop_condition:\n",
    "        index = index +1\n",
    "        output_tokens = predicted[0][index-1]\n",
    "        sampled_token_index = np.argmax(target[index-1])\n",
    "          \n",
    "        probability.append(output_tokens[sampled_token_index])\n",
    "        sampled_nucleotide = nucleotide[np.random.choice(encode_dimension, 1, p=output_tokens)[0]]\n",
    "        \n",
    "        decoded_seq += sampled_nucleotide\n",
    "        if (len(decoded_seq) == seq_length):\n",
    "            break\n",
    "\n",
    "\n",
    "    return decoded_seq, probability\n",
    "\n",
    "def diffList(a, b):\n",
    "    count = 0\n",
    "    length = len(a)\n",
    "    for i in range(length):\n",
    "        if a[i] != b[i]:\n",
    "            count = count+1\n",
    "    return count\n",
    "\n",
    "def decoder(input):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    decoded = ''\n",
    "    for i in range(len(input)):\n",
    "        # decoded= decoded+(nucleotide[np.argmax(onehot_encoder.inverse_transform(input[i].reshape(-1, 1)))])\n",
    "        #print(np.argmax(input[i]))\n",
    "        #print(nucleotide)\n",
    "        decoded= decoded+nucleotide[np.argmax(input[i])]\n",
    "    return decoded\n",
    "\n",
    "model = load_model('models/lstm_{}_hg38_0_512_10.h5'.format(ancName))\n",
    "decoded_seq = decode_sequence(encoded_anc, model)\n",
    "np.save('simulated_{}_lstm.npy'.format(ancName), decoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
