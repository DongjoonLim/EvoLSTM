{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 30 01:32:57 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 29%   23C    P8     6W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 30%   28C    P8    22W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8     1W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 30%   27C    P8    20W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  On   | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 30%   28C    P8     8W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  On   | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 30%   22C    P8     1W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  On   | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8    14W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  On   | 00000000:3F:00.0 Off |                  N/A |\n",
      "| 30%   23C    P8     4W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   8  GeForce RTX 208...  On   | 00000000:40:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8    17W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   9  GeForce RTX 208...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8    12W / 250W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import math\n",
    "import itertools\n",
    "import operator\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as k\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import choice\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "ancName = '_HPGPNRMPC'\n",
    "desName = 'hg38'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "seq_length = 5\n",
    "val_loss_hist = []\n",
    "train_size = 0\n",
    "modelName = 'lstm'\n",
    "\n",
    "#K.clear_session()\n",
    "#keras.backend.clear_session()\n",
    "\n",
    "anc = str(np.load('prepData/insert1Anc_{}_{}.npy'.format(ancName, desName)))\n",
    "des = str(np.load('prepData/insert1Des_{}_{}.npy'.format(ancName, desName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcb/users/dlim63/miniconda3/envs/research/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "anc = np.array(list(anc+'0'))\n",
    "des = np.array(list(des+'0'))\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(des)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded_des = label_encoder.transform(des)\n",
    "integer_encoded_anc = label_encoder.transform(anc)\n",
    "#one hot the sequence\n",
    "integer_des = integer_encoded_des.reshape(len(integer_encoded_des), 1)\n",
    "\n",
    "onehot_encoder.fit(integer_des)\n",
    "encoded_des =onehot_encoder.transform(integer_des)\n",
    "\n",
    "integer_anc = integer_encoded_anc.reshape(len(integer_encoded_anc), 1)\n",
    "encoded_anc = onehot_encoder.transform(integer_anc)\n",
    "\n",
    "print(encoded_des)\n",
    "print(encoded_anc)\n",
    "\n",
    "print(len(encoded_des[0]))\n",
    "encode_dimension= len(encoded_des[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_des.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-' '0' 'A' 'C' 'E' 'G' 'O' 'P' 'Q' 'T' 'V' 'W' 'Y' 'c' 'l' 'm' 'p' 'r'\n",
      " 'u' 'w' 'x' 'y']\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.inverse_transform(range(encode_dimension)))\n",
    "print(onehot_encoder.transform(np.ones(1).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5044003, 5, 22)\n",
      "[[[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]]]\n",
      "AAAAA AAAAA\n",
      "ATTTT ATTTT\n",
      "AAAGG AAAGG\n",
      "AAAAC AAAAC\n",
      "TATAG TACAG\n",
      "CCCTT CCATT\n",
      "GTGGG GTGGG\n",
      "TTATC TTATC\n",
      "AGATT AGATT\n",
      "CTAGT CTAGT\n",
      "CTTGT CTTGT\n",
      "TTCTT TTCTT\n",
      "GTCTT GTTTC\n",
      "TGGGC TGGGC\n",
      "TATTT TATTT\n",
      "TTACC TTACC\n",
      "TCTTT TCTTT\n",
      "GTAAA GTAAA\n",
      "CTGGA CTGCA\n",
      "TCCTG TCCTG\n",
      "CCATC CCATC\n",
      "TGATG TGATG\n",
      "AATTT AATTT\n",
      "TGCCA TGCCA\n",
      "CAATG CAATG\n",
      "ATACT ATACT\n",
      "TGTGG TGGGG\n",
      "AACAA AACAA\n",
      "GAAGC GAAGC\n",
      "CAAAT CAATT\n",
      "ATTGT ATTGT\n",
      "CTCTC CTCTC\n",
      "CTATT CTACT\n",
      "AATGT AATGT\n",
      "ATCTA ATCTA\n",
      "TTGTC TTGTC\n",
      "AGTTA AGTTA\n",
      "ATTTG ATTTG\n",
      "AAGGT AAGGT\n",
      "CTCCA CTCCA\n",
      "ACCCT ACCCT\n",
      "GGAAC GGAAC\n",
      "AAAGT AAAGT\n",
      "TAGAA TAGAA\n",
      "GAAGG GAAGG\n",
      "TTTTT TTCTG\n",
      "CTCCC CTCCC\n",
      "CAAAT PAAAT\n",
      "TAACC TAACC\n",
      "AAATT AAATT\n",
      "GTGGT GTGGT\n",
      "ACATT ACATT\n",
      "CATGC CATGT\n",
      "AATGG AATGG\n",
      "AACAC AACAC\n",
      "TATTT TATTT\n",
      "AGCCA AGCCA\n",
      "TAGAA TAGAA\n",
      "AGGAA ACGAA\n",
      "CAAGC CAAGC\n",
      "TGACA TGACA\n",
      "TGAGT TGAGT\n",
      "GAATC GAATC\n",
      "TTGCA TTGCA\n",
      "TGCAC TGCAC\n",
      "ATTGC ATTGC\n",
      "TAAGT TAAGT\n",
      "GGAAG GGAAG\n",
      "AAGAC AAGAC\n",
      "AGTCT AGTCT\n",
      "GAGGA GAGGA\n",
      "GGATA GGATA\n",
      "CACAC CACAC\n",
      "AGTGA AGTG-\n",
      "CTGAC -TGAC\n",
      "TTCAT CTCAT\n",
      "TTAAT TTAAT\n",
      "GAGAT GAGAC\n",
      "TCTGG ACTGG\n",
      "AGAAG AGAAG\n",
      "GCAAA GC-AA\n",
      "ACTAC ACTAC\n",
      "ACAGA ACAGA\n",
      "TGGGA TGGGA\n",
      "AGCCA AGCCA\n",
      "TTGGC TTGGC\n",
      "TCCAT TCCAT\n",
      "GGGGT GGGGT\n",
      "GGGGG GGGGG\n",
      "TTTGA TTTGA\n",
      "AGCAT AGCAT\n",
      "TCCAT TCCAT\n",
      "ATGAT ATGAT\n",
      "ACTTT ACTTT\n",
      "AATTG AATTG\n",
      "CCACT CCACA\n",
      "ATGCA ATGCA\n",
      "TTTGT TTTGT\n",
      "CAAAA CAAAA\n",
      "CACGC TATGC\n"
     ]
    }
   ],
   "source": [
    "def splice(input, pad):\n",
    "    result = []\n",
    "    if pad == False:\n",
    "        for i in range(int(len(input)/seq_length)):\n",
    "            result.append(input[i*seq_length:(i+1)*seq_length])\n",
    "    else :\n",
    "        for i in range(int(len(input)/seq_length)):\n",
    "            result.append(np.concatenate((onehot_encoder.transform(np.ones(1).reshape(-1,1)), \n",
    "                                         input[i*seq_length:(i+1)*seq_length-1]), \n",
    "                                         axis = 0)\n",
    "                         )\n",
    "    return np.array(result)\n",
    "\n",
    "def decoder(input):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    decoded = ''\n",
    "    for i in range(len(input)):\n",
    "        # decoded= decoded+(nucleotide[np.argmax(onehot_encoder.inverse_transform(input[i].reshape(-1, 1)))])\n",
    "        #print(np.argmax(input[i]))\n",
    "        #print(nucleotide)\n",
    "        decoded= decoded+nucleotide[np.argmax(input[i])]\n",
    "    return decoded\n",
    "\n",
    "y = splice(encoded_des, False)\n",
    "X = splice(encoded_anc, False)\n",
    "\n",
    "print(X.shape)\n",
    "print(X)\n",
    "\n",
    "onehot_encoder.transform(np.ones(1).reshape(-1,1))\n",
    "for i in range (100):\n",
    "    print(decoder(X[i]), decoder(y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "# X_train = X[:-300000]\n",
    "# X_test = X[-300000:]\n",
    "# y_train1 = y1[:-300000]\n",
    "# y_test1 = y1[-300000:]\n",
    "# y_train = y[:-300000]\n",
    "# y_test = y[-300000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GACAC GACAC\n",
      "TTAGG TT-GG\n",
      "CATCA CATCA\n",
      "AGGCC AGGCT\n",
      "GGTAT GGTAT\n",
      "ACCTG ACCTG\n",
      "GTCAA GTCAA\n",
      "TGTCT TGTCT\n",
      "ATAGA ATAGA\n",
      "TAGTG TAGTG\n",
      "TAGTT TAGTT\n",
      "CCCCA CCCCC\n",
      "TGGCC TGGCC\n",
      "ACATC ACATC\n",
      "CAATA CAATA\n",
      "AGTGA AGTGA\n",
      "AGATA AGATA\n",
      "ATATA ATATA\n",
      "AAATT AAATT\n",
      "ACTAG ACTAG\n",
      "ACTCA ACTCA\n",
      "CCAAC CCAAC\n",
      "TTAGT TTAGT\n",
      "GGCTA GGCTA\n",
      "AGCTT AGCTT\n",
      "CTCCA CTCCA\n",
      "TTCCT TTCCT\n",
      "TGAAT TGAAT\n",
      "ACCCA ACCCA\n",
      "CAGGA CAGGA\n",
      "GCAAA GCAAA\n",
      "TCTTA TCTTA\n",
      "CCCTG CCCTG\n",
      "AATGT AATGT\n",
      "GTGCA GTGCA\n",
      "ATTCA ATTCA\n",
      "TATGA TATGA\n",
      "CATGA CATGA\n",
      "AATCA AATCA\n",
      "TTCCT TTCCT\n",
      "AACAG AACAG\n",
      "GGATA GGATA\n",
      "GAGTG GAGTG\n",
      "AAACA AAACA\n",
      "TACTG TACTG\n",
      "AGCCG AGCCG\n",
      "ATTTC ATTGC\n",
      "GTGCA GTGCA\n",
      "ACCAG ACCAG\n",
      "CCCAA CCCAA\n",
      "AGCCT AGCCT\n",
      "TTTCA TTTCA\n",
      "CATCA CATCA\n",
      "GGACT GGACT\n",
      "GAGAA GAGAA\n",
      "TCCCC TCCCC\n",
      "ATGCA ATGCA\n",
      "TGAGG GGAGG\n",
      "AATTA AATTA\n",
      "TACTT TACTT\n",
      "GACAA GACAA\n",
      "TCAGT TCAGT\n",
      "TTCAA TTCAA\n",
      "TTTAC TTTAC\n",
      "CTGAC CTGAC\n",
      "CCATC CCATC\n",
      "TATTG TATGG\n",
      "TAAAG TAAAG\n",
      "CTGTC TTGTC\n",
      "ACCAG ACCAG\n",
      "TACTA TACTA\n",
      "CTTTA CTTTA\n",
      "CACAT CACAT\n",
      "CACTC CACTC\n",
      "TAAAA TAAAA\n",
      "TAAGA TAAGA\n",
      "TGAGT TGAGT\n",
      "TCAAG TCAAG\n",
      "AACAA AACAA\n",
      "CTTTT CTTTT\n",
      "TAATG TAATG\n",
      "TTGAG TTGAG\n",
      "AAAAT AAAAT\n",
      "ACCCT ACCCT\n",
      "CACAT CACAT\n",
      "TTATA TTATA\n",
      "CACCA CACCA\n",
      "TCCTC TCTTC\n",
      "TCAAA TCAAA\n",
      "TTTTG TTTTG\n",
      "TGAGC TGAGC\n",
      "CTGAC CTGAC\n",
      "TAGGA TAGGA\n",
      "TCCCC TCCCC\n",
      "ACGCA ACGCA\n",
      "TATGA TATGA\n",
      "GGATT ---TT\n",
      "TAATC CAATC\n",
      "AGAAT AGAAT\n",
      "TGTTT TGTTT\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder.transform(np.ones(1).reshape(-1,1))\n",
    "for i in range (100):\n",
    "    print(decoder(X_train[i]), decoder(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHitMiss(a,b):\n",
    "    if a==b:\n",
    "        return 'Hit'\n",
    "    else:\n",
    "        return 'Miss'\n",
    "def accuracy(a, b):\n",
    "    count = 0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == b[i]:\n",
    "            count = count+1\n",
    "    return count/len(a)\n",
    "\n",
    "def accuracy2(a, b, c):\n",
    "    count = 0\n",
    "    count2 =0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != c[i]:\n",
    "            count2 = count2 +1\n",
    "        if a[i] != c[i] and b[i]==c[i]:\n",
    "            count = count+1\n",
    "    return count/count2\n",
    "\n",
    "def isMutation(a, b):\n",
    "    if a!= b:\n",
    "        print(\"mutation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4035202, 5, 22)\n",
      "Train on 3228161 samples, validate on 807041 samples\n",
      "3228161/3228161 [==============================] - 80s 25us/sample - loss: 0.2328 - accuracy: 0.9558 - val_loss: 0.2038 - val_accuracy: 0.9621\n",
      "Train on 3228161 samples, validate on 807041 samples\n",
      "Epoch 1/2\n",
      "3228161/3228161 [==============================] - 71s 22us/sample - loss: 0.2320 - accuracy: 0.9563 - val_loss: 0.2040 - val_accuracy: 0.9621\n",
      "Epoch 2/2\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2034 - accuracy: 0.9622 - val_loss: 0.2032 - val_accuracy: 0.9621\n",
      "Train on 3228161 samples, validate on 807041 samples\n",
      "Epoch 1/10\n",
      "3228161/3228161 [==============================] - 71s 22us/sample - loss: 0.2317 - accuracy: 0.9562 - val_loss: 0.2034 - val_accuracy: 0.9621\n",
      "Epoch 2/10\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2034 - accuracy: 0.9622 - val_loss: 0.2033 - val_accuracy: 0.9621\n",
      "Epoch 3/10\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2031 - accuracy: 0.9622 - val_loss: 0.2032 - val_accuracy: 0.9621\n",
      "Epoch 4/10\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2030 - accuracy: 0.9622 - val_loss: 0.2032 - val_accuracy: 0.9621\n",
      "Epoch 5/10\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2029 - accuracy: 0.9622 - val_loss: 0.2032 - val_accuracy: 0.9621\n",
      "Epoch 6/10\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2029 - accuracy: 0.9622 - val_loss: 0.2032 - val_accuracy: 0.9621\n",
      "Epoch 7/10\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2029 - accuracy: 0.9622 - val_loss: 0.2031 - val_accuracy: 0.9621\n",
      "Epoch 8/10\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2029 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 9/10\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 10/10\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2031 - val_accuracy: 0.9621\n",
      "Train on 3228161 samples, validate on 807041 samples\n",
      "Epoch 1/30\n",
      "3228161/3228161 [==============================] - 71s 22us/sample - loss: 0.2323 - accuracy: 0.9560 - val_loss: 0.2033 - val_accuracy: 0.9621\n",
      "Epoch 2/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2034 - accuracy: 0.9622 - val_loss: 0.2034 - val_accuracy: 0.9621\n",
      "Epoch 3/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2031 - accuracy: 0.9622 - val_loss: 0.2032 - val_accuracy: 0.9621\n",
      "Epoch 4/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2030 - accuracy: 0.9622 - val_loss: 0.2031 - val_accuracy: 0.9621\n",
      "Epoch 5/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2029 - accuracy: 0.9622 - val_loss: 0.2031 - val_accuracy: 0.9621\n",
      "Epoch 6/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2029 - accuracy: 0.9622 - val_loss: 0.2031 - val_accuracy: 0.9621\n",
      "Epoch 7/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2029 - accuracy: 0.9622 - val_loss: 0.2031 - val_accuracy: 0.9621\n",
      "Epoch 8/30\n",
      "3228161/3228161 [==============================] - 66s 21us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 9/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 10/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 11/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 12/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 13/30\n",
      "3228161/3228161 [==============================] - 66s 21us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2031 - val_accuracy: 0.9621\n",
      "Epoch 14/30\n",
      "3228161/3228161 [==============================] - 66s 21us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 15/30\n",
      "3228161/3228161 [==============================] - 66s 20us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 16/30\n",
      "3228161/3228161 [==============================] - 66s 21us/sample - loss: 0.2028 - accuracy: 0.9622 - val_loss: 0.2031 - val_accuracy: 0.9621\n",
      "Epoch 17/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 18/30\n",
      "3228161/3228161 [==============================] - 66s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2031 - val_accuracy: 0.9621\n",
      "Epoch 19/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 20/30\n",
      "3228161/3228161 [==============================] - 66s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2031 - val_accuracy: 0.9621\n",
      "Epoch 21/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 22/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 23/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 24/30\n",
      "3228161/3228161 [==============================] - 66s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 25/30\n",
      "3228161/3228161 [==============================] - 66s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 26/30\n",
      "3228161/3228161 [==============================] - 66s 20us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 27/30\n",
      "3228161/3228161 [==============================] - 66s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 28/30\n",
      "3228161/3228161 [==============================] - 66s 20us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 29/30\n",
      "3228161/3228161 [==============================] - 67s 21us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 30/30\n",
      "3228161/3228161 [==============================] - 66s 20us/sample - loss: 0.2027 - accuracy: 0.9622 - val_loss: 0.2030 - val_accuracy: 0.9621\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-930263d2ab06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# grid_search(256, 128, 000, X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# grid_search(512, 256, 000, X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;31m#grid_search(8192, 4096, 000, X_train, y_train, y_train1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-930263d2ab06>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(latent, half, train_size, X_train, y_train)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/{}_{}_{}_{}_{}_{}_2.h5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mancName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/{}_{}_{}_{}_{}_{}_10.h5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mancName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/{}_{}_{}_{}_{}_{}_30.h5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mancName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;31m#model4.save(\"models/{}_{}_{}_30_double.h5\".format(train_size,half))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m#model5.save(\"models/_gap_hg38_{}_{}_50_double.h5\".format(train_size,half))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model4' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train.shape)\n",
    "def lstm_model(latent_dim, half):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(half, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.LSTM(half, return_sequences=True))\n",
    "    \n",
    "    model.add(layers.Dense(encode_dimension, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "                  )\n",
    "\n",
    "#     model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def modelFit(epoch, batchSize, latent_dim, half, X_train, y_train):\n",
    "    model1 = lstm_model(latent_dim, half)\n",
    "    hist1 = model1.fit(X_train, y_train,\n",
    "          batch_size=batchSize,\n",
    "          epochs=epoch,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1\n",
    "         )\n",
    "    return hist1, model1\n",
    "\n",
    "def grid_search(latent, half,train_size, X_train, y_train):\n",
    "    hist1, model1 = modelFit(1, 1000, latent, half, X_train, y_train)\n",
    "    hist2 ,model2 = modelFit(2, 1000, latent, half, X_train, y_train)\n",
    "    hist3 ,model3 = modelFit(10, 1000, latent, half, X_train, y_train)\n",
    "    hist4 ,model4 = modelFit(30, 1000, latent, half, X_train, y_train)\n",
    "    #hist4 ,model4, encoder_model4, decoder_model4 = modelFit(30, 1000, latent, half, X_train, y_train)\n",
    "    #hist5 ,model5, encoder_model5, decoder_model5 = modelFit(50, 100, latent, half, X_train, y_train)\n",
    "    #hist6 ,model6, encoder_model6, decoder_model6 = modelFit(80, 100, latent, half, X_train, y_train)\n",
    "    #hist7 ,model7, encoder_model7, decoder_model7 = modelFit(100, 100, latent, half, X_train, y_train)\n",
    "    #hist8 ,model8, encoder_model8, decoder_model8 = modelFit(500, 100, latent, half)\n",
    "\n",
    "    model1.save(\"models/{}_{}_{}_{}_{}_{}_1.h5\".format(modelName,ancName, desName,train_size,half,seq_length))\n",
    "    model2.save(\"models/{}_{}_{}_{}_{}_{}_2.h5\".format(modelName,ancName, desName,train_size,half,seq_length))\n",
    "    model3.save(\"models/{}_{}_{}_{}_{}_{}_10.h5\".format(modelName,ancName, desName,train_size,half,seq_length))\n",
    "    model4.save(\"models/{}_{}_{}_{}_{}_{}_30.h5\".format(modelName,ancName, desName,train_size,half,seq_length))\n",
    "    #model4.save(\"models/{}_{}_{}_30_double.h5\".format(train_size,half))\n",
    "    #model5.save(\"models/_gap_hg38_{}_{}_50_double.h5\".format(train_size,half))\n",
    "    #model6.save(\"models/_gap_hg38_{}_{}_80_double.h5\".format(train_size,half))\n",
    "    #model7.save(\"models/_gap_hg38_{}_{}_100_double.h5\".format(train_size,half))\n",
    "    #model8.save(\"_gap_hg38_{}_{}_500.h5\".format(train_size,half))\n",
    "\n",
    "\n",
    "# grid_search(2, 1, 000, X_train, y_train)\n",
    "# grid_search(16, 8, 000, X_train, y_train)        \n",
    "# grid_search(32, 16, 000, X_train, y_train)\n",
    "# grid_search(64, 32, 000, X_train, y_train)\n",
    "# grid_search(128, 64, 000, X_train, y_train)\n",
    "# grid_search(256, 128, 000, X_train, y_train)\n",
    "# grid_search(512, 256, 000, X_train, y_train)\n",
    "# grid_search(1024, 512, 000, X_train, y_train)\n",
    "#grid_search(8192, 4096, 000, X_train, y_train, y_train1)\n",
    "\n",
    "with open('loss_hist.txt', 'wb') as fp:\n",
    "    pickle.dump(val_loss_hist, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%precision 2\n",
    "test_size = len(y_test)\n",
    "val_size = 30000\n",
    "\n",
    "key = ['-', '0', 'A', 'B', 'C', 'G', 'I', 'L', 'N', 'O', 'P', 'T', 'V' ,'X' ,'b', 'c', 'f', 'g', 'h', 'i',\n",
    "       'o', 'p' ,'r']\n",
    "\n",
    "mapDict = {'A': 'A', 'C': 'C', 'G': 'G', 'T': 'T', '-': '-', 'AA': 'O', 'AC': 'h', '0': '0',\n",
    "           'AT': 'b', 'AG': 'V', 'CA': 'r', 'CC': 'p', 'CT': 'o', 'CG': 'i', 'TA': 'g', \n",
    "           'TC': 'I', 'TT': 'f', 'TG': 'L', 'GA': 'B', 'GC': 'c', 'GT': 'X', 'GG': 'P'}\n",
    "\n",
    "rev_dict = {v: k for k, v in mapDict.items()}\n",
    "#print(rev_dict.keys())\n",
    "rev_key = []\n",
    "for item in key:\n",
    "    #print(item)\n",
    "    if item in list(rev_dict.keys()):\n",
    "        rev_key.append(rev_dict[item])\n",
    "        #print('hi')\n",
    "    else :\n",
    "        rev_key.append(item)\n",
    "print(rev_key)\n",
    "\n",
    "nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "\n",
    "def printHitMiss(a,b):\n",
    "    if a==b:\n",
    "        return 'Hit'\n",
    "    else:\n",
    "        return 'Miss'\n",
    "    \n",
    "def accuracy(a, b):\n",
    "    count = 0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] == b[i]:\n",
    "            count = count+1\n",
    "    return count/len(a)\n",
    "\n",
    "def accuracy2(a, b, c):\n",
    "    count = 0\n",
    "    count2 =0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != c[i]:\n",
    "            count2 = count2 +1\n",
    "        if a[i] != c[i] and b[i]==c[i]:\n",
    "            count = count+1\n",
    "    return count/count2\n",
    "\n",
    "def isMutation(a, b):\n",
    "    if a!= b:\n",
    "        print(\"mutation\")\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq, model):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    # Encode the input as state vectors.\n",
    "    #print(input_seq[0,0])\n",
    "    index = 0\n",
    "#     states_value = model.predict(input_seq)\n",
    "#     target_seq = np.zeros((1, 1, encode_dimension*2))\n",
    "#     target_seq[0][0]= np.hstack((input_seq[0,index], onehot_encoder.transform(np.ones(1).reshape(-1,1))[0]))\n",
    "    stop_condition = False\n",
    "    decoded_seq = ''\n",
    "    probability = 1\n",
    "    \n",
    "    predicted = model.predict(input_seq)\n",
    "    while not stop_condition:\n",
    "        index = index +1\n",
    "#         print([input_seq[index-1]])\n",
    "        output_tokens = predicted[0][index-1]\n",
    "#        sampled_token_index = np.random.choice(encode_dimension, 1, p=output_tokens)[0]\n",
    "        sampled_nucleotide = nucleotide[np.random.choice(encode_dimension, 1, p=output_tokens)[0]]\n",
    "        \n",
    "        decoded_seq += sampled_nucleotide\n",
    "        if (len(decoded_seq) == seq_length):\n",
    "            break\n",
    "\n",
    "    return decoded_seq\n",
    "\n",
    "def get_prob(input_seq, target, model):\n",
    "    # Encode the input as state vectors.\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    index = 0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_seq = ''\n",
    "    probability = []\n",
    "    predicted = model.predict(input_seq)\n",
    "    \n",
    "    while not stop_condition:\n",
    "        index = index +1\n",
    "        output_tokens = predicted[0][index-1]\n",
    "        sampled_token_index = np.argmax(target[index-1])\n",
    "          \n",
    "        probability.append(output_tokens[sampled_token_index])\n",
    "        sampled_nucleotide = nucleotide[np.random.choice(encode_dimension, 1, p=output_tokens)[0]]\n",
    "        \n",
    "        decoded_seq += sampled_nucleotide\n",
    "        if (len(decoded_seq) == seq_length):\n",
    "            break\n",
    "\n",
    "\n",
    "    return decoded_seq, probability\n",
    "\n",
    "def diffList(a, b):\n",
    "    count = 0\n",
    "    length = len(a)\n",
    "    for i in range(length):\n",
    "        if a[i] != b[i]:\n",
    "            count = count+1\n",
    "    return count\n",
    "\n",
    "def decoder(input):\n",
    "    nucleotide = label_encoder.inverse_transform(range(encode_dimension))\n",
    "    decoded = ''\n",
    "    for i in range(len(input)):\n",
    "        # decoded= decoded+(nucleotide[np.argmax(onehot_encoder.inverse_transform(input[i].reshape(-1, 1)))])\n",
    "        #print(np.argmax(input[i]))\n",
    "        #print(nucleotide)\n",
    "        decoded= decoded+nucleotide[np.argmax(input[i])]\n",
    "    return decoded\n",
    "\n",
    "#for seq_index in range(1):\n",
    "def predict2(X_test, y_test, model, gru=False):\n",
    "    print(X_test.shape)\n",
    "    x_true =[]\n",
    "    y_hat =[]\n",
    "    y_true =[]\n",
    "    probList=[]\n",
    "    generator_output = []\n",
    "    productProb = [0]*seq_length\n",
    "\n",
    "    for seq_index in notebook.tqdm(range(len(X_test))):\n",
    "        input_seq = X_test[seq_index: seq_index + 1]\n",
    "#         if gru:\n",
    "#             decoded_sentence = decode_gru(input_seq, model)\n",
    "#         else :\n",
    "#             decoded_sentence = decode_sequence(input_seq, model)\n",
    "        decoded_sentence, prob = get_prob(input_seq, y_test[seq_index], model)\n",
    "        prob = [math.log(x) for x in prob]\n",
    "        productProb = [sum(x) for x in zip(productProb, prob)]\n",
    "        input_sen = decoder(input_seq[0])\n",
    "#         inputAll = inputAll + input_sen\n",
    "#         predAll = predAll + decoded_sentence\n",
    "#         outputAll = outputAll + decoder(y_test[seq_index])\n",
    "#         print(input_sen, ' -> ',\n",
    "#               decoded_sentence, 'True:', decoder(y_test[seq_index]), \n",
    "#               printHitMiss(decoded_sentence, decoder(y_test[seq_index]))\n",
    "#               #diffList(input_sen, decoded_sentence)\n",
    "#              )\n",
    "#         print(input_sen, ' -> ',\n",
    "#               decoder(y_test[seq_index]), 'True:', decoder(y_test[seq_index]), \n",
    "#               prob,\n",
    "#               printHitMiss(decoded_sentence, decoder(y_test[seq_index]))\n",
    "#               #diffList(input_sen, decoded_sentence)\n",
    "#              )\n",
    "        x_true.append(input_sen)\n",
    "        y_hat.append(decoded_sentence)\n",
    "        y_true.append(decoder(y_test[seq_index]))\n",
    "    #generator_output.append(input_sen+decoded_seq)\n",
    "    print(productProb)\n",
    "    productProb = [x/test_size for x in productProb]\n",
    "    print(\"Sum of log probabilities : {}\".format(productProb))\n",
    "    print(\"Percentage of target and prediction being identical: {}\".format(accuracy(y_hat, y_true)))\n",
    "    print(\"Percentage of training and prediction being identical: {}\".format(accuracy(y_hat, x_true)))\n",
    "    print(\"Accuracy given mutation happened : {}\".format(accuracy2(x_true, y_hat, y_true)))\n",
    "    #np.save('data/hg38_output.npy', generator_output)\n",
    "    \n",
    "    return x_true, y_hat, y_true\n",
    "\n",
    "def grid_predict(train_size, half, epoch, X_test, y_test):\n",
    "    model1 = tf.keras.models.load_model(\"models/{}_{}_{}_{}_{}_{}_{}.h5\".format(modelName, ancName, desName,train_size,half,seq_length,epoch))\n",
    "\n",
    "   \n",
    "\n",
    "    inputAll, predAll, outputAll = predict2(X_test, y_test, model1, gru=False)\n",
    "    \n",
    "    return inputAll, predAll, outputAll\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "def concat(input1, input2):\n",
    "    result = []\n",
    "    for x, y in zip(input1, input2):\n",
    "        result.append(np.hstack((x, y)))\n",
    "    \n",
    "    return np.array(result)\n",
    "\n",
    "# def get_data(trainInd, valInd, testInd):\n",
    "#     X_train=np.load('prepData/X_train_gap_hg38_v3_chr2_size10.npy')[:trainInd]\n",
    "#     X_val=np.load('prepData/X_val_gap_hg38_v3_chr2_size10.npy')[:valInd]\n",
    "#     X_test=np.load('prepData/X_test_gap_hg38_v3_chr2_size10.npy')[:testInd]\n",
    "#     y_train=np.load('prepData/y_train_gap_hg38_v3_chr2_size10.npy')[:trainInd]\n",
    "#     y_val=np.load('prepData/y_val_gap_hg38_v3_chr2_size10.npy')[:valInd]\n",
    "#     y_test=np.load('prepData/y_test_gap_hg38_v3_chr2_size10.npy')[:testInd]\n",
    "\n",
    "#     y_train1 = np.load('prepData/y_train1_gap_hg38_v3_chr2_size10.npy')[:trainInd]\n",
    "#     y_val1 = np.load('prepData/y_val1_gap_hg38_v3_chr2_size10.npy')[:valInd]\n",
    "#     y_test1 = np.load('prepData/y_test1_gap_hg38_v3_chr2_size10.npy')[:testInd]\n",
    "\n",
    "#     y_train1 = concat(X_train, y_train1)\n",
    "#     y_val1 = concat(X_val, y_val1)\n",
    "#     y_test1 = concat(X_test, y_test1)\n",
    "#     return X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "# hidden = [16, 32, 64,128,256,512]\n",
    "# epoch = [10, 10, 2, 2, 2, 1]\n",
    "hidden = [512]\n",
    "epoch = [10]\n",
    "#X_test, y_test = get_data(train_size, val_size, test_size)\n",
    "for h, e in zip(hidden, epoch):\n",
    "    print(\"Anc : {}, Des : {}, Train size = {}, hidden_size = {}, epoch = {}\".format(ancName, desName, train_size, h, e))\n",
    "    inputAll, predAll, outputAll = grid_predict(train_size, h, e, X_test[-100000:], y_test[-100000:])\n",
    "    print(\"The end of Anc : {}, Des : {}, Train size = {}, hidden_size = {}, epoch = {}\".format(ancName, desName,train_size, h, e))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# mapDict = {'A': 'A', 'C': 'C', 'G': 'G', 'T': 'T', '-': '-', 'AA': 'O', 'AC': 'h', '0': '0',\n",
    "#        'AT': 'b', 'AG': 'V', 'CA': 'r', 'CC': 'p', 'CT': 'o', 'CG': 'i', 'TA': 'g', \n",
    "#        'TC': 'I', 'TT': 'f', 'TG': 'L', 'GA': 'B', 'GC': 'c', 'GT': 'X', 'GG': 'P'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def contextMut(size, ancNuc, desNuc, anc, des):\n",
    "    cont = list(itertools.product('ACGT-', repeat=size))\n",
    "    context_dict = {}\n",
    "    count_dict = {}\n",
    "    for i in cont:\n",
    "        for j in cont:\n",
    "            #context_dict[(''.join(i)+'A'+''.join(j) , ''.join(i)+'G'+''.join(j))] = 0\n",
    "            context_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "            count_dict[(''.join(i)+ancNuc+''.join(j))] = 0\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(seq_length-size*2):\n",
    "            if a[i+size] == ancNuc :\n",
    "                count_dict[(a[i:i+size*2+1])] += 1\n",
    "    for a,b in zip(anc, des):\n",
    "        for i in range(seq_length-size*2):\n",
    "            if a[i+size] == ancNuc and b[i+size] == desNuc:\n",
    "                context_dict[(a[i:i+size*2+1])] += 1\n",
    "    for key in context_dict.keys():\n",
    "        if count_dict[key] !=0:\n",
    "            context_dict[key] = context_dict[key]/count_dict[key] \n",
    "        else :\n",
    "            continue\n",
    "    sorted_context = sorted(context_dict.items(), key=operator.itemgetter(1), reverse = 1)\n",
    "    return sorted_context\n",
    "\n",
    "# pred_contextAG = contextMut(contextLen, 'A', 'G', inputAll, predAll)\n",
    "# true_contextAG = contextMut(contextLen, 'A', 'G', inputAll, outputAll)\n",
    "# pred_contextCT = contextMut(contextLen, 'C', 'T', inputAll, predAll)\n",
    "# true_contextCT = contextMut(contextLen, 'C', 'T', inputAll, outputAll)\n",
    "# print(pred_context)\n",
    "# print(true_context)\n",
    "    \n",
    "# for i in range(100):\n",
    "#     print(pred_context[i], true_context[i])\n",
    "\n",
    "def plotPointMut(n_groups, predSeq, trueSeq, ancNuc, desNuc):\n",
    "    pred = [b for a,b in predSeq][:n_groups]\n",
    "    true = [b for a,b in trueSeq][:n_groups]\n",
    "\n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.05\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, pred, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='b',\n",
    "    label='pred')\n",
    "\n",
    "    rects2 = plt.bar(index + bar_width, true, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='g',\n",
    "    label='true')\n",
    "\n",
    "    plt.xlabel('context')\n",
    "    plt.ylabel('number')\n",
    "    plt.title('{} to {} point mutation'.format(ancNuc, desNuc))\n",
    "    plt.xticks(index + bar_width, [a for (a,b) in trueSeq][:n_groups])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "contextLen = 2\n",
    "numBin = 40\n",
    "np.save('inputAll_{}_{}_{}_{}'.format(modelName, ancName, desName, seq_length), inputAll)\n",
    "np.save('predAll_{}_{}_{}_{}'.format(modelName, ancName, desName, seq_length), predAll)\n",
    "np.save('outputAll_{}_{}_{}_{}'.format(modelName, ancName, desName, seq_length), outputAll)\n",
    "\n",
    "pred_contextAG = contextMut(contextLen, 'A', 'G', inputAll, predAll)\n",
    "true_contextAG = contextMut(contextLen, 'A', 'G', inputAll, outputAll)\n",
    "pred_contextAT = contextMut(contextLen, 'A', 'T', inputAll, predAll)\n",
    "true_contextAT = contextMut(contextLen, 'A', 'T', inputAll, outputAll)\n",
    "pred_contextAC = contextMut(contextLen, 'A', 'C', inputAll, predAll)\n",
    "true_contextAC = contextMut(contextLen, 'A', 'C', inputAll, outputAll)\n",
    "pred_contextCT = contextMut(contextLen, 'C', 'T', inputAll, predAll)\n",
    "true_contextCT = contextMut(contextLen, 'C', 'T', inputAll, outputAll)\n",
    "pred_contextCG = contextMut(contextLen, 'C', 'G', inputAll, predAll)\n",
    "true_contextCG = contextMut(contextLen, 'C', 'G', inputAll, outputAll)\n",
    "pred_contextCA = contextMut(contextLen, 'C', 'A', inputAll, predAll)\n",
    "true_contextCA = contextMut(contextLen, 'C', 'A', inputAll, outputAll)\n",
    "pred_contextGA = contextMut(contextLen, 'G', 'A', inputAll, predAll)\n",
    "true_contextGA = contextMut(contextLen, 'G', 'A', inputAll, outputAll)\n",
    "pred_contextGT = contextMut(contextLen, 'G', 'T', inputAll, predAll)\n",
    "true_contextGT = contextMut(contextLen, 'G', 'T', inputAll, outputAll)\n",
    "pred_contextGC = contextMut(contextLen, 'G', 'C', inputAll, predAll)\n",
    "true_contextGC = contextMut(contextLen, 'G', 'C', inputAll, outputAll)\n",
    "pred_contextTA = contextMut(contextLen, 'T', 'A', inputAll, predAll)\n",
    "true_contextTA = contextMut(contextLen, 'T', 'A', inputAll, outputAll)\n",
    "pred_contextTC = contextMut(contextLen, 'T', 'C', inputAll, predAll)\n",
    "true_contextTC = contextMut(contextLen, 'T', 'C', inputAll, outputAll)\n",
    "pred_contextTG = contextMut(contextLen, 'T', 'G', inputAll, predAll)\n",
    "true_contextTG = contextMut(contextLen, 'T', 'G', inputAll, outputAll)\n",
    "true_contextAgap = contextMut(contextLen, 'A', '-', inputAll, outputAll)\n",
    "pred_contextAgap = contextMut(contextLen, 'A', '-', inputAll, predAll)\n",
    "true_contextCgap = contextMut(contextLen, 'C', '-', inputAll, outputAll)\n",
    "pred_contextCgap = contextMut(contextLen, 'C', '-', inputAll, predAll)\n",
    "true_contextGgap = contextMut(contextLen, 'G', '-', inputAll, outputAll)\n",
    "pred_contextGgap = contextMut(contextLen, 'G', '-', inputAll, predAll)\n",
    "true_contextTgap = contextMut(contextLen, 'T', '-', inputAll, outputAll)\n",
    "pred_contextTgap = contextMut(contextLen, 'T', '-', inputAll, predAll)\n",
    "# print(pred_context)\n",
    "# print(true_context)\n",
    "    \n",
    "plotPointMut(numBin, pred_contextAG, true_contextAG, 'A','G')\n",
    "plotPointMut(numBin, pred_contextAT, true_contextAT, 'A','T')\n",
    "plotPointMut(numBin, pred_contextAC, true_contextAC, 'A','C')\n",
    "plotPointMut(numBin, pred_contextCT, true_contextCT, 'C','T')\n",
    "plotPointMut(numBin, pred_contextCA, true_contextCA, 'C','A')\n",
    "plotPointMut(numBin, pred_contextCG, true_contextCG, 'C','G')\n",
    "plotPointMut(numBin, pred_contextGA, true_contextGA, 'G','A')\n",
    "plotPointMut(numBin, pred_contextGT, true_contextGT, 'G','T')\n",
    "plotPointMut(numBin, pred_contextGC, true_contextGC, 'G','C')\n",
    "plotPointMut(numBin, pred_contextTC, true_contextTC, 'T','C')\n",
    "plotPointMut(numBin, pred_contextTA, true_contextTA, 'T','A')\n",
    "plotPointMut(numBin, pred_contextTG, true_contextTG, 'T','G')\n",
    "plotPointMut(numBin, pred_contextAgap, true_contextAgap, 'A','-')\n",
    "plotPointMut(numBin, pred_contextCgap, true_contextCgap, 'C','-')\n",
    "plotPointMut(numBin, pred_contextGgap, true_contextGgap, 'G','-')\n",
    "plotPointMut(numBin, pred_contextTgap, true_contextTgap, 'T','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqCases(mutList):\n",
    "    sum = 0\n",
    "    for item in mutList:\n",
    "        sum += item[1]\n",
    "    print(sum)\n",
    "\n",
    "freqCases(pred_contextAG)\n",
    "freqCases(pred_contextAgap)\n",
    "\n",
    "print(predAll[:100])\n",
    "print(outputAll[:100])\n",
    "print(inputAll[:100])\n",
    "model1 = tf.keras.models.load_model(\"models/{}_{}_{}_{}_{}_{}.h5\".format(modelName, ancName, desName,train_size,512,10))\n",
    "print(model1.predict(X_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScatter(n_groups, predSeq, trueSeq, ancNuc, desNuc):\n",
    "    pred = [b for a,b in predSeq][:n_groups]\n",
    "    true = [b for a,b in trueSeq][:n_groups]\n",
    "    plt.scatter(pred, true, color = 'm')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.axis('scaled')\n",
    "    plt.axis('square')\n",
    "    plt.title('{} to {} point mutation'.format(ancNuc, desNuc))\n",
    "    plt.savefig('figures/scatter_{}_{}_{}_{}_{}->{}.png'.format(ancName, desName, train_size, seq_length, ancNuc, desNuc))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "plotScatter(numBin, pred_contextAG, true_contextAG, 'A','G')\n",
    "plotScatter(numBin, pred_contextAT, true_contextAT, 'A','T')\n",
    "plotScatter(numBin, pred_contextAC, true_contextAC, 'A','C')\n",
    "plotScatter(numBin, pred_contextCT, true_contextCT, 'C','T')\n",
    "plotScatter(numBin, pred_contextCA, true_contextCA, 'C','A')\n",
    "plotScatter(numBin, pred_contextCG, true_contextCG, 'C','G')\n",
    "plotScatter(numBin, pred_contextGA, true_contextGA, 'G','A')\n",
    "plotScatter(numBin, pred_contextGT, true_contextGT, 'G','T')\n",
    "plotScatter(numBin, pred_contextGC, true_contextGC, 'G','C')\n",
    "plotScatter(numBin, pred_contextTC, true_contextTC, 'T','C')\n",
    "plotScatter(numBin, pred_contextTA, true_contextTA, 'T','A')\n",
    "plotScatter(numBin, pred_contextTG, true_contextTG, 'T','G')\n",
    "plotScatter(numBin, pred_contextAgap, true_contextAgap, 'A','-')\n",
    "plotScatter(numBin, pred_contextCgap, true_contextCgap, 'C','-')\n",
    "plotScatter(numBin, pred_contextGgap, true_contextGgap, 'G','-')\n",
    "plotScatter(numBin, pred_contextTgap, true_contextTgap, 'T','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newInputAll = ''\n",
    "# newOutputAll = ''\n",
    "# for i in range(len(inputAll)):\n",
    "#     newInputAll =+ \n",
    "    \n",
    "contextLen = 2\n",
    "numBin = 20\n",
    "\n",
    "pred_contextAG = contextMut(contextLen, 'A', 'G', inputAll, predAll)\n",
    "true_contextAG = contextMut(contextLen, 'A', 'G', inputAll, outputAll)\n",
    "pred_contextAT = contextMut(contextLen, 'A', 'T', inputAll, predAll)\n",
    "true_contextAT = contextMut(contextLen, 'A', 'T', inputAll, outputAll)\n",
    "pred_contextAC = contextMut(contextLen, 'A', 'C', inputAll, predAll)\n",
    "true_contextAC = contextMut(contextLen, 'A', 'C', inputAll, outputAll)\n",
    "pred_contextCT = contextMut(contextLen, 'C', 'T', inputAll, predAll)\n",
    "true_contextCT = contextMut(contextLen, 'C', 'T', inputAll, outputAll)\n",
    "pred_contextCG = contextMut(contextLen, 'C', 'G', inputAll, predAll)\n",
    "true_contextCG = contextMut(contextLen, 'C', 'G', inputAll, outputAll)\n",
    "pred_contextCA = contextMut(contextLen, 'C', 'A', inputAll, predAll)\n",
    "true_contextCA = contextMut(contextLen, 'C', 'A', inputAll, outputAll)\n",
    "pred_contextGA = contextMut(contextLen, 'G', 'A', inputAll, predAll)\n",
    "true_contextGA = contextMut(contextLen, 'G', 'A', inputAll, outputAll)\n",
    "pred_contextGT = contextMut(contextLen, 'G', 'T', inputAll, predAll)\n",
    "true_contextGT = contextMut(contextLen, 'G', 'T', inputAll, outputAll)\n",
    "pred_contextGC = contextMut(contextLen, 'G', 'C', inputAll, predAll)\n",
    "true_contextGC = contextMut(contextLen, 'G', 'C', inputAll, outputAll)\n",
    "pred_contextTA = contextMut(contextLen, 'T', 'A', inputAll, predAll)\n",
    "true_contextTA = contextMut(contextLen, 'T', 'A', inputAll, outputAll)\n",
    "pred_contextTC = contextMut(contextLen, 'T', 'C', inputAll, predAll)\n",
    "true_contextTC = contextMut(contextLen, 'T', 'C', inputAll, outputAll)\n",
    "pred_contextTG = contextMut(contextLen, 'T', 'G', inputAll, predAll)\n",
    "true_contextTG = contextMut(contextLen, 'T', 'G', inputAll, outputAll)\n",
    "true_contextAgap = contextMut(contextLen, 'A', '-', inputAll, outputAll)\n",
    "pred_contextAgap = contextMut(contextLen, 'A', '-', inputAll, predAll)\n",
    "true_contextCgap = contextMut(contextLen, 'C', '-', inputAll, outputAll)\n",
    "pred_contextCgap = contextMut(contextLen, 'C', '-', inputAll, predAll)\n",
    "true_contextGgap = contextMut(contextLen, 'G', '-', inputAll, outputAll)\n",
    "pred_contextGgap = contextMut(contextLen, 'G', '-', inputAll, predAll)\n",
    "true_contextTgap = contextMut(contextLen, 'T', '-', inputAll, outputAll)\n",
    "pred_contextTgap = contextMut(contextLen, 'T', '-', inputAll, predAll)\n",
    "# print(pred_context)\n",
    "# print(true_context)\n",
    "    \n",
    "plotPointMut(numBin, pred_contextAG, true_contextAG, 'A','G')\n",
    "plotPointMut(numBin, pred_contextAT, true_contextAT, 'A','T')\n",
    "plotPointMut(numBin, pred_contextAC, true_contextAC, 'A','C')\n",
    "plotPointMut(numBin, pred_contextCT, true_contextCT, 'C','T')\n",
    "plotPointMut(numBin, pred_contextCA, true_contextCA, 'C','A')\n",
    "plotPointMut(numBin, pred_contextCG, true_contextCG, 'C','G')\n",
    "plotPointMut(numBin, pred_contextGA, true_contextGA, 'G','A')\n",
    "plotPointMut(numBin, pred_contextGT, true_contextGT, 'G','T')\n",
    "plotPointMut(numBin, pred_contextGC, true_contextGC, 'G','C')\n",
    "plotPointMut(numBin, pred_contextTC, true_contextTC, 'T','C')\n",
    "plotPointMut(numBin, pred_contextTA, true_contextTA, 'T','A')\n",
    "plotPointMut(numBin, pred_contextTG, true_contextTG, 'T','G')\n",
    "plotPointMut(numBin, pred_contextAgap, true_contextAgap, 'A','-')\n",
    "plotPointMut(numBin, pred_contextCgap, true_contextCgap, 'C','-')\n",
    "plotPointMut(numBin, pred_contextGgap, true_contextGgap, 'G','-')\n",
    "plotPointMut(numBin, pred_contextTgap, true_contextTgap, 'T','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder.transform(np.ones(1).reshape(-1,1))\n",
    "for i in range (100):\n",
    "    print(decoder(X_train[i]), decoder(y_train[i]), decoder(y_train1[i]))\n",
    "    \n",
    "print(y_train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancList = ['_HP','_HPG','_HPGP','_HPGPN','_HPGPNRMPC']\n",
    "trainL = [100000, 1000000, 1000000]\n",
    "lenL = [5, 11, 15, 21, 51, 101]\n",
    "\n",
    "for a in ancList:\n",
    "    for b in trainL:\n",
    "        for c in lenL:\n",
    "            print('sbatch insert1Train_general_size.sh {} \\'hg38\\' {} {}'.format(a, b, c))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
